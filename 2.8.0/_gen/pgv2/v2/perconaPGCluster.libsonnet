{
  local d = (import 'doc-util/main.libsonnet'),
  '#':: d.pkg(name='perconaPGCluster', url='', help='"PerconaPGCluster is the CRD that defines a Percona PG Cluster"'),
  '#metadata':: d.obj(help='"ObjectMeta is metadata that all persisted resources must have, which includes all objects users must create."'),
  metadata: {
    '#withAnnotations':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotations(annotations): { metadata+: { annotations: annotations } },
    '#withAnnotationsMixin':: d.fn(help='"Annotations is an unstructured key value map stored with a resource that may be set by external tools to store and retrieve arbitrary metadata. They are not queryable and should be preserved when modifying objects. More info: http://kubernetes.io/docs/user-guide/annotations"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
    withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
    '#withClusterName':: d.fn(help='"The name of the cluster which the object belongs to. This is used to distinguish resources with same name and namespace in different clusters. This field is not set anywhere right now and apiserver is going to ignore it if set in create or update request."', args=[d.arg(name='clusterName', type=d.T.string)]),
    withClusterName(clusterName): { metadata+: { clusterName: clusterName } },
    '#withCreationTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='creationTimestamp', type=d.T.string)]),
    withCreationTimestamp(creationTimestamp): { metadata+: { creationTimestamp: creationTimestamp } },
    '#withDeletionGracePeriodSeconds':: d.fn(help='"Number of seconds allowed for this object to gracefully terminate before it will be removed from the system. Only set when deletionTimestamp is also set. May only be shortened. Read-only."', args=[d.arg(name='deletionGracePeriodSeconds', type=d.T.integer)]),
    withDeletionGracePeriodSeconds(deletionGracePeriodSeconds): { metadata+: { deletionGracePeriodSeconds: deletionGracePeriodSeconds } },
    '#withDeletionTimestamp':: d.fn(help='"Time is a wrapper around time.Time which supports correct marshaling to YAML and JSON.  Wrappers are provided for many of the factory methods that the time package offers."', args=[d.arg(name='deletionTimestamp', type=d.T.string)]),
    withDeletionTimestamp(deletionTimestamp): { metadata+: { deletionTimestamp: deletionTimestamp } },
    '#withFinalizers':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizers(finalizers): { metadata+: { finalizers: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withFinalizersMixin':: d.fn(help='"Must be empty before the object is deleted from the registry. Each entry is an identifier for the responsible component that will remove the entry from the list. If the deletionTimestamp of the object is non-nil, entries in this list can only be removed. Finalizers may be processed and removed in any order.  Order is NOT enforced because it introduces significant risk of stuck finalizers. finalizers is a shared field, any actor with permission can reorder it. If the finalizer list is processed in order, then this can lead to a situation in which the component responsible for the first finalizer in the list is waiting for a signal (field value, external system, or other) produced by a component responsible for a finalizer later in the list, resulting in a deadlock. Without enforced ordering finalizers are free to order amongst themselves and are not vulnerable to ordering changes in the list."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='finalizers', type=d.T.array)]),
    withFinalizersMixin(finalizers): { metadata+: { finalizers+: if std.isArray(v=finalizers) then finalizers else [finalizers] } },
    '#withGenerateName':: d.fn(help='"GenerateName is an optional prefix, used by the server, to generate a unique name ONLY IF the Name field has not been provided. If this field is used, the name returned to the client will be different than the name passed. This value will also be combined with a unique suffix. The provided value has the same validation rules as the Name field, and may be truncated by the length of the suffix required to make the value unique on the server.\\n\\nIf this field is specified and the generated name exists, the server will NOT return a 409 - instead, it will either return 201 Created or 500 with Reason ServerTimeout indicating a unique name could not be found in the time allotted, and the client should retry (optionally after the time indicated in the Retry-After header).\\n\\nApplied only if Name is not specified. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency"', args=[d.arg(name='generateName', type=d.T.string)]),
    withGenerateName(generateName): { metadata+: { generateName: generateName } },
    '#withGeneration':: d.fn(help='"A sequence number representing a specific generation of the desired state. Populated by the system. Read-only."', args=[d.arg(name='generation', type=d.T.integer)]),
    withGeneration(generation): { metadata+: { generation: generation } },
    '#withLabels':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"', args=[d.arg(name='labels', type=d.T.object)]),
    withLabels(labels): { metadata+: { labels: labels } },
    '#withLabelsMixin':: d.fn(help='"Map of string keys and values that can be used to organize and categorize (scope and select) objects. May match selectors of replication controllers and services. More info: http://kubernetes.io/docs/user-guide/labels"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
    withLabelsMixin(labels): { metadata+: { labels+: labels } },
    '#withName':: d.fn(help='"Name must be unique within a namespace. Is required when creating resources, although some resources may allow a client to request the generation of an appropriate name automatically. Name is primarily intended for creation idempotence and configuration definition. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/identifiers#names"', args=[d.arg(name='name', type=d.T.string)]),
    withName(name): { metadata+: { name: name } },
    '#withNamespace':: d.fn(help='"Namespace defines the space within which each name must be unique. An empty namespace is equivalent to the \\"default\\" namespace, but \\"default\\" is the canonical representation. Not all objects are required to be scoped to a namespace - the value of this field for those objects will be empty.\\n\\nMust be a DNS_LABEL. Cannot be updated. More info: http://kubernetes.io/docs/user-guide/namespaces"', args=[d.arg(name='namespace', type=d.T.string)]),
    withNamespace(namespace): { metadata+: { namespace: namespace } },
    '#withOwnerReferences':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferences(ownerReferences): { metadata+: { ownerReferences: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withOwnerReferencesMixin':: d.fn(help='"List of objects depended by this object. If ALL objects in the list have been deleted, this object will be garbage collected. If this object is managed by a controller, then an entry in this list will point to this controller, with the controller field set to true. There cannot be more than one managing controller."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ownerReferences', type=d.T.array)]),
    withOwnerReferencesMixin(ownerReferences): { metadata+: { ownerReferences+: if std.isArray(v=ownerReferences) then ownerReferences else [ownerReferences] } },
    '#withResourceVersion':: d.fn(help='"An opaque value that represents the internal version of this object that can be used by clients to determine when objects have changed. May be used for optimistic concurrency, change detection, and the watch operation on a resource or set of resources. Clients must treat these values as opaque and passed unmodified back to the server. They may only be valid for a particular resource or set of resources.\\n\\nPopulated by the system. Read-only. Value must be treated as opaque by clients and . More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency"', args=[d.arg(name='resourceVersion', type=d.T.string)]),
    withResourceVersion(resourceVersion): { metadata+: { resourceVersion: resourceVersion } },
    '#withSelfLink':: d.fn(help='"SelfLink is a URL representing this object. Populated by the system. Read-only.\\n\\nDEPRECATED Kubernetes will stop propagating this field in 1.20 release and the field is planned to be removed in 1.21 release."', args=[d.arg(name='selfLink', type=d.T.string)]),
    withSelfLink(selfLink): { metadata+: { selfLink: selfLink } },
    '#withUid':: d.fn(help='"UID is the unique in time and space value for this object. It is typically generated by the server on successful creation of a resource and is not allowed to change on PUT operations.\\n\\nPopulated by the system. Read-only. More info: http://kubernetes.io/docs/user-guide/identifiers#uids"', args=[d.arg(name='uid', type=d.T.string)]),
    withUid(uid): { metadata+: { uid: uid } },
  },
  '#new':: d.fn(help='new returns an instance of PerconaPGCluster', args=[d.arg(name='name', type=d.T.string)]),
  new(name): {
    apiVersion: 'pgv2.percona.com/v2',
    kind: 'PerconaPGCluster',
  } + self.metadata.withName(name=name),
  '#spec':: d.obj(help=''),
  spec: {
    '#backups':: d.obj(help='"PostgreSQL backup configuration"'),
    backups: {
      '#pgbackrest':: d.obj(help='"pgBackRest archive configuration"'),
      pgbackrest: {
        '#configuration':: d.obj(help='"Projected volumes containing custom pgBackRest configuration.  These files are mounted\\nunder \\"/etc/pgbackrest/conf.d\\" alongside any pgBackRest configuration generated by the\\nPostgreSQL Operator:\\nhttps://pgbackrest.org/configuration.html"'),
        configuration: {
          '#clusterTrustBundle':: d.obj(help='"ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field\\nof ClusterTrustBundle objects in an auto-updating file.\\n\\nAlpha, gated by the ClusterTrustBundleProjection feature gate.\\n\\nClusterTrustBundle objects can either be selected by name, or by the\\ncombination of signer name and a label selector.\\n\\nKubelet performs aggressive normalization of the PEM contents written\\ninto the pod filesystem.  Esoteric PEM features such as inter-block\\ncomments and block headers are stripped.  Certificates are deduplicated.\\nThe ordering of certificates within the file is arbitrary, and Kubelet\\nmay change the order over time."'),
          clusterTrustBundle: {
            '#labelSelector':: d.obj(help='"Select all ClusterTrustBundles that match this label selector.  Only has\\neffect if signerName is set.  Mutually-exclusive with name.  If unset,\\ninterpreted as \\"match nothing\\".  If set but empty, interpreted as \\"match\\neverything\\"."'),
            labelSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels: matchLabels } } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels+: matchLabels } } },
            },
            '#withName':: d.fn(help='"Select a single ClusterTrustBundle by object name.  Mutually-exclusive\\nwith signerName and labelSelector."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { clusterTrustBundle+: { name: name } },
            '#withOptional':: d.fn(help="\"If true, don't block pod startup if the referenced ClusterTrustBundle(s)\\naren't available.  If using name, then the named ClusterTrustBundle is\\nallowed not to exist.  If using signerName, then the combination of\\nsignerName and labelSelector is allowed to match zero\\nClusterTrustBundles.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { clusterTrustBundle+: { optional: optional } },
            '#withPath':: d.fn(help='"Relative path from the volume root to write the bundle."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { clusterTrustBundle+: { path: path } },
            '#withSignerName':: d.fn(help='"Select all ClusterTrustBundles that match this signer name.\\nMutually-exclusive with name.  The contents of all selected\\nClusterTrustBundles will be unified and deduplicated."', args=[d.arg(name='signerName', type=d.T.string)]),
            withSignerName(signerName): { clusterTrustBundle+: { signerName: signerName } },
          },
          '#configMap':: d.obj(help='"configMap information about the configMap data to project"'),
          configMap: {
            '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
            '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { configMap+: { name: name } },
            '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { configMap+: { optional: optional } },
          },
          '#downwardAPI':: d.obj(help='"downwardAPI information about the downwardAPI data to project"'),
          downwardAPI: {
            '#items':: d.obj(help='"Items is a list of DownwardAPIVolume file"'),
            items: {
              '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
              fieldRef: {
                '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
              },
              '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
              resourceFieldRef: {
                '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                withResource(resource): { resourceFieldRef+: { resource: resource } },
              },
              '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items is a list of DownwardAPIVolume file"', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
            '#withItemsMixin':: d.fn(help='"Items is a list of DownwardAPIVolume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
          },
          '#podCertificate':: d.obj(help="\"Projects an auto-rotating credential bundle (private key and certificate\\nchain) that the pod can use either as a TLS client or server.\\n\\nKubelet generates a private key and uses it to send a\\nPodCertificateRequest to the named signer.  Once the signer approves the\\nrequest and issues a certificate chain, Kubelet writes the key and\\ncertificate chain to the pod filesystem.  The pod does not start until\\ncertificates have been issued for each podCertificate projected volume\\nsource in its spec.\\n\\nKubelet will begin trying to rotate the certificate at the time indicated\\nby the signer using the PodCertificateRequest.Status.BeginRefreshAt\\ntimestamp.\\n\\nKubelet can write a single file, indicated by the credentialBundlePath\\nfield, or separate files, indicated by the keyPath and\\ncertificateChainPath fields.\\n\\nThe credential bundle is a single file in PEM format.  The first PEM\\nentry is the private key (in PKCS#8 format), and the remaining PEM\\nentries are the certificate chain issued by the signer (typically,\\nsigners will return their certificate chain in leaf-to-root order).\\n\\nPrefer using the credential bundle format, since your application code\\ncan read it atomically.  If you use keyPath and certificateChainPath,\\nyour application must make two separate file reads. If these coincide\\nwith a certificate rotation, it is possible that the private key and leaf\\ncertificate you read may not correspond to each other.  Your application\\nwill need to check for this condition, and re-read until they are\\nconsistent.\\n\\nThe named signer controls chooses the format of the certificate it\\nissues; consult the signer implementation's documentation to learn how to\\nuse the certificates it issues.\""),
          podCertificate: {
            '#withCertificateChainPath':: d.fn(help='"Write the certificate chain at this path in the projected volume.\\n\\nMost applications should use credentialBundlePath.  When using keyPath\\nand certificateChainPath, your application needs to check that the key\\nand leaf certificate are consistent, because it is possible to read the\\nfiles mid-rotation."', args=[d.arg(name='certificateChainPath', type=d.T.string)]),
            withCertificateChainPath(certificateChainPath): { podCertificate+: { certificateChainPath: certificateChainPath } },
            '#withCredentialBundlePath':: d.fn(help="\"Write the credential bundle at this path in the projected volume.\\n\\nThe credential bundle is a single file that contains multiple PEM blocks.\\nThe first PEM block is a PRIVATE KEY block, containing a PKCS#8 private\\nkey.\\n\\nThe remaining blocks are CERTIFICATE blocks, containing the issued\\ncertificate chain from the signer (leaf and any intermediates).\\n\\nUsing credentialBundlePath lets your Pod's application code make a single\\natomic read that retrieves a consistent key and certificate chain.  If you\\nproject them to separate files, your application code will need to\\nadditionally check that the leaf certificate was issued to the key.\"", args=[d.arg(name='credentialBundlePath', type=d.T.string)]),
            withCredentialBundlePath(credentialBundlePath): { podCertificate+: { credentialBundlePath: credentialBundlePath } },
            '#withKeyPath':: d.fn(help='"Write the key at this path in the projected volume.\\n\\nMost applications should use credentialBundlePath.  When using keyPath\\nand certificateChainPath, your application needs to check that the key\\nand leaf certificate are consistent, because it is possible to read the\\nfiles mid-rotation."', args=[d.arg(name='keyPath', type=d.T.string)]),
            withKeyPath(keyPath): { podCertificate+: { keyPath: keyPath } },
            '#withKeyType':: d.fn(help='"The type of keypair Kubelet will generate for the pod.\\n\\nValid values are \\"RSA3072\\", \\"RSA4096\\", \\"ECDSAP256\\", \\"ECDSAP384\\",\\n\\"ECDSAP521\\", and \\"ED25519\\"."', args=[d.arg(name='keyType', type=d.T.string)]),
            withKeyType(keyType): { podCertificate+: { keyType: keyType } },
            '#withMaxExpirationSeconds':: d.fn(help='"maxExpirationSeconds is the maximum lifetime permitted for the\\ncertificate.\\n\\nKubelet copies this value verbatim into the PodCertificateRequests it\\ngenerates for this projection.\\n\\nIf omitted, kube-apiserver will set it to 86400(24 hours). kube-apiserver\\nwill reject values shorter than 3600 (1 hour).  The maximum allowable\\nvalue is 7862400 (91 days).\\n\\nThe signer implementation is then free to issue a certificate with any\\nlifetime *shorter* than MaxExpirationSeconds, but no shorter than 3600\\nseconds (1 hour).  This constraint is enforced by kube-apiserver.\\n`kubernetes.io` signers will never issue certificates with a lifetime\\nlonger than 24 hours."', args=[d.arg(name='maxExpirationSeconds', type=d.T.integer)]),
            withMaxExpirationSeconds(maxExpirationSeconds): { podCertificate+: { maxExpirationSeconds: maxExpirationSeconds } },
            '#withSignerName':: d.fn(help="\"Kubelet's generated CSRs will be addressed to this signer.\"", args=[d.arg(name='signerName', type=d.T.string)]),
            withSignerName(signerName): { podCertificate+: { signerName: signerName } },
          },
          '#secret':: d.obj(help='"secret information about the secret data to project"'),
          secret: {
            '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
            '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { secret+: { name: name } },
            '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { secret+: { optional: optional } },
          },
          '#serviceAccountToken':: d.obj(help='"serviceAccountToken is information about the serviceAccountToken data to project"'),
          serviceAccountToken: {
            '#withAudience':: d.fn(help='"audience is the intended audience of the token. A recipient of a token\\nmust identify itself with an identifier specified in the audience of the\\ntoken, and otherwise should reject the token. The audience defaults to the\\nidentifier of the apiserver."', args=[d.arg(name='audience', type=d.T.string)]),
            withAudience(audience): { serviceAccountToken+: { audience: audience } },
            '#withExpirationSeconds':: d.fn(help='"expirationSeconds is the requested duration of validity of the service\\naccount token. As the token approaches expiration, the kubelet volume\\nplugin will proactively rotate the service account token. The kubelet will\\nstart trying to rotate the token if the token is older than 80 percent of\\nits time to live or if the token is older than 24 hours.Defaults to 1 hour\\nand must be at least 10 minutes."', args=[d.arg(name='expirationSeconds', type=d.T.integer)]),
            withExpirationSeconds(expirationSeconds): { serviceAccountToken+: { expirationSeconds: expirationSeconds } },
            '#withPath':: d.fn(help='"path is the path relative to the mount point of the file to project the\\ntoken into."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { serviceAccountToken+: { path: path } },
          },
        },
        '#containers':: d.obj(help='"Configuration for pgBackRest sidecar containers"'),
        containers: {
          '#pgbackrest':: d.obj(help='"Defines the configuration for the pgBackRest sidecar container"'),
          pgbackrest: {
            '#resources':: d.obj(help='"Resource requirements for a sidecar container"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrest+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrest+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrest+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrest+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrest+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrest+: { resources+: { requests+: requests } } } } } } },
            },
          },
          '#pgbackrestConfig':: d.obj(help='"Defines the configuration for the pgBackRest config sidecar container"'),
          pgbackrestConfig: {
            '#resources':: d.obj(help='"Resource requirements for a sidecar container"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrestConfig+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrestConfig+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrestConfig+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrestConfig+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrestConfig+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { containers+: { pgbackrestConfig+: { resources+: { requests+: requests } } } } } } },
            },
          },
        },
        '#env':: d.obj(help='"K8SPG-833"'),
        env: {
          '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
          valueFrom: {
            '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
            configMapKeyRef: {
              '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
            },
            '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
            fieldRef: {
              '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
              withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
              '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
              withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
            },
            '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
            fileKeyRef: {
              '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
              '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
              '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
              '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
            },
            '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
            resourceFieldRef: {
              '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
              withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
              '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
              withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
              '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
              withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
            },
            '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
            secretKeyRef: {
              '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
            },
          },
          '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#envFrom':: d.obj(help='"K8SPG-833"'),
        envFrom: {
          '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
          configMapRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { configMapRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { configMapRef+: { optional: optional } },
          },
          '#secretRef':: d.obj(help='"The Secret to select from"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { secretRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { secretRef+: { optional: optional } },
          },
          '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
          withPrefix(prefix): { prefix: prefix },
        },
        '#initContainer':: d.obj(help=''),
        initContainer: {
          '#containerSecurityContext':: d.obj(help='"SecurityContext holds security configuration that will be applied to a container.\\nSome fields are present in both SecurityContext and PodSecurityContext.  When both\\nare set, the values in SecurityContext take precedence."'),
          containerSecurityContext: {
            '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
            appArmorProfile: {
              '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { appArmorProfile+: { type: type } } } } } } },
            },
            '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
            capabilities: {
              '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
              withAdd(add): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } } } },
              '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
              withAddMixin(add): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } } } },
              '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
              withDrop(drop): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } } } },
              '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
              withDropMixin(drop): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } } } },
            },
            '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seLinuxOptions: {
              '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
              withLevel(level): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { level: level } } } } } } },
              '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
              withRole(role): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { role: role } } } } } } },
              '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { type: type } } } } } } },
              '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
              withUser(user): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { user: user } } } } } } },
            },
            '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seccompProfile: {
              '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { seccompProfile+: { type: type } } } } } } },
            },
            '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
            windowsOptions: {
              '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
              withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } },
              '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
              withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } },
              '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
              withHostProcess(hostProcess): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } },
              '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
              withRunAsUserName(runAsUserName): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } },
            },
            '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
            withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } } } },
            '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
            withPrivileged(privileged): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { privileged: privileged } } } } } },
            '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
            withProcMount(procMount): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { procMount: procMount } } } } } },
            '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
            withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } } } },
            '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
            withRunAsGroup(runAsGroup): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { runAsGroup: runAsGroup } } } } } },
            '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
            withRunAsNonRoot(runAsNonRoot): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { runAsNonRoot: runAsNonRoot } } } } } },
            '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
            withRunAsUser(runAsUser): { spec+: { backups+: { pgbackrest+: { initContainer+: { containerSecurityContext+: { runAsUser: runAsUser } } } } } },
          },
          '#resources':: d.obj(help='"ResourceRequirements describes the compute resource requirements."'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { spec+: { backups+: { pgbackrest+: { initContainer+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { initContainer+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { backups+: { pgbackrest+: { initContainer+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { initContainer+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { backups+: { pgbackrest+: { initContainer+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { initContainer+: { resources+: { requests+: requests } } } } } },
          },
          '#withImage':: d.fn(help='', args=[d.arg(name='image', type=d.T.string)]),
          withImage(image): { spec+: { backups+: { pgbackrest+: { initContainer+: { image: image } } } } },
        },
        '#jobs':: d.obj(help='"Jobs field allows configuration for all backup jobs"'),
        jobs: {
          '#affinity':: d.obj(help='"Scheduling constraints of pgBackRest backup Job pods.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
          affinity: {
            '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
            nodeAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
                preference: {
                  '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                  matchFields: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                  '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                },
                '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
                nodeSelectorTerms: {
                  '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                  matchFields: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                  '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                  '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                  '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                },
                '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                withNodeSelectorTerms(nodeSelectorTerms): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } },
                '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
            '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
            podAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                podAffinityTerm: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                },
                '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { topologyKey: topologyKey },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
            '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
            podAntiAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                podAffinityTerm: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                },
                '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { topologyKey: topologyKey },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { jobs+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
          },
          '#resources':: d.obj(help='"Resource limits for backup jobs. Includes manual, scheduled and replica\\ncreate backups"'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { spec+: { backups+: { pgbackrest+: { jobs+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { jobs+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { backups+: { pgbackrest+: { jobs+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { jobs+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { backups+: { pgbackrest+: { jobs+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { jobs+: { resources+: { requests+: requests } } } } } },
          },
          '#securityContext':: d.obj(help='"SecurityContext defines the security settings for PGBackRest pod."'),
          securityContext: {
            '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
            appArmorProfile: {
              '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { appArmorProfile+: { type: type } } } } } } },
            },
            '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seLinuxOptions: {
              '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
              withLevel(level): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } },
              '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
              withRole(role): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } },
              '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } },
              '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
              withUser(user): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } },
            },
            '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seccompProfile: {
              '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seccompProfile+: { type: type } } } } } } },
            },
            '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
            sysctls: {
              '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
            windowsOptions: {
              '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
              withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } },
              '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
              withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } },
              '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
              withHostProcess(hostProcess): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } },
              '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
              withRunAsUserName(runAsUserName): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } },
            },
            '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
            withFsGroup(fsGroup): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { fsGroup: fsGroup } } } } } },
            '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
            withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } } } } },
            '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
            withRunAsGroup(runAsGroup): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { runAsGroup: runAsGroup } } } } } },
            '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
            withRunAsNonRoot(runAsNonRoot): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } },
            '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
            withRunAsUser(runAsUser): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { runAsUser: runAsUser } } } } } },
            '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
            withSeLinuxChangePolicy(seLinuxChangePolicy): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } } } } } },
            '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
            withSupplementalGroups(supplementalGroups): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } },
            '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
            withSupplementalGroupsMixin(supplementalGroups): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } },
            '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
            withSupplementalGroupsPolicy(supplementalGroupsPolicy): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } } } } } },
            '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
            withSysctls(sysctls): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } },
            '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
            withSysctlsMixin(sysctls): { spec+: { backups+: { pgbackrest+: { jobs+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } },
          },
          '#tolerations':: d.obj(help='"Tolerations of pgBackRest backup Job pods.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
          tolerations: {
            '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
            withEffect(effect): { effect: effect },
            '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
            withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
            '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#withBackoffLimit':: d.fn(help='', args=[d.arg(name='backoffLimit', type=d.T.integer)]),
          withBackoffLimit(backoffLimit): { spec+: { backups+: { pgbackrest+: { jobs+: { backoffLimit: backoffLimit } } } } },
          '#withPriorityClassName':: d.fn(help='"Priority class name for the pgBackRest backup Job pods.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
          withPriorityClassName(priorityClassName): { spec+: { backups+: { pgbackrest+: { jobs+: { priorityClassName: priorityClassName } } } } },
          '#withRestartPolicy':: d.fn(help='"RestartPolicy describes how the container should be restarted.\\nOnly one of the following restart policies may be specified.\\nIf none of the following policies is specified, the default one\\nis RestartPolicyAlways."', args=[d.arg(name='restartPolicy', type=d.T.string)]),
          withRestartPolicy(restartPolicy): { spec+: { backups+: { pgbackrest+: { jobs+: { restartPolicy: restartPolicy } } } } },
          '#withTolerations':: d.fn(help='"Tolerations of pgBackRest backup Job pods.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerations(tolerations): { spec+: { backups+: { pgbackrest+: { jobs+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTolerationsMixin':: d.fn(help='"Tolerations of pgBackRest backup Job pods.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerationsMixin(tolerations): { spec+: { backups+: { pgbackrest+: { jobs+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTtlSecondsAfterFinished':: d.fn(help='"Limit the lifetime of a Job that has finished.\\nMore info: https://kubernetes.io/docs/concepts/workloads/controllers/job"', args=[d.arg(name='ttlSecondsAfterFinished', type=d.T.integer)]),
          withTtlSecondsAfterFinished(ttlSecondsAfterFinished): { spec+: { backups+: { pgbackrest+: { jobs+: { ttlSecondsAfterFinished: ttlSecondsAfterFinished } } } } },
        },
        '#manual':: d.obj(help='"Defines details for manual pgBackRest backup Jobs"'),
        manual: {
          '#withInitialDelaySeconds':: d.fn(help='"InitialDelaySeconds defines the number of seconds to wait before starting the backup.\\nAfter the backup pod is scheduled, its entrypoint will wait for this number of seconds\\nbefore initiating the backup process."', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { spec+: { backups+: { pgbackrest+: { manual+: { initialDelaySeconds: initialDelaySeconds } } } } },
          '#withOptions':: d.fn(help='"Command line options to include when running the pgBackRest backup command.\\nhttps://pgbackrest.org/command.html#command-backup"', args=[d.arg(name='options', type=d.T.array)]),
          withOptions(options): { spec+: { backups+: { pgbackrest+: { manual+: { options: if std.isArray(v=options) then options else [options] } } } } },
          '#withOptionsMixin':: d.fn(help='"Command line options to include when running the pgBackRest backup command.\\nhttps://pgbackrest.org/command.html#command-backup"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
          withOptionsMixin(options): { spec+: { backups+: { pgbackrest+: { manual+: { options+: if std.isArray(v=options) then options else [options] } } } } },
          '#withRepoName':: d.fn(help='"The name of the pgBackRest repo to run the backup command against."', args=[d.arg(name='repoName', type=d.T.string)]),
          withRepoName(repoName): { spec+: { backups+: { pgbackrest+: { manual+: { repoName: repoName } } } } },
        },
        '#metadata':: d.obj(help='"Metadata contains metadata for custom resources"'),
        metadata: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { backups+: { pgbackrest+: { metadata+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { backups+: { pgbackrest+: { metadata+: { annotations+: annotations } } } } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { backups+: { pgbackrest+: { metadata+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { backups+: { pgbackrest+: { metadata+: { labels+: labels } } } } },
        },
        '#repoHost':: d.obj(help='"Defines configuration for a pgBackRest dedicated repository host.  This section is only\\napplicable if at least one \\"volume\\" (i.e. PVC-based) repository is defined in the \\"repos\\"\\nsection, therefore enabling a dedicated repository host Deployment."'),
        repoHost: {
          '#affinity':: d.obj(help='"Scheduling constraints of the Dedicated repo host pod.\\nChanging this value causes repo host to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
          affinity: {
            '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
            nodeAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
                preference: {
                  '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                  matchFields: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                  '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                },
                '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
                nodeSelectorTerms: {
                  '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                  matchFields: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                  '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                  '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                  '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                },
                '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                withNodeSelectorTerms(nodeSelectorTerms): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } },
                '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
            '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
            podAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                podAffinityTerm: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                },
                '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { topologyKey: topologyKey },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
            '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
            podAntiAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                podAffinityTerm: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                },
                '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { topologyKey: topologyKey },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { repoHost+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
          },
          '#resources':: d.obj(help='"Resource requirements for a pgBackRest repository host"'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { spec+: { backups+: { pgbackrest+: { repoHost+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { repoHost+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { backups+: { pgbackrest+: { repoHost+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { repoHost+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { backups+: { pgbackrest+: { repoHost+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { repoHost+: { resources+: { requests+: requests } } } } } },
          },
          '#securityContext':: d.obj(help='"SecurityContext defines the security settings for PGBackRest pod."'),
          securityContext: {
            '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
            appArmorProfile: {
              '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { appArmorProfile+: { type: type } } } } } } },
            },
            '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seLinuxOptions: {
              '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
              withLevel(level): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seLinuxOptions+: { level: level } } } } } } },
              '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
              withRole(role): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seLinuxOptions+: { role: role } } } } } } },
              '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seLinuxOptions+: { type: type } } } } } } },
              '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
              withUser(user): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seLinuxOptions+: { user: user } } } } } } },
            },
            '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seccompProfile: {
              '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } } },
              '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seccompProfile+: { type: type } } } } } } },
            },
            '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
            sysctls: {
              '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
            windowsOptions: {
              '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
              withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } } },
              '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
              withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } } },
              '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
              withHostProcess(hostProcess): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } } },
              '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
              withRunAsUserName(runAsUserName): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } } },
            },
            '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
            withFsGroup(fsGroup): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { fsGroup: fsGroup } } } } } },
            '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
            withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } } } } },
            '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
            withRunAsGroup(runAsGroup): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { runAsGroup: runAsGroup } } } } } },
            '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
            withRunAsNonRoot(runAsNonRoot): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } } },
            '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
            withRunAsUser(runAsUser): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { runAsUser: runAsUser } } } } } },
            '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
            withSeLinuxChangePolicy(seLinuxChangePolicy): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } } } } } },
            '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
            withSupplementalGroups(supplementalGroups): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } },
            '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
            withSupplementalGroupsMixin(supplementalGroups): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } } },
            '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
            withSupplementalGroupsPolicy(supplementalGroupsPolicy): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } } } } } },
            '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
            withSysctls(sysctls): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } },
            '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
            withSysctlsMixin(sysctls): { spec+: { backups+: { pgbackrest+: { repoHost+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } } },
          },
          '#sidecars':: d.obj(help='"Custom sidecars for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."'),
          sidecars: {
            '#env':: d.obj(help='"List of environment variables to set in the container.\\nCannot be updated."'),
            env: {
              '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
              valueFrom: {
                '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
                configMapKeyRef: {
                  '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
                },
                '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
                },
                '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
                fileKeyRef: {
                  '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
                  '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
                  '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
                  '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
                  withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
                },
                '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
                secretKeyRef: {
                  '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                  '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                  '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                  withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
                },
              },
              '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#envFrom':: d.obj(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\""),
            envFrom: {
              '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
              configMapRef: {
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { configMapRef+: { name: name } },
                '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { configMapRef+: { optional: optional } },
              },
              '#secretRef':: d.obj(help='"The Secret to select from"'),
              secretRef: {
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { secretRef+: { name: name } },
                '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { secretRef+: { optional: optional } },
              },
              '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
              withPrefix(prefix): { prefix: prefix },
            },
            '#lifecycle':: d.obj(help='"Actions that the management system should take in response to container lifecycle events.\\nCannot be updated."'),
            lifecycle: {
              '#postStart':: d.obj(help='"PostStart is called immediately after a container is created. If the handler fails,\\nthe container is terminated and restarted according to its restart policy.\\nOther management of the container blocks until the hook completes.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks"'),
              postStart: {
                '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
                exec: {
                  '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                  withCommand(command): { lifecycle+: { postStart+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
                  '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                  withCommandMixin(command): { lifecycle+: { postStart+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
                },
                '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
                httpGet: {
                  '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                  httpHeaders: {
                    '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { name: name },
                    '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                    withValue(value): { value: value },
                  },
                  '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { postStart+: { httpGet+: { host: host } } } },
                  '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeaders(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeadersMixin(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { lifecycle+: { postStart+: { httpGet+: { path: path } } } },
                  '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { postStart+: { httpGet+: { port: port } } } },
                  '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                  withScheme(scheme): { lifecycle+: { postStart+: { httpGet+: { scheme: scheme } } } },
                },
                '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
                sleep: {
                  '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
                  withSeconds(seconds): { lifecycle+: { postStart+: { sleep+: { seconds: seconds } } } },
                },
                '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
                tcpSocket: {
                  '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { postStart+: { tcpSocket+: { host: host } } } },
                  '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { postStart+: { tcpSocket+: { port: port } } } },
                },
              },
              '#preStop':: d.obj(help="\"PreStop is called immediately before a container is terminated due to an\\nAPI request or management event such as liveness/startup probe failure,\\npreemption, resource contention, etc. The handler is not called if the\\ncontainer crashes or exits. The Pod's termination grace period countdown begins before the\\nPreStop hook is executed. Regardless of the outcome of the handler, the\\ncontainer will eventually terminate within the Pod's termination grace\\nperiod (unless delayed by finalizers). Other management of the container blocks until the hook completes\\nor until the termination grace period is reached.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks\""),
              preStop: {
                '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
                exec: {
                  '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                  withCommand(command): { lifecycle+: { preStop+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
                  '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                  withCommandMixin(command): { lifecycle+: { preStop+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
                },
                '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
                httpGet: {
                  '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                  httpHeaders: {
                    '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                    withName(name): { name: name },
                    '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                    withValue(value): { value: value },
                  },
                  '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { preStop+: { httpGet+: { host: host } } } },
                  '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeaders(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                  withHttpHeadersMixin(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                  '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                  withPath(path): { lifecycle+: { preStop+: { httpGet+: { path: path } } } },
                  '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { preStop+: { httpGet+: { port: port } } } },
                  '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                  withScheme(scheme): { lifecycle+: { preStop+: { httpGet+: { scheme: scheme } } } },
                },
                '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
                sleep: {
                  '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
                  withSeconds(seconds): { lifecycle+: { preStop+: { sleep+: { seconds: seconds } } } },
                },
                '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
                tcpSocket: {
                  '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                  withHost(host): { lifecycle+: { preStop+: { tcpSocket+: { host: host } } } },
                  '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                  withPort(port): { lifecycle+: { preStop+: { tcpSocket+: { port: port } } } },
                },
              },
              '#withStopSignal':: d.fn(help='"StopSignal defines which signal will be sent to a container when it is being stopped.\\nIf not specified, the default is defined by the container runtime in use.\\nStopSignal can only be set for Pods with a non-empty .spec.os.name"', args=[d.arg(name='stopSignal', type=d.T.string)]),
              withStopSignal(stopSignal): { lifecycle+: { stopSignal: stopSignal } },
            },
            '#livenessProbe':: d.obj(help='"Periodic probe of container liveness.\\nContainer will be restarted if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
            livenessProbe: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { livenessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { livenessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
              },
              '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
              grpc: {
                '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { livenessProbe+: { grpc+: { port: port } } },
                '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
                withService(service): { livenessProbe+: { grpc+: { service: service } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { livenessProbe+: { httpGet+: { host: host } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { livenessProbe+: { httpGet+: { path: path } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { livenessProbe+: { httpGet+: { port: port } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { livenessProbe+: { httpGet+: { scheme: scheme } } },
              },
              '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { livenessProbe+: { tcpSocket+: { host: host } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { livenessProbe+: { tcpSocket+: { port: port } } },
              },
              '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
              withFailureThreshold(failureThreshold): { livenessProbe+: { failureThreshold: failureThreshold } },
              '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
              withInitialDelaySeconds(initialDelaySeconds): { livenessProbe+: { initialDelaySeconds: initialDelaySeconds } },
              '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
              withPeriodSeconds(periodSeconds): { livenessProbe+: { periodSeconds: periodSeconds } },
              '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
              withSuccessThreshold(successThreshold): { livenessProbe+: { successThreshold: successThreshold } },
              '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
              withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { livenessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
              '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { livenessProbe+: { timeoutSeconds: timeoutSeconds } },
            },
            '#ports':: d.obj(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."'),
            ports: {
              '#withContainerPort':: d.fn(help="\"Number of port to expose on the pod's IP address.\\nThis must be a valid port number, 0 \u003c x \u003c 65536.\"", args=[d.arg(name='containerPort', type=d.T.integer)]),
              withContainerPort(containerPort): { containerPort: containerPort },
              '#withHostIP':: d.fn(help='"What host IP to bind the external port to."', args=[d.arg(name='hostIP', type=d.T.string)]),
              withHostIP(hostIP): { hostIP: hostIP },
              '#withHostPort':: d.fn(help='"Number of port to expose on the host.\\nIf specified, this must be a valid port number, 0 < x < 65536.\\nIf HostNetwork is specified, this must match ContainerPort.\\nMost containers do not need this."', args=[d.arg(name='hostPort', type=d.T.integer)]),
              withHostPort(hostPort): { hostPort: hostPort },
              '#withName':: d.fn(help='"If specified, this must be an IANA_SVC_NAME and unique within the pod. Each\\nnamed port in a pod must have a unique name. Name for the port that can be\\nreferred to by services."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withProtocol':: d.fn(help='"Protocol for port. Must be UDP, TCP, or SCTP.\\nDefaults to \\"TCP\\"."', args=[d.arg(name='protocol', type=d.T.string)]),
              withProtocol(protocol): { protocol: protocol },
            },
            '#readinessProbe':: d.obj(help='"Periodic probe of container service readiness.\\nContainer will be removed from service endpoints if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
            readinessProbe: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { readinessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { readinessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
              },
              '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
              grpc: {
                '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { readinessProbe+: { grpc+: { port: port } } },
                '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
                withService(service): { readinessProbe+: { grpc+: { service: service } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { readinessProbe+: { httpGet+: { host: host } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { readinessProbe+: { httpGet+: { path: path } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { readinessProbe+: { httpGet+: { port: port } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { readinessProbe+: { httpGet+: { scheme: scheme } } },
              },
              '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { readinessProbe+: { tcpSocket+: { host: host } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { readinessProbe+: { tcpSocket+: { port: port } } },
              },
              '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
              withFailureThreshold(failureThreshold): { readinessProbe+: { failureThreshold: failureThreshold } },
              '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
              withInitialDelaySeconds(initialDelaySeconds): { readinessProbe+: { initialDelaySeconds: initialDelaySeconds } },
              '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
              withPeriodSeconds(periodSeconds): { readinessProbe+: { periodSeconds: periodSeconds } },
              '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
              withSuccessThreshold(successThreshold): { readinessProbe+: { successThreshold: successThreshold } },
              '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
              withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { readinessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
              '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { readinessProbe+: { timeoutSeconds: timeoutSeconds } },
            },
            '#resizePolicy':: d.obj(help='"Resources resize policy for the container."'),
            resizePolicy: {
              '#withResourceName':: d.fn(help='"Name of the resource to which this resource resize policy applies.\\nSupported values: cpu, memory."', args=[d.arg(name='resourceName', type=d.T.string)]),
              withResourceName(resourceName): { resourceName: resourceName },
              '#withRestartPolicy':: d.fn(help='"Restart policy to apply when specified resource is resized.\\nIf not specified, it defaults to NotRequired."', args=[d.arg(name='restartPolicy', type=d.T.string)]),
              withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
            },
            '#resources':: d.obj(help='"Compute Resources required by this container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { resources+: { limits: limits } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { resources+: { limits+: limits } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { resources+: { requests: requests } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { resources+: { requests+: requests } },
            },
            '#restartPolicyRules':: d.obj(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\""),
            restartPolicyRules: {
              '#exitCodes':: d.obj(help='"Represents the exit codes to check on container exits."'),
              exitCodes: {
                '#withOperator':: d.fn(help='"Represents the relationship between the container exit code(s) and the\\nspecified values. Possible values are:\\n- In: the requirement is satisfied if the container exit code is in the\\n  set of specified values.\\n- NotIn: the requirement is satisfied if the container exit code is\\n  not in the set of specified values."', args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { exitCodes+: { operator: operator } },
                '#withValues':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { exitCodes+: { values: if std.isArray(v=values) then values else [values] } },
                '#withValuesMixin':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { exitCodes+: { values+: if std.isArray(v=values) then values else [values] } },
              },
              '#withAction':: d.fn(help='"Specifies the action taken on a container exit if the requirements\\nare satisfied. The only possible value is \\"Restart\\" to restart the\\ncontainer."', args=[d.arg(name='action', type=d.T.string)]),
              withAction(action): { action: action },
            },
            '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
            securityContext: {
              '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
              appArmorProfile: {
                '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
                '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
              },
              '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
              capabilities: {
                '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
                withAdd(add): { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
                '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
                withAddMixin(add): { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
                '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
                withDrop(drop): { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
                '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
                withDropMixin(drop): { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
              },
              '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seLinuxOptions: {
                '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
                withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
                '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
                withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
                '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
                '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
                withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
              },
              '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
              seccompProfile: {
                '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
                withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
                '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
                withType(type): { securityContext+: { seccompProfile+: { type: type } } },
              },
              '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
              windowsOptions: {
                '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
                withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
                '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
                withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
                '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
                withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
                '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
                withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
              },
              '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
              withAllowPrivilegeEscalation(allowPrivilegeEscalation): { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } },
              '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
              withPrivileged(privileged): { securityContext+: { privileged: privileged } },
              '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
              withProcMount(procMount): { securityContext+: { procMount: procMount } },
              '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
              withReadOnlyRootFilesystem(readOnlyRootFilesystem): { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } },
              '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
              withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
              '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
              withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
              '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
              withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
            },
            '#startupProbe':: d.obj(help="\"StartupProbe indicates that the Pod has successfully initialized.\\nIf specified, no other probes are executed until this completes successfully.\\nIf this probe fails, the Pod will be restarted, just as if the livenessProbe failed.\\nThis can be used to provide different probe parameters at the beginning of a Pod's lifecycle,\\nwhen it might take a long time to load data or warm a cache, than during steady-state operation.\\nThis cannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes\""),
            startupProbe: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { startupProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { startupProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
              },
              '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
              grpc: {
                '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
                withPort(port): { startupProbe+: { grpc+: { port: port } } },
                '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
                withService(service): { startupProbe+: { grpc+: { service: service } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { startupProbe+: { httpGet+: { host: host } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { startupProbe+: { httpGet+: { path: path } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { startupProbe+: { httpGet+: { port: port } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { startupProbe+: { httpGet+: { scheme: scheme } } },
              },
              '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { startupProbe+: { tcpSocket+: { host: host } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { startupProbe+: { tcpSocket+: { port: port } } },
              },
              '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
              withFailureThreshold(failureThreshold): { startupProbe+: { failureThreshold: failureThreshold } },
              '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
              withInitialDelaySeconds(initialDelaySeconds): { startupProbe+: { initialDelaySeconds: initialDelaySeconds } },
              '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
              withPeriodSeconds(periodSeconds): { startupProbe+: { periodSeconds: periodSeconds } },
              '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
              withSuccessThreshold(successThreshold): { startupProbe+: { successThreshold: successThreshold } },
              '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
              withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { startupProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
              '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
              withTimeoutSeconds(timeoutSeconds): { startupProbe+: { timeoutSeconds: timeoutSeconds } },
            },
            '#volumeDevices':: d.obj(help='"volumeDevices is the list of block devices to be used by the container."'),
            volumeDevices: {
              '#withDevicePath':: d.fn(help='"devicePath is the path inside of the container that the device will be mapped to."', args=[d.arg(name='devicePath', type=d.T.string)]),
              withDevicePath(devicePath): { devicePath: devicePath },
              '#withName':: d.fn(help='"name must match the name of a persistentVolumeClaim in the pod"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
            },
            '#volumeMounts':: d.obj(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\""),
            volumeMounts: {
              '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
              withMountPath(mountPath): { mountPath: mountPath },
              '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
              withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
              '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
              withReadOnly(readOnly): { readOnly: readOnly },
              '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
              withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
              '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
              withSubPath(subPath): { subPath: subPath },
              '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
              withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
            },
            '#withArgs':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='args', type=d.T.array)]),
            withArgs(args): { args: if std.isArray(v=args) then args else [args] },
            '#withArgsMixin':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
            withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
            '#withCommand':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { command: if std.isArray(v=command) then command else [command] },
            '#withCommandMixin':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { command+: if std.isArray(v=command) then command else [command] },
            '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."', args=[d.arg(name='env', type=d.T.array)]),
            withEnv(env): { env: if std.isArray(v=env) then env else [env] },
            '#withEnvFrom':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"", args=[d.arg(name='envFrom', type=d.T.array)]),
            withEnvFrom(envFrom): { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] },
            '#withEnvFromMixin':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='envFrom', type=d.T.array)]),
            withEnvFromMixin(envFrom): { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] },
            '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
            withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
            '#withImage':: d.fn(help='"Container image name.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='image', type=d.T.string)]),
            withImage(image): { image: image },
            '#withImagePullPolicy':: d.fn(help='"Image pull policy.\\nOne of Always, Never, IfNotPresent.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#updating-images"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
            withImagePullPolicy(imagePullPolicy): { imagePullPolicy: imagePullPolicy },
            '#withName':: d.fn(help='"Name of the container specified as a DNS_LABEL.\\nEach container in a pod must have a unique name (DNS_LABEL).\\nCannot be updated."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withPorts':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."', args=[d.arg(name='ports', type=d.T.array)]),
            withPorts(ports): { ports: if std.isArray(v=ports) then ports else [ports] },
            '#withPortsMixin':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
            withPortsMixin(ports): { ports+: if std.isArray(v=ports) then ports else [ports] },
            '#withResizePolicy':: d.fn(help='"Resources resize policy for the container."', args=[d.arg(name='resizePolicy', type=d.T.array)]),
            withResizePolicy(resizePolicy): { resizePolicy: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
            '#withResizePolicyMixin':: d.fn(help='"Resources resize policy for the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resizePolicy', type=d.T.array)]),
            withResizePolicyMixin(resizePolicy): { resizePolicy+: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
            '#withRestartPolicy':: d.fn(help="\"RestartPolicy defines the restart behavior of individual containers in a pod.\\nThis overrides the pod-level restart policy. When this field is not specified,\\nthe restart behavior is defined by the Pod's restart policy and the container type.\\nAdditionally, setting the RestartPolicy as \\\"Always\\\" for the init container will\\nhave the following effect:\\nthis init container will be continually restarted on\\nexit until all regular containers have terminated. Once all regular\\ncontainers have completed, all init containers with restartPolicy \\\"Always\\\"\\nwill be shut down. This lifecycle differs from normal init containers and\\nis often referred to as a \\\"sidecar\\\" container. Although this init\\ncontainer still starts in the init container sequence, it does not wait\\nfor the container to complete before proceeding to the next init\\ncontainer. Instead, the next init container starts immediately after this\\ninit container is started, or after any startupProbe has successfully\\ncompleted.\"", args=[d.arg(name='restartPolicy', type=d.T.string)]),
            withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
            '#withRestartPolicyRules':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
            withRestartPolicyRules(restartPolicyRules): { restartPolicyRules: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
            '#withRestartPolicyRulesMixin':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
            withRestartPolicyRulesMixin(restartPolicyRules): { restartPolicyRules+: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
            '#withStdin':: d.fn(help='"Whether this container should allocate a buffer for stdin in the container runtime. If this\\nis not set, reads from stdin in the container will always result in EOF.\\nDefault is false."', args=[d.arg(name='stdin', type=d.T.boolean)]),
            withStdin(stdin): { stdin: stdin },
            '#withStdinOnce':: d.fn(help='"Whether the container runtime should close the stdin channel after it has been opened by\\na single attach. When stdin is true the stdin stream will remain open across multiple attach\\nsessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the\\nfirst client attaches to stdin, and then remains open and accepts data until the client disconnects,\\nat which time stdin is closed and remains closed until the container is restarted. If this\\nflag is false, a container processes that reads from stdin will never receive an EOF.\\nDefault is false"', args=[d.arg(name='stdinOnce', type=d.T.boolean)]),
            withStdinOnce(stdinOnce): { stdinOnce: stdinOnce },
            '#withTerminationMessagePath':: d.fn(help="\"Optional: Path at which the file to which the container's termination message\\nwill be written is mounted into the container's filesystem.\\nMessage written is intended to be brief final status, such as an assertion failure message.\\nWill be truncated by the node if greater than 4096 bytes. The total message length across\\nall containers will be limited to 12kb.\\nDefaults to /dev/termination-log.\\nCannot be updated.\"", args=[d.arg(name='terminationMessagePath', type=d.T.string)]),
            withTerminationMessagePath(terminationMessagePath): { terminationMessagePath: terminationMessagePath },
            '#withTerminationMessagePolicy':: d.fn(help='"Indicate how the termination message should be populated. File will use the contents of\\nterminationMessagePath to populate the container status message on both success and failure.\\nFallbackToLogsOnError will use the last chunk of container log output if the termination\\nmessage file is empty and the container exited with an error.\\nThe log output is limited to 2048 bytes or 80 lines, whichever is smaller.\\nDefaults to File.\\nCannot be updated."', args=[d.arg(name='terminationMessagePolicy', type=d.T.string)]),
            withTerminationMessagePolicy(terminationMessagePolicy): { terminationMessagePolicy: terminationMessagePolicy },
            '#withTty':: d.fn(help="\"Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.\\nDefault is false.\"", args=[d.arg(name='tty', type=d.T.boolean)]),
            withTty(tty): { tty: tty },
            '#withVolumeDevices':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."', args=[d.arg(name='volumeDevices', type=d.T.array)]),
            withVolumeDevices(volumeDevices): { volumeDevices: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
            '#withVolumeDevicesMixin':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeDevices', type=d.T.array)]),
            withVolumeDevicesMixin(volumeDevices): { volumeDevices+: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
            '#withVolumeMounts':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMounts(volumeMounts): { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
            '#withVolumeMountsMixin':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
            withVolumeMountsMixin(volumeMounts): { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
            '#withWorkingDir':: d.fn(help="\"Container's working directory.\\nIf not specified, the container runtime's default will be used, which\\nmight be configured in the container image.\\nCannot be updated.\"", args=[d.arg(name='workingDir', type=d.T.string)]),
            withWorkingDir(workingDir): { workingDir: workingDir },
          },
          '#sshConfigMap':: d.obj(help='"ConfigMap containing custom SSH configuration.\\nDeprecated: Repository hosts use mTLS for encryption, authentication, and authorization."'),
          sshConfigMap: {
            '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshConfigMap+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshConfigMap+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshConfigMap+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshConfigMap+: { optional: optional } } } } } },
          },
          '#sshSecret':: d.obj(help='"Secret containing custom SSH keys.\\nDeprecated: Repository hosts use mTLS for encryption, authentication, and authorization."'),
          sshSecret: {
            '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshSecret+: { items: if std.isArray(v=items) then items else [items] } } } } } },
            '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshSecret+: { items+: if std.isArray(v=items) then items else [items] } } } } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshSecret+: { name: name } } } } } },
            '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { spec+: { backups+: { pgbackrest+: { repoHost+: { sshSecret+: { optional: optional } } } } } },
          },
          '#tolerations':: d.obj(help='"Tolerations of a PgBackRest repo host pod. Changing this value causes a restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
          tolerations: {
            '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
            withEffect(effect): { effect: effect },
            '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
            withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
            '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#topologySpreadConstraints':: d.obj(help='"Topology spread constraints of a Dedicated repo host pod. Changing this\\nvalue causes the repo host to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"'),
          topologySpreadConstraints: {
            '#labelSelector':: d.obj(help='"LabelSelector is used to find matching pods.\\nPods that match this label selector are counted to determine the number of pods\\nin their corresponding topology domain."'),
            labelSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
            },
            '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
            withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
            '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
            withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
            '#withMaxSkew':: d.fn(help="\"MaxSkew describes the degree to which pods may be unevenly distributed.\\nWhen `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference\\nbetween the number of matching pods in the target topology and the global minimum.\\nThe global minimum is the minimum number of matching pods in an eligible domain\\nor zero if the number of eligible domains is less than MinDomains.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 2/2/1:\\nIn this case, the global minimum is 1.\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |   P   |\\n- if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;\\nscheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)\\nviolate MaxSkew(1).\\n- if MaxSkew is 2, incoming pod can be scheduled onto any zone.\\nWhen `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence\\nto topologies that satisfy it.\\nIt's a required field. Default value is 1 and 0 is not allowed.\"", args=[d.arg(name='maxSkew', type=d.T.integer)]),
            withMaxSkew(maxSkew): { maxSkew: maxSkew },
            '#withMinDomains':: d.fn(help="\"MinDomains indicates a minimum number of eligible domains.\\nWhen the number of eligible domains with matching topology keys is less than minDomains,\\nPod Topology Spread treats \\\"global minimum\\\" as 0, and then the calculation of Skew is performed.\\nAnd when the number of eligible domains with matching topology keys equals or greater than minDomains,\\nthis value has no effect on scheduling.\\nAs a result, when the number of eligible domains is less than minDomains,\\nscheduler won't schedule more than maxSkew Pods to those domains.\\nIf value is nil, the constraint behaves as if MinDomains is equal to 1.\\nValid values are integers greater than 0.\\nWhen value is not nil, WhenUnsatisfiable must be DoNotSchedule.\\n\\nFor example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same\\nlabelSelector spread as 2/2/2:\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |  P P  |\\nThe number of domains is less than 5(MinDomains), so \\\"global minimum\\\" is treated as 0.\\nIn this situation, new pod with the same labelSelector cannot be scheduled,\\nbecause computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,\\nit will violate MaxSkew.\"", args=[d.arg(name='minDomains', type=d.T.integer)]),
            withMinDomains(minDomains): { minDomains: minDomains },
            '#withNodeAffinityPolicy':: d.fn(help="\"NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector\\nwhen calculating pod topology spread skew. Options are:\\n- Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.\\n- Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.\\n\\nIf this value is nil, the behavior is equivalent to the Honor policy.\"", args=[d.arg(name='nodeAffinityPolicy', type=d.T.string)]),
            withNodeAffinityPolicy(nodeAffinityPolicy): { nodeAffinityPolicy: nodeAffinityPolicy },
            '#withNodeTaintsPolicy':: d.fn(help='"NodeTaintsPolicy indicates how we will treat node taints when calculating\\npod topology spread skew. Options are:\\n- Honor: nodes without taints, along with tainted nodes for which the incoming pod\\nhas a toleration, are included.\\n- Ignore: node taints are ignored. All nodes are included.\\n\\nIf this value is nil, the behavior is equivalent to the Ignore policy."', args=[d.arg(name='nodeTaintsPolicy', type=d.T.string)]),
            withNodeTaintsPolicy(nodeTaintsPolicy): { nodeTaintsPolicy: nodeTaintsPolicy },
            '#withTopologyKey':: d.fn(help="\"TopologyKey is the key of node labels. Nodes that have a label with this key\\nand identical values are considered to be in the same topology.\\nWe consider each \u003ckey, value\u003e as a \\\"bucket\\\", and try to put balanced number\\nof pods into each bucket.\\nWe define a domain as a particular instance of a topology.\\nAlso, we define an eligible domain as a domain whose nodes meet the requirements of\\nnodeAffinityPolicy and nodeTaintsPolicy.\\ne.g. If TopologyKey is \\\"kubernetes.io/hostname\\\", each Node is a domain of that topology.\\nAnd, if TopologyKey is \\\"topology.kubernetes.io/zone\\\", each zone is a domain of that topology.\\nIt's a required field.\"", args=[d.arg(name='topologyKey', type=d.T.string)]),
            withTopologyKey(topologyKey): { topologyKey: topologyKey },
            '#withWhenUnsatisfiable':: d.fn(help="\"WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy\\nthe spread constraint.\\n- DoNotSchedule (default) tells the scheduler not to schedule it.\\n- ScheduleAnyway tells the scheduler to schedule the pod in any location,\\n  but giving higher precedence to topologies that would help reduce the\\n  skew.\\nA constraint is considered \\\"Unsatisfiable\\\" for an incoming pod\\nif and only if every possible node assignment for that pod would violate\\n\\\"MaxSkew\\\" on some topology.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 3/1/1:\\n| zone1 | zone2 | zone3 |\\n| P P P |   P   |   P   |\\nIf WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled\\nto zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies\\nMaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler\\nwon't make it *more* imbalanced.\\nIt's a required field.\"", args=[d.arg(name='whenUnsatisfiable', type=d.T.string)]),
            withWhenUnsatisfiable(whenUnsatisfiable): { whenUnsatisfiable: whenUnsatisfiable },
          },
          '#withPriorityClassName':: d.fn(help='"Priority class name for the pgBackRest repo host pod. Changing this value\\ncauses PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
          withPriorityClassName(priorityClassName): { spec+: { backups+: { pgbackrest+: { repoHost+: { priorityClassName: priorityClassName } } } } },
          '#withSidecars':: d.fn(help='"Custom sidecars for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."', args=[d.arg(name='sidecars', type=d.T.array)]),
          withSidecars(sidecars): { spec+: { backups+: { pgbackrest+: { repoHost+: { sidecars: if std.isArray(v=sidecars) then sidecars else [sidecars] } } } } },
          '#withSidecarsMixin':: d.fn(help='"Custom sidecars for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sidecars', type=d.T.array)]),
          withSidecarsMixin(sidecars): { spec+: { backups+: { pgbackrest+: { repoHost+: { sidecars+: if std.isArray(v=sidecars) then sidecars else [sidecars] } } } } },
          '#withTolerations':: d.fn(help='"Tolerations of a PgBackRest repo host pod. Changing this value causes a restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerations(tolerations): { spec+: { backups+: { pgbackrest+: { repoHost+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTolerationsMixin':: d.fn(help='"Tolerations of a PgBackRest repo host pod. Changing this value causes a restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerationsMixin(tolerations): { spec+: { backups+: { pgbackrest+: { repoHost+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTopologySpreadConstraints':: d.fn(help='"Topology spread constraints of a Dedicated repo host pod. Changing this\\nvalue causes the repo host to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
          withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { backups+: { pgbackrest+: { repoHost+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } } },
          '#withTopologySpreadConstraintsMixin':: d.fn(help='"Topology spread constraints of a Dedicated repo host pod. Changing this\\nvalue causes the repo host to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
          withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { backups+: { pgbackrest+: { repoHost+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } } },
        },
        '#repos':: d.obj(help='"Defines a pgBackRest repository"'),
        repos: {
          '#azure':: d.obj(help='"Represents a pgBackRest repository that is created using Azure storage"'),
          azure: {
            '#withContainer':: d.fn(help='"The Azure container utilized for the repository"', args=[d.arg(name='container', type=d.T.string)]),
            withContainer(container): { azure+: { container: container } },
          },
          '#gcs':: d.obj(help='"Represents a pgBackRest repository that is created using Google Cloud Storage"'),
          gcs: {
            '#withBucket':: d.fn(help='"The GCS bucket utilized for the repository"', args=[d.arg(name='bucket', type=d.T.string)]),
            withBucket(bucket): { gcs+: { bucket: bucket } },
          },
          '#s3':: d.obj(help='"RepoS3 represents a pgBackRest repository that is created using AWS S3 (or S3-compatible)\\nstorage"'),
          s3: {
            '#withBucket':: d.fn(help='"The S3 bucket utilized for the repository"', args=[d.arg(name='bucket', type=d.T.string)]),
            withBucket(bucket): { s3+: { bucket: bucket } },
            '#withEndpoint':: d.fn(help='"A valid endpoint corresponding to the specified region"', args=[d.arg(name='endpoint', type=d.T.string)]),
            withEndpoint(endpoint): { s3+: { endpoint: endpoint } },
            '#withRegion':: d.fn(help='"The region corresponding to the S3 bucket"', args=[d.arg(name='region', type=d.T.string)]),
            withRegion(region): { s3+: { region: region } },
          },
          '#schedules':: d.obj(help='"Defines the schedules for the pgBackRest backups\\nFull, Differential and Incremental backup types are supported:\\nhttps://pgbackrest.org/user-guide.html#concept/backup"'),
          schedules: {
            '#withDifferential':: d.fn(help='"Defines the Cron schedule for a differential pgBackRest backup.\\nFollows the standard Cron schedule syntax:\\nhttps://k8s.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax"', args=[d.arg(name='differential', type=d.T.string)]),
            withDifferential(differential): { schedules+: { differential: differential } },
            '#withFull':: d.fn(help='"Defines the Cron schedule for a full pgBackRest backup.\\nFollows the standard Cron schedule syntax:\\nhttps://k8s.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax"', args=[d.arg(name='full', type=d.T.string)]),
            withFull(full): { schedules+: { full: full } },
            '#withIncremental':: d.fn(help='"Defines the Cron schedule for an incremental pgBackRest backup.\\nFollows the standard Cron schedule syntax:\\nhttps://k8s.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax"', args=[d.arg(name='incremental', type=d.T.string)]),
            withIncremental(incremental): { schedules+: { incremental: incremental } },
          },
          '#volume':: d.obj(help='"Represents a pgBackRest repository that is created using a PersistentVolumeClaim"'),
          volume: {
            '#volumeClaimSpec':: d.obj(help='"Defines a PersistentVolumeClaim spec used to create and/or bind a volume"'),
            volumeClaimSpec: {
              '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
              dataSource: {
                '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                withApiGroup(apiGroup): { volume+: { volumeClaimSpec+: { dataSource+: { apiGroup: apiGroup } } } },
                '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { volume+: { volumeClaimSpec+: { dataSource+: { kind: kind } } } },
                '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { volume+: { volumeClaimSpec+: { dataSource+: { name: name } } } },
              },
              '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
              dataSourceRef: {
                '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                withApiGroup(apiGroup): { volume+: { volumeClaimSpec+: { dataSourceRef+: { apiGroup: apiGroup } } } },
                '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { volume+: { volumeClaimSpec+: { dataSourceRef+: { kind: kind } } } },
                '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { volume+: { volumeClaimSpec+: { dataSourceRef+: { name: name } } } },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { volume+: { volumeClaimSpec+: { dataSourceRef+: { namespace: namespace } } } },
              },
              '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
              resources: {
                '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
                withLimits(limits): { volume+: { volumeClaimSpec+: { resources+: { limits: limits } } } },
                '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
                withLimitsMixin(limits): { volume+: { volumeClaimSpec+: { resources+: { limits+: limits } } } },
                '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
                withRequests(requests): { volume+: { volumeClaimSpec+: { resources+: { requests: requests } } } },
                '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
                withRequestsMixin(requests): { volume+: { volumeClaimSpec+: { resources+: { requests+: requests } } } },
              },
              '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
              selector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { volume+: { volumeClaimSpec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { volume+: { volumeClaimSpec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { volume+: { volumeClaimSpec+: { selector+: { matchLabels: matchLabels } } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { volume+: { volumeClaimSpec+: { selector+: { matchLabels+: matchLabels } } } },
              },
              '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
              withAccessModes(accessModes): { volume+: { volumeClaimSpec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } },
              '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
              withAccessModesMixin(accessModes): { volume+: { volumeClaimSpec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } },
              '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
              withStorageClassName(storageClassName): { volume+: { volumeClaimSpec+: { storageClassName: storageClassName } } },
              '#withVolumeAttributesClassName':: d.fn(help='"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string or nil value indicates that no\\nVolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,\\nthis field can be reset to its previous value (including nil) to cancel the modification.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/"', args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
              withVolumeAttributesClassName(volumeAttributesClassName): { volume+: { volumeClaimSpec+: { volumeAttributesClassName: volumeAttributesClassName } } },
              '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
              withVolumeMode(volumeMode): { volume+: { volumeClaimSpec+: { volumeMode: volumeMode } } },
              '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { volume+: { volumeClaimSpec+: { volumeName: volumeName } } },
            },
          },
          '#withName':: d.fn(help='"The name of the repository"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#restore':: d.obj(help='"Defines details for performing an in-place restore using pgBackRest"'),
        restore: {
          '#affinity':: d.obj(help='"Scheduling constraints of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
          affinity: {
            '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
            nodeAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
                preference: {
                  '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                  matchFields: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                  '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                },
                '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
                nodeSelectorTerms: {
                  '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                  matchFields: {
                    '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                  '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                  '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                  '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                  withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                },
                '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                withNodeSelectorTerms(nodeSelectorTerms): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } },
                '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
                withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } } },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
            '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
            podAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                podAffinityTerm: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                },
                '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { topologyKey: topologyKey },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
            '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
            podAntiAffinity: {
              '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
              preferredDuringSchedulingIgnoredDuringExecution: {
                '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
                podAffinityTerm: {
                  '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                  labelSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                  namespaceSelector: {
                    '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                    matchExpressions: {
                      '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                      withKey(key): { key: key },
                      '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                      withOperator(operator): { operator: operator },
                      '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                      withValues(values): { values: if std.isArray(v=values) then values else [values] },
                      '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                      withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                    },
                    '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                    withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                    '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                    '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                    withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                  },
                  '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                  withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                  '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                  withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                  '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                  withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                  '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                  withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
                },
                '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
                withWeight(weight): { weight: weight },
              },
              '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
              requiredDuringSchedulingIgnoredDuringExecution: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { topologyKey: topologyKey },
              },
              '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
              '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
              withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { backups+: { pgbackrest+: { restore+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } } },
            },
          },
          '#resources':: d.obj(help='"Resource requirements for the pgBackRest restore Job."'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { spec+: { backups+: { pgbackrest+: { restore+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { restore+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { spec+: { backups+: { pgbackrest+: { restore+: { resources+: { limits: limits } } } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { restore+: { resources+: { limits+: limits } } } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { spec+: { backups+: { pgbackrest+: { restore+: { resources+: { requests: requests } } } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { restore+: { resources+: { requests+: requests } } } } } },
          },
          '#tolerations':: d.obj(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
          tolerations: {
            '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
            withEffect(effect): { effect: effect },
            '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
            withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
            '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#withClusterName':: d.fn(help='"The name of an existing PostgresCluster to use as the data source for the new PostgresCluster.\\nDefaults to the name of the PostgresCluster being created if not provided."', args=[d.arg(name='clusterName', type=d.T.string)]),
          withClusterName(clusterName): { spec+: { backups+: { pgbackrest+: { restore+: { clusterName: clusterName } } } } },
          '#withClusterNamespace':: d.fn(help='"The namespace of the cluster specified as the data source using the clusterName field.\\nDefaults to the namespace of the PostgresCluster being created if not provided."', args=[d.arg(name='clusterNamespace', type=d.T.string)]),
          withClusterNamespace(clusterNamespace): { spec+: { backups+: { pgbackrest+: { restore+: { clusterNamespace: clusterNamespace } } } } },
          '#withEnabled':: d.fn(help='"Whether or not in-place pgBackRest restores are enabled for this PostgresCluster."', args=[d.arg(name='enabled', type=d.T.boolean)]),
          withEnabled(enabled): { spec+: { backups+: { pgbackrest+: { restore+: { enabled: enabled } } } } },
          '#withOptions':: d.fn(help='"Command line options to include when running the pgBackRest restore command.\\nhttps://pgbackrest.org/command.html#command-restore"', args=[d.arg(name='options', type=d.T.array)]),
          withOptions(options): { spec+: { backups+: { pgbackrest+: { restore+: { options: if std.isArray(v=options) then options else [options] } } } } },
          '#withOptionsMixin':: d.fn(help='"Command line options to include when running the pgBackRest restore command.\\nhttps://pgbackrest.org/command.html#command-restore"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
          withOptionsMixin(options): { spec+: { backups+: { pgbackrest+: { restore+: { options+: if std.isArray(v=options) then options else [options] } } } } },
          '#withPriorityClassName':: d.fn(help='"Priority class name for the pgBackRest restore Job pod. Changing this\\nvalue causes PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
          withPriorityClassName(priorityClassName): { spec+: { backups+: { pgbackrest+: { restore+: { priorityClassName: priorityClassName } } } } },
          '#withRepoName':: d.fn(help='"The name of the pgBackRest repo within the source PostgresCluster that contains the backups\\nthat should be utilized to perform a pgBackRest restore when initializing the data source\\nfor the new PostgresCluster."', args=[d.arg(name='repoName', type=d.T.string)]),
          withRepoName(repoName): { spec+: { backups+: { pgbackrest+: { restore+: { repoName: repoName } } } } },
          '#withTolerations':: d.fn(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerations(tolerations): { spec+: { backups+: { pgbackrest+: { restore+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTolerationsMixin':: d.fn(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerationsMixin(tolerations): { spec+: { backups+: { pgbackrest+: { restore+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
        },
        '#sidecars':: d.obj(help='"Deprecated: Use Containers instead"'),
        sidecars: {
          '#pgbackrest':: d.obj(help='"Defines the configuration for the pgBackRest sidecar container"'),
          pgbackrest: {
            '#resources':: d.obj(help='"Resource requirements for a sidecar container"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrest+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrest+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrest+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrest+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrest+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrest+: { resources+: { requests+: requests } } } } } } },
            },
          },
          '#pgbackrestConfig':: d.obj(help='"Defines the configuration for the pgBackRest config sidecar container"'),
          pgbackrestConfig: {
            '#resources':: d.obj(help='"Resource requirements for a sidecar container"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrestConfig+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrestConfig+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrestConfig+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrestConfig+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrestConfig+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { backups+: { pgbackrest+: { sidecars+: { pgbackrestConfig+: { resources+: { requests+: requests } } } } } } },
            },
          },
        },
        '#withConfiguration':: d.fn(help='"Projected volumes containing custom pgBackRest configuration.  These files are mounted\\nunder \\"/etc/pgbackrest/conf.d\\" alongside any pgBackRest configuration generated by the\\nPostgreSQL Operator:\\nhttps://pgbackrest.org/configuration.html"', args=[d.arg(name='configuration', type=d.T.array)]),
        withConfiguration(configuration): { spec+: { backups+: { pgbackrest+: { configuration: if std.isArray(v=configuration) then configuration else [configuration] } } } },
        '#withConfigurationMixin':: d.fn(help='"Projected volumes containing custom pgBackRest configuration.  These files are mounted\\nunder \\"/etc/pgbackrest/conf.d\\" alongside any pgBackRest configuration generated by the\\nPostgreSQL Operator:\\nhttps://pgbackrest.org/configuration.html"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='configuration', type=d.T.array)]),
        withConfigurationMixin(configuration): { spec+: { backups+: { pgbackrest+: { configuration+: if std.isArray(v=configuration) then configuration else [configuration] } } } },
        '#withEnv':: d.fn(help='"K8SPG-833"', args=[d.arg(name='env', type=d.T.array)]),
        withEnv(env): { spec+: { backups+: { pgbackrest+: { env: if std.isArray(v=env) then env else [env] } } } },
        '#withEnvFrom':: d.fn(help='"K8SPG-833"', args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFrom(envFrom): { spec+: { backups+: { pgbackrest+: { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] } } } },
        '#withEnvFromMixin':: d.fn(help='"K8SPG-833"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFromMixin(envFrom): { spec+: { backups+: { pgbackrest+: { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] } } } },
        '#withEnvMixin':: d.fn(help='"K8SPG-833"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
        withEnvMixin(env): { spec+: { backups+: { pgbackrest+: { env+: if std.isArray(v=env) then env else [env] } } } },
        '#withGlobal':: d.fn(help='"Global pgBackRest configuration settings.  These settings are included in the \\"global\\"\\nsection of the pgBackRest configuration generated by the PostgreSQL Operator, and then\\nmounted under \\"/etc/pgbackrest/conf.d\\":\\nhttps://pgbackrest.org/configuration.html"', args=[d.arg(name='global', type=d.T.object)]),
        withGlobal(global): { spec+: { backups+: { pgbackrest+: { global: global } } } },
        '#withGlobalMixin':: d.fn(help='"Global pgBackRest configuration settings.  These settings are included in the \\"global\\"\\nsection of the pgBackRest configuration generated by the PostgreSQL Operator, and then\\nmounted under \\"/etc/pgbackrest/conf.d\\":\\nhttps://pgbackrest.org/configuration.html"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='global', type=d.T.object)]),
        withGlobalMixin(global): { spec+: { backups+: { pgbackrest+: { global+: global } } } },
        '#withImage':: d.fn(help='"The image name to use for pgBackRest containers.  Utilized to run\\npgBackRest repository hosts and backups. The image may also be set using\\nthe RELATED_IMAGE_PGBACKREST environment variable"', args=[d.arg(name='image', type=d.T.string)]),
        withImage(image): { spec+: { backups+: { pgbackrest+: { image: image } } } },
        '#withRepos':: d.fn(help='"Defines a pgBackRest repository"', args=[d.arg(name='repos', type=d.T.array)]),
        withRepos(repos): { spec+: { backups+: { pgbackrest+: { repos: if std.isArray(v=repos) then repos else [repos] } } } },
        '#withReposMixin':: d.fn(help='"Defines a pgBackRest repository"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='repos', type=d.T.array)]),
        withReposMixin(repos): { spec+: { backups+: { pgbackrest+: { repos+: if std.isArray(v=repos) then repos else [repos] } } } },
      },
      '#withEnabled':: d.fn(help='', args=[d.arg(name='enabled', type=d.T.boolean)]),
      withEnabled(enabled): { spec+: { backups+: { enabled: enabled } } },
      '#withTrackLatestRestorableTime':: d.fn(help='"Enable tracking latest restorable time"', args=[d.arg(name='trackLatestRestorableTime', type=d.T.boolean)]),
      withTrackLatestRestorableTime(trackLatestRestorableTime): { spec+: { backups+: { trackLatestRestorableTime: trackLatestRestorableTime } } },
    },
    '#dataSource':: d.obj(help='"Specifies a data source for bootstrapping the PostgreSQL cluster."'),
    dataSource: {
      '#pgbackrest':: d.obj(help='"Defines a pgBackRest cloud-based data source that can be used to pre-populate the\\nPostgreSQL data directory for a new PostgreSQL cluster using a pgBackRest restore.\\nThe PGBackRest field is incompatible with the PostgresCluster field: only one\\ndata source can be used for pre-populating a new PostgreSQL cluster"'),
      pgbackrest: {
        '#affinity':: d.obj(help='"Scheduling constraints of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
        affinity: {
          '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
          nodeAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
              preference: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
              },
              '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
              nodeSelectorTerms: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
              },
              '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTerms(nodeSelectorTerms): { spec+: { dataSource+: { pgbackrest+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
              '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { dataSource+: { pgbackrest+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
          podAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
          podAntiAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { pgbackrest+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
        },
        '#configuration':: d.obj(help='"Projected volumes containing custom pgBackRest configuration.  These files are mounted\\nunder \\"/etc/pgbackrest/conf.d\\" alongside any pgBackRest configuration generated by the\\nPostgreSQL Operator:\\nhttps://pgbackrest.org/configuration.html"'),
        configuration: {
          '#clusterTrustBundle':: d.obj(help='"ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field\\nof ClusterTrustBundle objects in an auto-updating file.\\n\\nAlpha, gated by the ClusterTrustBundleProjection feature gate.\\n\\nClusterTrustBundle objects can either be selected by name, or by the\\ncombination of signer name and a label selector.\\n\\nKubelet performs aggressive normalization of the PEM contents written\\ninto the pod filesystem.  Esoteric PEM features such as inter-block\\ncomments and block headers are stripped.  Certificates are deduplicated.\\nThe ordering of certificates within the file is arbitrary, and Kubelet\\nmay change the order over time."'),
          clusterTrustBundle: {
            '#labelSelector':: d.obj(help='"Select all ClusterTrustBundles that match this label selector.  Only has\\neffect if signerName is set.  Mutually-exclusive with name.  If unset,\\ninterpreted as \\"match nothing\\".  If set but empty, interpreted as \\"match\\neverything\\"."'),
            labelSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels: matchLabels } } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels+: matchLabels } } },
            },
            '#withName':: d.fn(help='"Select a single ClusterTrustBundle by object name.  Mutually-exclusive\\nwith signerName and labelSelector."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { clusterTrustBundle+: { name: name } },
            '#withOptional':: d.fn(help="\"If true, don't block pod startup if the referenced ClusterTrustBundle(s)\\naren't available.  If using name, then the named ClusterTrustBundle is\\nallowed not to exist.  If using signerName, then the combination of\\nsignerName and labelSelector is allowed to match zero\\nClusterTrustBundles.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { clusterTrustBundle+: { optional: optional } },
            '#withPath':: d.fn(help='"Relative path from the volume root to write the bundle."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { clusterTrustBundle+: { path: path } },
            '#withSignerName':: d.fn(help='"Select all ClusterTrustBundles that match this signer name.\\nMutually-exclusive with name.  The contents of all selected\\nClusterTrustBundles will be unified and deduplicated."', args=[d.arg(name='signerName', type=d.T.string)]),
            withSignerName(signerName): { clusterTrustBundle+: { signerName: signerName } },
          },
          '#configMap':: d.obj(help='"configMap information about the configMap data to project"'),
          configMap: {
            '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
            '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { configMap+: { name: name } },
            '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { configMap+: { optional: optional } },
          },
          '#downwardAPI':: d.obj(help='"downwardAPI information about the downwardAPI data to project"'),
          downwardAPI: {
            '#items':: d.obj(help='"Items is a list of DownwardAPIVolume file"'),
            items: {
              '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
              fieldRef: {
                '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
              },
              '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
              resourceFieldRef: {
                '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                withResource(resource): { resourceFieldRef+: { resource: resource } },
              },
              '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help='"Items is a list of DownwardAPIVolume file"', args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
            '#withItemsMixin':: d.fn(help='"Items is a list of DownwardAPIVolume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
          },
          '#podCertificate':: d.obj(help="\"Projects an auto-rotating credential bundle (private key and certificate\\nchain) that the pod can use either as a TLS client or server.\\n\\nKubelet generates a private key and uses it to send a\\nPodCertificateRequest to the named signer.  Once the signer approves the\\nrequest and issues a certificate chain, Kubelet writes the key and\\ncertificate chain to the pod filesystem.  The pod does not start until\\ncertificates have been issued for each podCertificate projected volume\\nsource in its spec.\\n\\nKubelet will begin trying to rotate the certificate at the time indicated\\nby the signer using the PodCertificateRequest.Status.BeginRefreshAt\\ntimestamp.\\n\\nKubelet can write a single file, indicated by the credentialBundlePath\\nfield, or separate files, indicated by the keyPath and\\ncertificateChainPath fields.\\n\\nThe credential bundle is a single file in PEM format.  The first PEM\\nentry is the private key (in PKCS#8 format), and the remaining PEM\\nentries are the certificate chain issued by the signer (typically,\\nsigners will return their certificate chain in leaf-to-root order).\\n\\nPrefer using the credential bundle format, since your application code\\ncan read it atomically.  If you use keyPath and certificateChainPath,\\nyour application must make two separate file reads. If these coincide\\nwith a certificate rotation, it is possible that the private key and leaf\\ncertificate you read may not correspond to each other.  Your application\\nwill need to check for this condition, and re-read until they are\\nconsistent.\\n\\nThe named signer controls chooses the format of the certificate it\\nissues; consult the signer implementation's documentation to learn how to\\nuse the certificates it issues.\""),
          podCertificate: {
            '#withCertificateChainPath':: d.fn(help='"Write the certificate chain at this path in the projected volume.\\n\\nMost applications should use credentialBundlePath.  When using keyPath\\nand certificateChainPath, your application needs to check that the key\\nand leaf certificate are consistent, because it is possible to read the\\nfiles mid-rotation."', args=[d.arg(name='certificateChainPath', type=d.T.string)]),
            withCertificateChainPath(certificateChainPath): { podCertificate+: { certificateChainPath: certificateChainPath } },
            '#withCredentialBundlePath':: d.fn(help="\"Write the credential bundle at this path in the projected volume.\\n\\nThe credential bundle is a single file that contains multiple PEM blocks.\\nThe first PEM block is a PRIVATE KEY block, containing a PKCS#8 private\\nkey.\\n\\nThe remaining blocks are CERTIFICATE blocks, containing the issued\\ncertificate chain from the signer (leaf and any intermediates).\\n\\nUsing credentialBundlePath lets your Pod's application code make a single\\natomic read that retrieves a consistent key and certificate chain.  If you\\nproject them to separate files, your application code will need to\\nadditionally check that the leaf certificate was issued to the key.\"", args=[d.arg(name='credentialBundlePath', type=d.T.string)]),
            withCredentialBundlePath(credentialBundlePath): { podCertificate+: { credentialBundlePath: credentialBundlePath } },
            '#withKeyPath':: d.fn(help='"Write the key at this path in the projected volume.\\n\\nMost applications should use credentialBundlePath.  When using keyPath\\nand certificateChainPath, your application needs to check that the key\\nand leaf certificate are consistent, because it is possible to read the\\nfiles mid-rotation."', args=[d.arg(name='keyPath', type=d.T.string)]),
            withKeyPath(keyPath): { podCertificate+: { keyPath: keyPath } },
            '#withKeyType':: d.fn(help='"The type of keypair Kubelet will generate for the pod.\\n\\nValid values are \\"RSA3072\\", \\"RSA4096\\", \\"ECDSAP256\\", \\"ECDSAP384\\",\\n\\"ECDSAP521\\", and \\"ED25519\\"."', args=[d.arg(name='keyType', type=d.T.string)]),
            withKeyType(keyType): { podCertificate+: { keyType: keyType } },
            '#withMaxExpirationSeconds':: d.fn(help='"maxExpirationSeconds is the maximum lifetime permitted for the\\ncertificate.\\n\\nKubelet copies this value verbatim into the PodCertificateRequests it\\ngenerates for this projection.\\n\\nIf omitted, kube-apiserver will set it to 86400(24 hours). kube-apiserver\\nwill reject values shorter than 3600 (1 hour).  The maximum allowable\\nvalue is 7862400 (91 days).\\n\\nThe signer implementation is then free to issue a certificate with any\\nlifetime *shorter* than MaxExpirationSeconds, but no shorter than 3600\\nseconds (1 hour).  This constraint is enforced by kube-apiserver.\\n`kubernetes.io` signers will never issue certificates with a lifetime\\nlonger than 24 hours."', args=[d.arg(name='maxExpirationSeconds', type=d.T.integer)]),
            withMaxExpirationSeconds(maxExpirationSeconds): { podCertificate+: { maxExpirationSeconds: maxExpirationSeconds } },
            '#withSignerName':: d.fn(help="\"Kubelet's generated CSRs will be addressed to this signer.\"", args=[d.arg(name='signerName', type=d.T.string)]),
            withSignerName(signerName): { podCertificate+: { signerName: signerName } },
          },
          '#secret':: d.obj(help='"secret information about the secret data to project"'),
          secret: {
            '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
            items: {
              '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
              withMode(mode): { mode: mode },
              '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { path: path },
            },
            '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
            withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
            '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
            withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { secret+: { name: name } },
            '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { secret+: { optional: optional } },
          },
          '#serviceAccountToken':: d.obj(help='"serviceAccountToken is information about the serviceAccountToken data to project"'),
          serviceAccountToken: {
            '#withAudience':: d.fn(help='"audience is the intended audience of the token. A recipient of a token\\nmust identify itself with an identifier specified in the audience of the\\ntoken, and otherwise should reject the token. The audience defaults to the\\nidentifier of the apiserver."', args=[d.arg(name='audience', type=d.T.string)]),
            withAudience(audience): { serviceAccountToken+: { audience: audience } },
            '#withExpirationSeconds':: d.fn(help='"expirationSeconds is the requested duration of validity of the service\\naccount token. As the token approaches expiration, the kubelet volume\\nplugin will proactively rotate the service account token. The kubelet will\\nstart trying to rotate the token if the token is older than 80 percent of\\nits time to live or if the token is older than 24 hours.Defaults to 1 hour\\nand must be at least 10 minutes."', args=[d.arg(name='expirationSeconds', type=d.T.integer)]),
            withExpirationSeconds(expirationSeconds): { serviceAccountToken+: { expirationSeconds: expirationSeconds } },
            '#withPath':: d.fn(help='"path is the path relative to the mount point of the file to project the\\ntoken into."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { serviceAccountToken+: { path: path } },
          },
        },
        '#repo':: d.obj(help='"Defines a pgBackRest repository"'),
        repo: {
          '#azure':: d.obj(help='"Represents a pgBackRest repository that is created using Azure storage"'),
          azure: {
            '#withContainer':: d.fn(help='"The Azure container utilized for the repository"', args=[d.arg(name='container', type=d.T.string)]),
            withContainer(container): { spec+: { dataSource+: { pgbackrest+: { repo+: { azure+: { container: container } } } } } },
          },
          '#gcs':: d.obj(help='"Represents a pgBackRest repository that is created using Google Cloud Storage"'),
          gcs: {
            '#withBucket':: d.fn(help='"The GCS bucket utilized for the repository"', args=[d.arg(name='bucket', type=d.T.string)]),
            withBucket(bucket): { spec+: { dataSource+: { pgbackrest+: { repo+: { gcs+: { bucket: bucket } } } } } },
          },
          '#s3':: d.obj(help='"RepoS3 represents a pgBackRest repository that is created using AWS S3 (or S3-compatible)\\nstorage"'),
          s3: {
            '#withBucket':: d.fn(help='"The S3 bucket utilized for the repository"', args=[d.arg(name='bucket', type=d.T.string)]),
            withBucket(bucket): { spec+: { dataSource+: { pgbackrest+: { repo+: { s3+: { bucket: bucket } } } } } },
            '#withEndpoint':: d.fn(help='"A valid endpoint corresponding to the specified region"', args=[d.arg(name='endpoint', type=d.T.string)]),
            withEndpoint(endpoint): { spec+: { dataSource+: { pgbackrest+: { repo+: { s3+: { endpoint: endpoint } } } } } },
            '#withRegion':: d.fn(help='"The region corresponding to the S3 bucket"', args=[d.arg(name='region', type=d.T.string)]),
            withRegion(region): { spec+: { dataSource+: { pgbackrest+: { repo+: { s3+: { region: region } } } } } },
          },
          '#schedules':: d.obj(help='"Defines the schedules for the pgBackRest backups\\nFull, Differential and Incremental backup types are supported:\\nhttps://pgbackrest.org/user-guide.html#concept/backup"'),
          schedules: {
            '#withDifferential':: d.fn(help='"Defines the Cron schedule for a differential pgBackRest backup.\\nFollows the standard Cron schedule syntax:\\nhttps://k8s.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax"', args=[d.arg(name='differential', type=d.T.string)]),
            withDifferential(differential): { spec+: { dataSource+: { pgbackrest+: { repo+: { schedules+: { differential: differential } } } } } },
            '#withFull':: d.fn(help='"Defines the Cron schedule for a full pgBackRest backup.\\nFollows the standard Cron schedule syntax:\\nhttps://k8s.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax"', args=[d.arg(name='full', type=d.T.string)]),
            withFull(full): { spec+: { dataSource+: { pgbackrest+: { repo+: { schedules+: { full: full } } } } } },
            '#withIncremental':: d.fn(help='"Defines the Cron schedule for an incremental pgBackRest backup.\\nFollows the standard Cron schedule syntax:\\nhttps://k8s.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax"', args=[d.arg(name='incremental', type=d.T.string)]),
            withIncremental(incremental): { spec+: { dataSource+: { pgbackrest+: { repo+: { schedules+: { incremental: incremental } } } } } },
          },
          '#volume':: d.obj(help='"Represents a pgBackRest repository that is created using a PersistentVolumeClaim"'),
          volume: {
            '#volumeClaimSpec':: d.obj(help='"Defines a PersistentVolumeClaim spec used to create and/or bind a volume"'),
            volumeClaimSpec: {
              '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
              dataSource: {
                '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                withApiGroup(apiGroup): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSource+: { apiGroup: apiGroup } } } } } } } },
                '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSource+: { kind: kind } } } } } } } },
                '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSource+: { name: name } } } } } } } },
              },
              '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
              dataSourceRef: {
                '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
                withApiGroup(apiGroup): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSourceRef+: { apiGroup: apiGroup } } } } } } } },
                '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
                withKind(kind): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSourceRef+: { kind: kind } } } } } } } },
                '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSourceRef+: { name: name } } } } } } } },
                '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
                withNamespace(namespace): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { dataSourceRef+: { namespace: namespace } } } } } } } },
              },
              '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
              resources: {
                '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
                withLimits(limits): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { resources+: { limits: limits } } } } } } } },
                '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
                withLimitsMixin(limits): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { resources+: { limits+: limits } } } } } } } },
                '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
                withRequests(requests): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { resources+: { requests: requests } } } } } } } },
                '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
                withRequestsMixin(requests): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { resources+: { requests+: requests } } } } } } } },
              },
              '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
              selector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } } } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } } } } } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { selector+: { matchLabels: matchLabels } } } } } } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { selector+: { matchLabels+: matchLabels } } } } } } } },
              },
              '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
              withAccessModes(accessModes): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } } } } },
              '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
              withAccessModesMixin(accessModes): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } } } } } } },
              '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
              withStorageClassName(storageClassName): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { storageClassName: storageClassName } } } } } } },
              '#withVolumeAttributesClassName':: d.fn(help='"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string or nil value indicates that no\\nVolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,\\nthis field can be reset to its previous value (including nil) to cancel the modification.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/"', args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
              withVolumeAttributesClassName(volumeAttributesClassName): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { volumeAttributesClassName: volumeAttributesClassName } } } } } } },
              '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
              withVolumeMode(volumeMode): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { volumeMode: volumeMode } } } } } } },
              '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { spec+: { dataSource+: { pgbackrest+: { repo+: { volume+: { volumeClaimSpec+: { volumeName: volumeName } } } } } } },
            },
          },
          '#withName':: d.fn(help='"The name of the repository"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { dataSource+: { pgbackrest+: { repo+: { name: name } } } } },
        },
        '#resources':: d.obj(help='"Resource requirements for the pgBackRest restore Job."'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { spec+: { dataSource+: { pgbackrest+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { spec+: { dataSource+: { pgbackrest+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { spec+: { dataSource+: { pgbackrest+: { resources+: { limits: limits } } } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { spec+: { dataSource+: { pgbackrest+: { resources+: { limits+: limits } } } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { spec+: { dataSource+: { pgbackrest+: { resources+: { requests: requests } } } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { spec+: { dataSource+: { pgbackrest+: { resources+: { requests+: requests } } } } },
        },
        '#tolerations':: d.obj(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
        tolerations: {
          '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
          withEffect(effect): { effect: effect },
          '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
          withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
          '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#withConfiguration':: d.fn(help='"Projected volumes containing custom pgBackRest configuration.  These files are mounted\\nunder \\"/etc/pgbackrest/conf.d\\" alongside any pgBackRest configuration generated by the\\nPostgreSQL Operator:\\nhttps://pgbackrest.org/configuration.html"', args=[d.arg(name='configuration', type=d.T.array)]),
        withConfiguration(configuration): { spec+: { dataSource+: { pgbackrest+: { configuration: if std.isArray(v=configuration) then configuration else [configuration] } } } },
        '#withConfigurationMixin':: d.fn(help='"Projected volumes containing custom pgBackRest configuration.  These files are mounted\\nunder \\"/etc/pgbackrest/conf.d\\" alongside any pgBackRest configuration generated by the\\nPostgreSQL Operator:\\nhttps://pgbackrest.org/configuration.html"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='configuration', type=d.T.array)]),
        withConfigurationMixin(configuration): { spec+: { dataSource+: { pgbackrest+: { configuration+: if std.isArray(v=configuration) then configuration else [configuration] } } } },
        '#withGlobal':: d.fn(help='"Global pgBackRest configuration settings.  These settings are included in the \\"global\\"\\nsection of the pgBackRest configuration generated by the PostgreSQL Operator, and then\\nmounted under \\"/etc/pgbackrest/conf.d\\":\\nhttps://pgbackrest.org/configuration.html"', args=[d.arg(name='global', type=d.T.object)]),
        withGlobal(global): { spec+: { dataSource+: { pgbackrest+: { global: global } } } },
        '#withGlobalMixin':: d.fn(help='"Global pgBackRest configuration settings.  These settings are included in the \\"global\\"\\nsection of the pgBackRest configuration generated by the PostgreSQL Operator, and then\\nmounted under \\"/etc/pgbackrest/conf.d\\":\\nhttps://pgbackrest.org/configuration.html"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='global', type=d.T.object)]),
        withGlobalMixin(global): { spec+: { dataSource+: { pgbackrest+: { global+: global } } } },
        '#withOptions':: d.fn(help='"Command line options to include when running the pgBackRest restore command.\\nhttps://pgbackrest.org/command.html#command-restore"', args=[d.arg(name='options', type=d.T.array)]),
        withOptions(options): { spec+: { dataSource+: { pgbackrest+: { options: if std.isArray(v=options) then options else [options] } } } },
        '#withOptionsMixin':: d.fn(help='"Command line options to include when running the pgBackRest restore command.\\nhttps://pgbackrest.org/command.html#command-restore"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
        withOptionsMixin(options): { spec+: { dataSource+: { pgbackrest+: { options+: if std.isArray(v=options) then options else [options] } } } },
        '#withPriorityClassName':: d.fn(help='"Priority class name for the pgBackRest restore Job pod. Changing this\\nvalue causes PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
        withPriorityClassName(priorityClassName): { spec+: { dataSource+: { pgbackrest+: { priorityClassName: priorityClassName } } } },
        '#withStanza':: d.fn(help='"The name of an existing pgBackRest stanza to use as the data source for the new PostgresCluster."', args=[d.arg(name='stanza', type=d.T.string)]),
        withStanza(stanza): { spec+: { dataSource+: { pgbackrest+: { stanza: stanza } } } },
        '#withTolerations':: d.fn(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerations(tolerations): { spec+: { dataSource+: { pgbackrest+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTolerationsMixin':: d.fn(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerationsMixin(tolerations): { spec+: { dataSource+: { pgbackrest+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
      },
      '#postgresCluster':: d.obj(help='"Defines a pgBackRest data source that can be used to pre-populate the PostgreSQL data\\ndirectory for a new PostgreSQL cluster using a pgBackRest restore.\\nThe PGBackRest field is incompatible with the PostgresCluster field: only one\\ndata source can be used for pre-populating a new PostgreSQL cluster"'),
      postgresCluster: {
        '#affinity':: d.obj(help='"Scheduling constraints of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
        affinity: {
          '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
          nodeAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
              preference: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
              },
              '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
              nodeSelectorTerms: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
              },
              '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTerms(nodeSelectorTerms): { spec+: { dataSource+: { postgresCluster+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
              '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { dataSource+: { postgresCluster+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
          podAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
          podAntiAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { dataSource+: { postgresCluster+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
        },
        '#resources':: d.obj(help='"Resource requirements for the pgBackRest restore Job."'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { spec+: { dataSource+: { postgresCluster+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { spec+: { dataSource+: { postgresCluster+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { spec+: { dataSource+: { postgresCluster+: { resources+: { limits: limits } } } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { spec+: { dataSource+: { postgresCluster+: { resources+: { limits+: limits } } } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { spec+: { dataSource+: { postgresCluster+: { resources+: { requests: requests } } } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { spec+: { dataSource+: { postgresCluster+: { resources+: { requests+: requests } } } } },
        },
        '#tolerations':: d.obj(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
        tolerations: {
          '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
          withEffect(effect): { effect: effect },
          '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
          withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
          '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#withClusterName':: d.fn(help='"The name of an existing PostgresCluster to use as the data source for the new PostgresCluster.\\nDefaults to the name of the PostgresCluster being created if not provided."', args=[d.arg(name='clusterName', type=d.T.string)]),
        withClusterName(clusterName): { spec+: { dataSource+: { postgresCluster+: { clusterName: clusterName } } } },
        '#withClusterNamespace':: d.fn(help='"The namespace of the cluster specified as the data source using the clusterName field.\\nDefaults to the namespace of the PostgresCluster being created if not provided."', args=[d.arg(name='clusterNamespace', type=d.T.string)]),
        withClusterNamespace(clusterNamespace): { spec+: { dataSource+: { postgresCluster+: { clusterNamespace: clusterNamespace } } } },
        '#withOptions':: d.fn(help='"Command line options to include when running the pgBackRest restore command.\\nhttps://pgbackrest.org/command.html#command-restore"', args=[d.arg(name='options', type=d.T.array)]),
        withOptions(options): { spec+: { dataSource+: { postgresCluster+: { options: if std.isArray(v=options) then options else [options] } } } },
        '#withOptionsMixin':: d.fn(help='"Command line options to include when running the pgBackRest restore command.\\nhttps://pgbackrest.org/command.html#command-restore"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='options', type=d.T.array)]),
        withOptionsMixin(options): { spec+: { dataSource+: { postgresCluster+: { options+: if std.isArray(v=options) then options else [options] } } } },
        '#withPriorityClassName':: d.fn(help='"Priority class name for the pgBackRest restore Job pod. Changing this\\nvalue causes PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
        withPriorityClassName(priorityClassName): { spec+: { dataSource+: { postgresCluster+: { priorityClassName: priorityClassName } } } },
        '#withRepoName':: d.fn(help='"The name of the pgBackRest repo within the source PostgresCluster that contains the backups\\nthat should be utilized to perform a pgBackRest restore when initializing the data source\\nfor the new PostgresCluster."', args=[d.arg(name='repoName', type=d.T.string)]),
        withRepoName(repoName): { spec+: { dataSource+: { postgresCluster+: { repoName: repoName } } } },
        '#withTolerations':: d.fn(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerations(tolerations): { spec+: { dataSource+: { postgresCluster+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTolerationsMixin':: d.fn(help='"Tolerations of the pgBackRest restore Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerationsMixin(tolerations): { spec+: { dataSource+: { postgresCluster+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
      },
      '#volumes':: d.obj(help='"Defines any existing volumes to reuse for this PostgresCluster."'),
      volumes: {
        '#pgBackRestVolume':: d.obj(help='"Defines the existing pgBackRest repo volume and directory to use in the\\ncurrent PostgresCluster."'),
        pgBackRestVolume: {
          '#tolerations':: d.obj(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
          tolerations: {
            '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
            withEffect(effect): { effect: effect },
            '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
            withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
            '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#withAnnotations':: d.fn(help='"Annotations of the move dir Job."', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='"Annotations of the move dir Job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { annotations+: annotations } } } } },
          '#withDirectory':: d.fn(help='"The existing directory. When not set, a move Job is not created for the\\nassociated volume."', args=[d.arg(name='directory', type=d.T.string)]),
          withDirectory(directory): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { directory: directory } } } } },
          '#withLabels':: d.fn(help='"Labels of the move dir Job."', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='"Labels of the move dir Job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { labels+: labels } } } } },
          '#withPvcName':: d.fn(help='"The existing PVC name."', args=[d.arg(name='pvcName', type=d.T.string)]),
          withPvcName(pvcName): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { pvcName: pvcName } } } } },
          '#withTolerations':: d.fn(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerations(tolerations): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTolerationsMixin':: d.fn(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerationsMixin(tolerations): { spec+: { dataSource+: { volumes+: { pgBackRestVolume+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
        },
        '#pgDataVolume':: d.obj(help='"Defines the existing pgData volume and directory to use in the current\\nPostgresCluster."'),
        pgDataVolume: {
          '#tolerations':: d.obj(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
          tolerations: {
            '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
            withEffect(effect): { effect: effect },
            '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
            withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
            '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#withAnnotations':: d.fn(help='"Annotations of the move dir Job."', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='"Annotations of the move dir Job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { annotations+: annotations } } } } },
          '#withDirectory':: d.fn(help='"The existing directory. When not set, a move Job is not created for the\\nassociated volume."', args=[d.arg(name='directory', type=d.T.string)]),
          withDirectory(directory): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { directory: directory } } } } },
          '#withLabels':: d.fn(help='"Labels of the move dir Job."', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='"Labels of the move dir Job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { labels+: labels } } } } },
          '#withPvcName':: d.fn(help='"The existing PVC name."', args=[d.arg(name='pvcName', type=d.T.string)]),
          withPvcName(pvcName): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { pvcName: pvcName } } } } },
          '#withTolerations':: d.fn(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerations(tolerations): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTolerationsMixin':: d.fn(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerationsMixin(tolerations): { spec+: { dataSource+: { volumes+: { pgDataVolume+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
        },
        '#pgWALVolume':: d.obj(help='"Defines the existing pg_wal volume and directory to use in the current\\nPostgresCluster. Note that a defined pg_wal volume MUST be accompanied by\\na pgData volume."'),
        pgWALVolume: {
          '#tolerations':: d.obj(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
          tolerations: {
            '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
            withEffect(effect): { effect: effect },
            '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
            withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
            '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#withAnnotations':: d.fn(help='"Annotations of the move dir Job."', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='"Annotations of the move dir Job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { annotations+: annotations } } } } },
          '#withDirectory':: d.fn(help='"The existing directory. When not set, a move Job is not created for the\\nassociated volume."', args=[d.arg(name='directory', type=d.T.string)]),
          withDirectory(directory): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { directory: directory } } } } },
          '#withLabels':: d.fn(help='"Labels of the move dir Job."', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='"Labels of the move dir Job."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { labels+: labels } } } } },
          '#withPvcName':: d.fn(help='"The existing PVC name."', args=[d.arg(name='pvcName', type=d.T.string)]),
          withPvcName(pvcName): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { pvcName: pvcName } } } } },
          '#withTolerations':: d.fn(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerations(tolerations): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
          '#withTolerationsMixin':: d.fn(help='"Tolerations of the move dir Job.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
          withTolerationsMixin(tolerations): { spec+: { dataSource+: { volumes+: { pgWALVolume+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } } },
        },
      },
    },
    '#databaseInitSQL':: d.obj(help='"DatabaseInitSQL defines a ConfigMap containing custom SQL that will\\nbe run after the cluster is initialized. This ConfigMap must be in the same\\nnamespace as the cluster."'),
    databaseInitSQL: {
      '#withKey':: d.fn(help='"Key is the ConfigMap data key that points to a SQL string"', args=[d.arg(name='key', type=d.T.string)]),
      withKey(key): { spec+: { databaseInitSQL+: { key: key } } },
      '#withName':: d.fn(help='"Name is the name of a ConfigMap"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { spec+: { databaseInitSQL+: { name: name } } },
    },
    '#expose':: d.obj(help='"Specification of the service that exposes the PostgreSQL primary instance."'),
    expose: {
      '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { expose+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { expose+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { expose+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { expose+: { labels+: labels } } },
      '#withLoadBalancerClass':: d.fn(help='"LoadBalancerClass specifies the class of the load balancer implementation\\nto be used. This field is supported for Service Type LoadBalancer only.\\n\\nMore info:\\nhttps://kubernetes.io/docs/concepts/services-networking/service/#load-balancer-class"', args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
      withLoadBalancerClass(loadBalancerClass): { spec+: { expose+: { loadBalancerClass: loadBalancerClass } } },
      '#withLoadBalancerSourceRanges':: d.fn(help='"LoadBalancerSourceRanges is a list of IP CIDRs allowed access to load.\\nThis field will be ignored if the cloud-provider does not support the feature."', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
      withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { expose+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } },
      '#withLoadBalancerSourceRangesMixin':: d.fn(help='"LoadBalancerSourceRanges is a list of IP CIDRs allowed access to load.\\nThis field will be ignored if the cloud-provider does not support the feature."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
      withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { expose+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } },
      '#withNodePort':: d.fn(help='"The port on which this service is exposed when type is NodePort or\\nLoadBalancer. Value must be in-range and not in use or the operation will\\nfail. If unspecified, a port will be allocated if this Service requires one.\\n- https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"', args=[d.arg(name='nodePort', type=d.T.integer)]),
      withNodePort(nodePort): { spec+: { expose+: { nodePort: nodePort } } },
      '#withType':: d.fn(help='"More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"', args=[d.arg(name='type', type=d.T.string)]),
      withType(type): { spec+: { expose+: { type: type } } },
    },
    '#exposeReplicas':: d.obj(help='"Specification of the service that exposes PostgreSQL replica instances"'),
    exposeReplicas: {
      '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { exposeReplicas+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { exposeReplicas+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { exposeReplicas+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { exposeReplicas+: { labels+: labels } } },
      '#withLoadBalancerClass':: d.fn(help='"LoadBalancerClass specifies the class of the load balancer implementation\\nto be used. This field is supported for Service Type LoadBalancer only.\\n\\nMore info:\\nhttps://kubernetes.io/docs/concepts/services-networking/service/#load-balancer-class"', args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
      withLoadBalancerClass(loadBalancerClass): { spec+: { exposeReplicas+: { loadBalancerClass: loadBalancerClass } } },
      '#withLoadBalancerSourceRanges':: d.fn(help='"LoadBalancerSourceRanges is a list of IP CIDRs allowed access to load.\\nThis field will be ignored if the cloud-provider does not support the feature."', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
      withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { exposeReplicas+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } },
      '#withLoadBalancerSourceRangesMixin':: d.fn(help='"LoadBalancerSourceRanges is a list of IP CIDRs allowed access to load.\\nThis field will be ignored if the cloud-provider does not support the feature."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
      withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { exposeReplicas+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } },
      '#withNodePort':: d.fn(help='"The port on which this service is exposed when type is NodePort or\\nLoadBalancer. Value must be in-range and not in use or the operation will\\nfail. If unspecified, a port will be allocated if this Service requires one.\\n- https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"', args=[d.arg(name='nodePort', type=d.T.integer)]),
      withNodePort(nodePort): { spec+: { exposeReplicas+: { nodePort: nodePort } } },
      '#withType':: d.fn(help='"More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"', args=[d.arg(name='type', type=d.T.string)]),
      withType(type): { spec+: { exposeReplicas+: { type: type } } },
    },
    '#extensions':: d.obj(help='"The specification of extensions."'),
    extensions: {
      '#builtin':: d.obj(help=''),
      builtin: {
        '#withPg_audit':: d.fn(help='', args=[d.arg(name='pg_audit', type=d.T.boolean)]),
        withPg_audit(pg_audit): { spec+: { extensions+: { builtin+: { pg_audit: pg_audit } } } },
        '#withPg_repack':: d.fn(help='', args=[d.arg(name='pg_repack', type=d.T.boolean)]),
        withPg_repack(pg_repack): { spec+: { extensions+: { builtin+: { pg_repack: pg_repack } } } },
        '#withPg_stat_monitor':: d.fn(help='', args=[d.arg(name='pg_stat_monitor', type=d.T.boolean)]),
        withPg_stat_monitor(pg_stat_monitor): { spec+: { extensions+: { builtin+: { pg_stat_monitor: pg_stat_monitor } } } },
        '#withPg_stat_statements':: d.fn(help='', args=[d.arg(name='pg_stat_statements', type=d.T.boolean)]),
        withPg_stat_statements(pg_stat_statements): { spec+: { extensions+: { builtin+: { pg_stat_statements: pg_stat_statements } } } },
        '#withPgvector':: d.fn(help='', args=[d.arg(name='pgvector', type=d.T.boolean)]),
        withPgvector(pgvector): { spec+: { extensions+: { builtin+: { pgvector: pgvector } } } },
      },
      '#custom':: d.obj(help=''),
      custom: {
        '#withChecksum':: d.fn(help='', args=[d.arg(name='checksum', type=d.T.string)]),
        withChecksum(checksum): { checksum: checksum },
        '#withName':: d.fn(help='', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withVersion':: d.fn(help='', args=[d.arg(name='version', type=d.T.string)]),
        withVersion(version): { version: version },
      },
      '#storage':: d.obj(help=''),
      storage: {
        '#secret':: d.obj(help="\"Adapts a secret into a projected volume.\\n\\nThe contents of the target Secret's Data field will be presented in a\\nprojected volume as files using the keys in the Data field as the file names.\\nNote that this is identical to a secret volume source without the default\\nmode.\""),
        secret: {
          '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
          items: {
            '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
            withMode(mode): { mode: mode },
            '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
          withItems(items): { spec+: { extensions+: { storage+: { secret+: { items: if std.isArray(v=items) then items else [items] } } } } },
          '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
          withItemsMixin(items): { spec+: { extensions+: { storage+: { secret+: { items+: if std.isArray(v=items) then items else [items] } } } } },
          '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { extensions+: { storage+: { secret+: { name: name } } } } },
          '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { extensions+: { storage+: { secret+: { optional: optional } } } } },
        },
        '#withBucket':: d.fn(help='', args=[d.arg(name='bucket', type=d.T.string)]),
        withBucket(bucket): { spec+: { extensions+: { storage+: { bucket: bucket } } } },
        '#withDisableSSL':: d.fn(help='', args=[d.arg(name='disableSSL', type=d.T.boolean)]),
        withDisableSSL(disableSSL): { spec+: { extensions+: { storage+: { disableSSL: disableSSL } } } },
        '#withEndpoint':: d.fn(help='', args=[d.arg(name='endpoint', type=d.T.string)]),
        withEndpoint(endpoint): { spec+: { extensions+: { storage+: { endpoint: endpoint } } } },
        '#withForcePathStyle':: d.fn(help='', args=[d.arg(name='forcePathStyle', type=d.T.boolean)]),
        withForcePathStyle(forcePathStyle): { spec+: { extensions+: { storage+: { forcePathStyle: forcePathStyle } } } },
        '#withRegion':: d.fn(help='', args=[d.arg(name='region', type=d.T.string)]),
        withRegion(region): { spec+: { extensions+: { storage+: { region: region } } } },
        '#withType':: d.fn(help='', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { extensions+: { storage+: { type: type } } } },
      },
      '#withCustom':: d.fn(help='', args=[d.arg(name='custom', type=d.T.array)]),
      withCustom(custom): { spec+: { extensions+: { custom: if std.isArray(v=custom) then custom else [custom] } } },
      '#withCustomMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='custom', type=d.T.array)]),
      withCustomMixin(custom): { spec+: { extensions+: { custom+: if std.isArray(v=custom) then custom else [custom] } } },
      '#withImage':: d.fn(help='', args=[d.arg(name='image', type=d.T.string)]),
      withImage(image): { spec+: { extensions+: { image: image } } },
      '#withImagePullPolicy':: d.fn(help='"PullPolicy describes a policy for if/when to pull a container image"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
      withImagePullPolicy(imagePullPolicy): { spec+: { extensions+: { imagePullPolicy: imagePullPolicy } } },
    },
    '#imagePullSecrets':: d.obj(help='"The image pull secrets used to pull from a private registry\\nChanging this value causes all running pods to restart.\\nhttps://k8s.io/docs/tasks/configure-pod-container/pull-image-private-registry/"'),
    imagePullSecrets: {
      '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
    },
    '#initContainer':: d.obj(help=''),
    initContainer: {
      '#containerSecurityContext':: d.obj(help='"SecurityContext holds security configuration that will be applied to a container.\\nSome fields are present in both SecurityContext and PodSecurityContext.  When both\\nare set, the values in SecurityContext take precedence."'),
      containerSecurityContext: {
        '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
        appArmorProfile: {
          '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
          withLocalhostProfile(localhostProfile): { spec+: { initContainer+: { containerSecurityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } },
          '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { initContainer+: { containerSecurityContext+: { appArmorProfile+: { type: type } } } } },
        },
        '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
        capabilities: {
          '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
          withAdd(add): { spec+: { initContainer+: { containerSecurityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } },
          '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
          withAddMixin(add): { spec+: { initContainer+: { containerSecurityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } },
          '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
          withDrop(drop): { spec+: { initContainer+: { containerSecurityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } },
          '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
          withDropMixin(drop): { spec+: { initContainer+: { containerSecurityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } },
        },
        '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
        seLinuxOptions: {
          '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
          withLevel(level): { spec+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { level: level } } } } },
          '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
          withRole(role): { spec+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { role: role } } } } },
          '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { type: type } } } } },
          '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
          withUser(user): { spec+: { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { user: user } } } } },
        },
        '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
        seccompProfile: {
          '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
          withLocalhostProfile(localhostProfile): { spec+: { initContainer+: { containerSecurityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } },
          '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { initContainer+: { containerSecurityContext+: { seccompProfile+: { type: type } } } } },
        },
        '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
        windowsOptions: {
          '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
          withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } },
          '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
          withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } },
          '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
          withHostProcess(hostProcess): { spec+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } },
          '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
          withRunAsUserName(runAsUserName): { spec+: { initContainer+: { containerSecurityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } },
        },
        '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
        withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { initContainer+: { containerSecurityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } },
        '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
        withPrivileged(privileged): { spec+: { initContainer+: { containerSecurityContext+: { privileged: privileged } } } },
        '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
        withProcMount(procMount): { spec+: { initContainer+: { containerSecurityContext+: { procMount: procMount } } } },
        '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
        withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { initContainer+: { containerSecurityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } },
        '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
        withRunAsGroup(runAsGroup): { spec+: { initContainer+: { containerSecurityContext+: { runAsGroup: runAsGroup } } } },
        '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
        withRunAsNonRoot(runAsNonRoot): { spec+: { initContainer+: { containerSecurityContext+: { runAsNonRoot: runAsNonRoot } } } },
        '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
        withRunAsUser(runAsUser): { spec+: { initContainer+: { containerSecurityContext+: { runAsUser: runAsUser } } } },
      },
      '#resources':: d.obj(help='"ResourceRequirements describes the compute resource requirements."'),
      resources: {
        '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
        claims: {
          '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
          withRequest(request): { request: request },
        },
        '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
        withClaims(claims): { spec+: { initContainer+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
        withClaimsMixin(claims): { spec+: { initContainer+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { initContainer+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { initContainer+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { initContainer+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { initContainer+: { resources+: { requests+: requests } } } },
      },
      '#withImage':: d.fn(help='', args=[d.arg(name='image', type=d.T.string)]),
      withImage(image): { spec+: { initContainer+: { image: image } } },
    },
    '#instances':: d.obj(help='"Specifies one or more sets of PostgreSQL pods that replicate data for\\nthis cluster."'),
    instances: {
      '#affinity':: d.obj(help='"Scheduling constraints of a PostgreSQL pod. Changing this value causes\\nPostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
      affinity: {
        '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
        nodeAffinity: {
          '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
          preferredDuringSchedulingIgnoredDuringExecution: {
            '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
            preference: {
              '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
              matchExpressions: {
                '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
              matchFields: {
                '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
              withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
              '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
              withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
            },
            '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
            withWeight(weight): { weight: weight },
          },
          '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
          requiredDuringSchedulingIgnoredDuringExecution: {
            '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
            nodeSelectorTerms: {
              '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
              matchExpressions: {
                '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
              matchFields: {
                '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
              '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
              '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
              withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
              '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
              withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
            },
            '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
            withNodeSelectorTerms(nodeSelectorTerms): { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } },
            '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
            withNodeSelectorTermsMixin(nodeSelectorTerms): { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } },
          },
          '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } },
          '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } },
        },
        '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
        podAffinity: {
          '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
          preferredDuringSchedulingIgnoredDuringExecution: {
            '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
            podAffinityTerm: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
            },
            '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
            withWeight(weight): { weight: weight },
          },
          '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
          requiredDuringSchedulingIgnoredDuringExecution: {
            '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
            labelSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
            },
            '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
            namespaceSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
            },
            '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
            withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
            '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
            withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
            '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
            withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
            '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
            withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
            '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
            withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
            '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
            withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
            '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
            withTopologyKey(topologyKey): { topologyKey: topologyKey },
          },
          '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } },
          '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } },
          '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } },
          '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } },
        },
        '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
        podAntiAffinity: {
          '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
          preferredDuringSchedulingIgnoredDuringExecution: {
            '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
            podAffinityTerm: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
            },
            '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
            withWeight(weight): { weight: weight },
          },
          '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
          requiredDuringSchedulingIgnoredDuringExecution: {
            '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
            labelSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
            },
            '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
            namespaceSelector: {
              '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
              matchExpressions: {
                '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                withOperator(operator): { operator: operator },
                '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                withValues(values): { values: if std.isArray(v=values) then values else [values] },
                '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
              },
              '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
              withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
              '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
              '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
              withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
            },
            '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
            withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
            '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
            withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
            '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
            withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
            '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
            withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
            '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
            withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
            '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
            withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
            '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
            withTopologyKey(topologyKey): { topologyKey: topologyKey },
          },
          '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } },
          '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } },
          '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } },
          '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
          withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } },
        },
      },
      '#containers':: d.obj(help='"Configuration for instance default sidecar containers."'),
      containers: {
        '#replicaCertCopy':: d.obj(help='"Defines the configuration for the replica cert copy sidecar container"'),
        replicaCertCopy: {
          '#resources':: d.obj(help='"Resource requirements for a sidecar container"'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { containers+: { replicaCertCopy+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { containers+: { replicaCertCopy+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { containers+: { replicaCertCopy+: { resources+: { limits: limits } } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { containers+: { replicaCertCopy+: { resources+: { limits+: limits } } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { containers+: { replicaCertCopy+: { resources+: { requests: requests } } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { containers+: { replicaCertCopy+: { resources+: { requests+: requests } } } },
          },
        },
      },
      '#dataVolumeClaimSpec':: d.obj(help='"Defines a PersistentVolumeClaim for PostgreSQL data.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes"'),
      dataVolumeClaimSpec: {
        '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
        dataSource: {
          '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
          withApiGroup(apiGroup): { dataVolumeClaimSpec+: { dataSource+: { apiGroup: apiGroup } } },
          '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
          withKind(kind): { dataVolumeClaimSpec+: { dataSource+: { kind: kind } } },
          '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { dataVolumeClaimSpec+: { dataSource+: { name: name } } },
        },
        '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
        dataSourceRef: {
          '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
          withApiGroup(apiGroup): { dataVolumeClaimSpec+: { dataSourceRef+: { apiGroup: apiGroup } } },
          '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
          withKind(kind): { dataVolumeClaimSpec+: { dataSourceRef+: { kind: kind } } },
          '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { dataVolumeClaimSpec+: { dataSourceRef+: { name: name } } },
          '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { dataVolumeClaimSpec+: { dataSourceRef+: { namespace: namespace } } },
        },
        '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
        resources: {
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { dataVolumeClaimSpec+: { resources+: { limits: limits } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { dataVolumeClaimSpec+: { resources+: { limits+: limits } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { dataVolumeClaimSpec+: { resources+: { requests: requests } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { dataVolumeClaimSpec+: { resources+: { requests+: requests } } },
        },
        '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
        selector: {
          '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
          matchExpressions: {
            '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { values: if std.isArray(v=values) then values else [values] },
            '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
          },
          '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressions(matchExpressions): { dataVolumeClaimSpec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
          '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressionsMixin(matchExpressions): { dataVolumeClaimSpec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
          '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { dataVolumeClaimSpec+: { selector+: { matchLabels: matchLabels } } },
          '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { dataVolumeClaimSpec+: { selector+: { matchLabels+: matchLabels } } },
        },
        '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
        withAccessModes(accessModes): { dataVolumeClaimSpec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
        '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
        withAccessModesMixin(accessModes): { dataVolumeClaimSpec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
        '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
        withStorageClassName(storageClassName): { dataVolumeClaimSpec+: { storageClassName: storageClassName } },
        '#withVolumeAttributesClassName':: d.fn(help='"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string or nil value indicates that no\\nVolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,\\nthis field can be reset to its previous value (including nil) to cancel the modification.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/"', args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
        withVolumeAttributesClassName(volumeAttributesClassName): { dataVolumeClaimSpec+: { volumeAttributesClassName: volumeAttributesClassName } },
        '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
        withVolumeMode(volumeMode): { dataVolumeClaimSpec+: { volumeMode: volumeMode } },
        '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
        withVolumeName(volumeName): { dataVolumeClaimSpec+: { volumeName: volumeName } },
      },
      '#env':: d.obj(help=''),
      env: {
        '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
        valueFrom: {
          '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
          configMapKeyRef: {
            '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
          },
          '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
          fieldRef: {
            '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
            withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
            '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
            withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
          },
          '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
          fileKeyRef: {
            '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
            '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
            '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
            '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
            withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
          },
          '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
          resourceFieldRef: {
            '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
            withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
            '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
            withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
            '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
            withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
          },
          '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
          secretKeyRef: {
            '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
            '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
          },
        },
        '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
        withValue(value): { value: value },
      },
      '#envFrom':: d.obj(help=''),
      envFrom: {
        '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
        configMapRef: {
          '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { configMapRef+: { name: name } },
          '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { configMapRef+: { optional: optional } },
        },
        '#secretRef':: d.obj(help='"The Secret to select from"'),
        secretRef: {
          '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { secretRef+: { name: name } },
          '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { secretRef+: { optional: optional } },
        },
        '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
        withPrefix(prefix): { prefix: prefix },
      },
      '#initContainer':: d.obj(help='"K8SPG-708\\nInitContainer defines the init container for the instance container of a PostgreSQL pod."'),
      initContainer: {
        '#containerSecurityContext':: d.obj(help='"SecurityContext holds security configuration that will be applied to a container.\\nSome fields are present in both SecurityContext and PodSecurityContext.  When both\\nare set, the values in SecurityContext take precedence."'),
        containerSecurityContext: {
          '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
          appArmorProfile: {
            '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { initContainer+: { containerSecurityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } },
            '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { initContainer+: { containerSecurityContext+: { appArmorProfile+: { type: type } } } },
          },
          '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
          capabilities: {
            '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
            withAdd(add): { initContainer+: { containerSecurityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } },
            '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
            withAddMixin(add): { initContainer+: { containerSecurityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } },
            '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
            withDrop(drop): { initContainer+: { containerSecurityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } },
            '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
            withDropMixin(drop): { initContainer+: { containerSecurityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } },
          },
          '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seLinuxOptions: {
            '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
            withLevel(level): { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { level: level } } } },
            '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
            withRole(role): { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { role: role } } } },
            '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { type: type } } } },
            '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
            withUser(user): { initContainer+: { containerSecurityContext+: { seLinuxOptions+: { user: user } } } },
          },
          '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seccompProfile: {
            '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { initContainer+: { containerSecurityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } },
            '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { initContainer+: { containerSecurityContext+: { seccompProfile+: { type: type } } } },
          },
          '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
          windowsOptions: {
            '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
            withGmsaCredentialSpec(gmsaCredentialSpec): { initContainer+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } },
            '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
            withGmsaCredentialSpecName(gmsaCredentialSpecName): { initContainer+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } },
            '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
            withHostProcess(hostProcess): { initContainer+: { containerSecurityContext+: { windowsOptions+: { hostProcess: hostProcess } } } },
            '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
            withRunAsUserName(runAsUserName): { initContainer+: { containerSecurityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } },
          },
          '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
          withAllowPrivilegeEscalation(allowPrivilegeEscalation): { initContainer+: { containerSecurityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } },
          '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
          withPrivileged(privileged): { initContainer+: { containerSecurityContext+: { privileged: privileged } } },
          '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
          withProcMount(procMount): { initContainer+: { containerSecurityContext+: { procMount: procMount } } },
          '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
          withReadOnlyRootFilesystem(readOnlyRootFilesystem): { initContainer+: { containerSecurityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } },
          '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
          withRunAsGroup(runAsGroup): { initContainer+: { containerSecurityContext+: { runAsGroup: runAsGroup } } },
          '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
          withRunAsNonRoot(runAsNonRoot): { initContainer+: { containerSecurityContext+: { runAsNonRoot: runAsNonRoot } } },
          '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
          withRunAsUser(runAsUser): { initContainer+: { containerSecurityContext+: { runAsUser: runAsUser } } },
        },
        '#resources':: d.obj(help='"ResourceRequirements describes the compute resource requirements."'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { initContainer+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { initContainer+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { initContainer+: { resources+: { limits: limits } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { initContainer+: { resources+: { limits+: limits } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { initContainer+: { resources+: { requests: requests } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { initContainer+: { resources+: { requests+: requests } } },
        },
        '#withImage':: d.fn(help='', args=[d.arg(name='image', type=d.T.string)]),
        withImage(image): { initContainer+: { image: image } },
      },
      '#initContainers':: d.obj(help='"Additional init containers for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."'),
      initContainers: {
        '#env':: d.obj(help='"List of environment variables to set in the container.\\nCannot be updated."'),
        env: {
          '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
          valueFrom: {
            '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
            configMapKeyRef: {
              '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
            },
            '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
            fieldRef: {
              '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
              withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
              '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
              withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
            },
            '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
            fileKeyRef: {
              '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
              '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
              '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
              '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
            },
            '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
            resourceFieldRef: {
              '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
              withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
              '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
              withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
              '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
              withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
            },
            '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
            secretKeyRef: {
              '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
            },
          },
          '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#envFrom':: d.obj(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\""),
        envFrom: {
          '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
          configMapRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { configMapRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { configMapRef+: { optional: optional } },
          },
          '#secretRef':: d.obj(help='"The Secret to select from"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { secretRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { secretRef+: { optional: optional } },
          },
          '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
          withPrefix(prefix): { prefix: prefix },
        },
        '#lifecycle':: d.obj(help='"Actions that the management system should take in response to container lifecycle events.\\nCannot be updated."'),
        lifecycle: {
          '#postStart':: d.obj(help='"PostStart is called immediately after a container is created. If the handler fails,\\nthe container is terminated and restarted according to its restart policy.\\nOther management of the container blocks until the hook completes.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks"'),
          postStart: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { lifecycle+: { postStart+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { lifecycle+: { postStart+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { postStart+: { httpGet+: { host: host } } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { lifecycle+: { postStart+: { httpGet+: { path: path } } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { postStart+: { httpGet+: { port: port } } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { lifecycle+: { postStart+: { httpGet+: { scheme: scheme } } } },
            },
            '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
            sleep: {
              '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
              withSeconds(seconds): { lifecycle+: { postStart+: { sleep+: { seconds: seconds } } } },
            },
            '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { postStart+: { tcpSocket+: { host: host } } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { postStart+: { tcpSocket+: { port: port } } } },
            },
          },
          '#preStop':: d.obj(help="\"PreStop is called immediately before a container is terminated due to an\\nAPI request or management event such as liveness/startup probe failure,\\npreemption, resource contention, etc. The handler is not called if the\\ncontainer crashes or exits. The Pod's termination grace period countdown begins before the\\nPreStop hook is executed. Regardless of the outcome of the handler, the\\ncontainer will eventually terminate within the Pod's termination grace\\nperiod (unless delayed by finalizers). Other management of the container blocks until the hook completes\\nor until the termination grace period is reached.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks\""),
          preStop: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { lifecycle+: { preStop+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { lifecycle+: { preStop+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { preStop+: { httpGet+: { host: host } } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { lifecycle+: { preStop+: { httpGet+: { path: path } } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { preStop+: { httpGet+: { port: port } } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { lifecycle+: { preStop+: { httpGet+: { scheme: scheme } } } },
            },
            '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
            sleep: {
              '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
              withSeconds(seconds): { lifecycle+: { preStop+: { sleep+: { seconds: seconds } } } },
            },
            '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { preStop+: { tcpSocket+: { host: host } } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { preStop+: { tcpSocket+: { port: port } } } },
            },
          },
          '#withStopSignal':: d.fn(help='"StopSignal defines which signal will be sent to a container when it is being stopped.\\nIf not specified, the default is defined by the container runtime in use.\\nStopSignal can only be set for Pods with a non-empty .spec.os.name"', args=[d.arg(name='stopSignal', type=d.T.string)]),
          withStopSignal(stopSignal): { lifecycle+: { stopSignal: stopSignal } },
        },
        '#livenessProbe':: d.obj(help='"Periodic probe of container liveness.\\nContainer will be restarted if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
        livenessProbe: {
          '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
          exec: {
            '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { livenessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
            '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { livenessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
          },
          '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
          grpc: {
            '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { livenessProbe+: { grpc+: { port: port } } },
            '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
            withService(service): { livenessProbe+: { grpc+: { service: service } } },
          },
          '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
          httpGet: {
            '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
            httpHeaders: {
              '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { livenessProbe+: { httpGet+: { host: host } } },
            '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeaders(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeadersMixin(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { livenessProbe+: { httpGet+: { path: path } } },
            '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { livenessProbe+: { httpGet+: { port: port } } },
            '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
            withScheme(scheme): { livenessProbe+: { httpGet+: { scheme: scheme } } },
          },
          '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
          tcpSocket: {
            '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { livenessProbe+: { tcpSocket+: { host: host } } },
            '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { livenessProbe+: { tcpSocket+: { port: port } } },
          },
          '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
          withFailureThreshold(failureThreshold): { livenessProbe+: { failureThreshold: failureThreshold } },
          '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { livenessProbe+: { initialDelaySeconds: initialDelaySeconds } },
          '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
          withPeriodSeconds(periodSeconds): { livenessProbe+: { periodSeconds: periodSeconds } },
          '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
          withSuccessThreshold(successThreshold): { livenessProbe+: { successThreshold: successThreshold } },
          '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
          withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { livenessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
          '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
          withTimeoutSeconds(timeoutSeconds): { livenessProbe+: { timeoutSeconds: timeoutSeconds } },
        },
        '#ports':: d.obj(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."'),
        ports: {
          '#withContainerPort':: d.fn(help="\"Number of port to expose on the pod's IP address.\\nThis must be a valid port number, 0 \u003c x \u003c 65536.\"", args=[d.arg(name='containerPort', type=d.T.integer)]),
          withContainerPort(containerPort): { containerPort: containerPort },
          '#withHostIP':: d.fn(help='"What host IP to bind the external port to."', args=[d.arg(name='hostIP', type=d.T.string)]),
          withHostIP(hostIP): { hostIP: hostIP },
          '#withHostPort':: d.fn(help='"Number of port to expose on the host.\\nIf specified, this must be a valid port number, 0 < x < 65536.\\nIf HostNetwork is specified, this must match ContainerPort.\\nMost containers do not need this."', args=[d.arg(name='hostPort', type=d.T.integer)]),
          withHostPort(hostPort): { hostPort: hostPort },
          '#withName':: d.fn(help='"If specified, this must be an IANA_SVC_NAME and unique within the pod. Each\\nnamed port in a pod must have a unique name. Name for the port that can be\\nreferred to by services."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withProtocol':: d.fn(help='"Protocol for port. Must be UDP, TCP, or SCTP.\\nDefaults to \\"TCP\\"."', args=[d.arg(name='protocol', type=d.T.string)]),
          withProtocol(protocol): { protocol: protocol },
        },
        '#readinessProbe':: d.obj(help='"Periodic probe of container service readiness.\\nContainer will be removed from service endpoints if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
        readinessProbe: {
          '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
          exec: {
            '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { readinessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
            '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { readinessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
          },
          '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
          grpc: {
            '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { readinessProbe+: { grpc+: { port: port } } },
            '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
            withService(service): { readinessProbe+: { grpc+: { service: service } } },
          },
          '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
          httpGet: {
            '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
            httpHeaders: {
              '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { readinessProbe+: { httpGet+: { host: host } } },
            '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeaders(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeadersMixin(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { readinessProbe+: { httpGet+: { path: path } } },
            '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { readinessProbe+: { httpGet+: { port: port } } },
            '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
            withScheme(scheme): { readinessProbe+: { httpGet+: { scheme: scheme } } },
          },
          '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
          tcpSocket: {
            '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { readinessProbe+: { tcpSocket+: { host: host } } },
            '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { readinessProbe+: { tcpSocket+: { port: port } } },
          },
          '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
          withFailureThreshold(failureThreshold): { readinessProbe+: { failureThreshold: failureThreshold } },
          '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { readinessProbe+: { initialDelaySeconds: initialDelaySeconds } },
          '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
          withPeriodSeconds(periodSeconds): { readinessProbe+: { periodSeconds: periodSeconds } },
          '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
          withSuccessThreshold(successThreshold): { readinessProbe+: { successThreshold: successThreshold } },
          '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
          withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { readinessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
          '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
          withTimeoutSeconds(timeoutSeconds): { readinessProbe+: { timeoutSeconds: timeoutSeconds } },
        },
        '#resizePolicy':: d.obj(help='"Resources resize policy for the container."'),
        resizePolicy: {
          '#withResourceName':: d.fn(help='"Name of the resource to which this resource resize policy applies.\\nSupported values: cpu, memory."', args=[d.arg(name='resourceName', type=d.T.string)]),
          withResourceName(resourceName): { resourceName: resourceName },
          '#withRestartPolicy':: d.fn(help='"Restart policy to apply when specified resource is resized.\\nIf not specified, it defaults to NotRequired."', args=[d.arg(name='restartPolicy', type=d.T.string)]),
          withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
        },
        '#resources':: d.obj(help='"Compute Resources required by this container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { resources+: { limits: limits } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { resources+: { limits+: limits } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { resources+: { requests: requests } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { resources+: { requests+: requests } },
        },
        '#restartPolicyRules':: d.obj(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\""),
        restartPolicyRules: {
          '#exitCodes':: d.obj(help='"Represents the exit codes to check on container exits."'),
          exitCodes: {
            '#withOperator':: d.fn(help='"Represents the relationship between the container exit code(s) and the\\nspecified values. Possible values are:\\n- In: the requirement is satisfied if the container exit code is in the\\n  set of specified values.\\n- NotIn: the requirement is satisfied if the container exit code is\\n  not in the set of specified values."', args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { exitCodes+: { operator: operator } },
            '#withValues':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { exitCodes+: { values: if std.isArray(v=values) then values else [values] } },
            '#withValuesMixin':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { exitCodes+: { values+: if std.isArray(v=values) then values else [values] } },
          },
          '#withAction':: d.fn(help='"Specifies the action taken on a container exit if the requirements\\nare satisfied. The only possible value is \\"Restart\\" to restart the\\ncontainer."', args=[d.arg(name='action', type=d.T.string)]),
          withAction(action): { action: action },
        },
        '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
        securityContext: {
          '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
          appArmorProfile: {
            '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
            '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
          },
          '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
          capabilities: {
            '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
            withAdd(add): { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
            '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
            withAddMixin(add): { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
            '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
            withDrop(drop): { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
            '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
            withDropMixin(drop): { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
          },
          '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seLinuxOptions: {
            '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
            withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
            '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
            withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
            '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
            '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
            withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
          },
          '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seccompProfile: {
            '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
            '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { securityContext+: { seccompProfile+: { type: type } } },
          },
          '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
          windowsOptions: {
            '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
            withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
            '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
            withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
            '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
            withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
            '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
            withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
          },
          '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
          withAllowPrivilegeEscalation(allowPrivilegeEscalation): { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } },
          '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
          withPrivileged(privileged): { securityContext+: { privileged: privileged } },
          '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
          withProcMount(procMount): { securityContext+: { procMount: procMount } },
          '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
          withReadOnlyRootFilesystem(readOnlyRootFilesystem): { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } },
          '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
          withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
          '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
          withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
          '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
          withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
        },
        '#startupProbe':: d.obj(help="\"StartupProbe indicates that the Pod has successfully initialized.\\nIf specified, no other probes are executed until this completes successfully.\\nIf this probe fails, the Pod will be restarted, just as if the livenessProbe failed.\\nThis can be used to provide different probe parameters at the beginning of a Pod's lifecycle,\\nwhen it might take a long time to load data or warm a cache, than during steady-state operation.\\nThis cannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes\""),
        startupProbe: {
          '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
          exec: {
            '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { startupProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
            '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { startupProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
          },
          '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
          grpc: {
            '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { startupProbe+: { grpc+: { port: port } } },
            '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
            withService(service): { startupProbe+: { grpc+: { service: service } } },
          },
          '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
          httpGet: {
            '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
            httpHeaders: {
              '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { startupProbe+: { httpGet+: { host: host } } },
            '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeaders(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeadersMixin(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { startupProbe+: { httpGet+: { path: path } } },
            '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { startupProbe+: { httpGet+: { port: port } } },
            '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
            withScheme(scheme): { startupProbe+: { httpGet+: { scheme: scheme } } },
          },
          '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
          tcpSocket: {
            '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { startupProbe+: { tcpSocket+: { host: host } } },
            '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { startupProbe+: { tcpSocket+: { port: port } } },
          },
          '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
          withFailureThreshold(failureThreshold): { startupProbe+: { failureThreshold: failureThreshold } },
          '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { startupProbe+: { initialDelaySeconds: initialDelaySeconds } },
          '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
          withPeriodSeconds(periodSeconds): { startupProbe+: { periodSeconds: periodSeconds } },
          '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
          withSuccessThreshold(successThreshold): { startupProbe+: { successThreshold: successThreshold } },
          '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
          withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { startupProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
          '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
          withTimeoutSeconds(timeoutSeconds): { startupProbe+: { timeoutSeconds: timeoutSeconds } },
        },
        '#volumeDevices':: d.obj(help='"volumeDevices is the list of block devices to be used by the container."'),
        volumeDevices: {
          '#withDevicePath':: d.fn(help='"devicePath is the path inside of the container that the device will be mapped to."', args=[d.arg(name='devicePath', type=d.T.string)]),
          withDevicePath(devicePath): { devicePath: devicePath },
          '#withName':: d.fn(help='"name must match the name of a persistentVolumeClaim in the pod"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#volumeMounts':: d.obj(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\""),
        volumeMounts: {
          '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
          withMountPath(mountPath): { mountPath: mountPath },
          '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
          withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
          '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { readOnly: readOnly },
          '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
          withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
          '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
          withSubPath(subPath): { subPath: subPath },
          '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
          withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
        },
        '#withArgs':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='args', type=d.T.array)]),
        withArgs(args): { args: if std.isArray(v=args) then args else [args] },
        '#withArgsMixin':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
        withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
        '#withCommand':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='command', type=d.T.array)]),
        withCommand(command): { command: if std.isArray(v=command) then command else [command] },
        '#withCommandMixin':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
        withCommandMixin(command): { command+: if std.isArray(v=command) then command else [command] },
        '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."', args=[d.arg(name='env', type=d.T.array)]),
        withEnv(env): { env: if std.isArray(v=env) then env else [env] },
        '#withEnvFrom':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"", args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFrom(envFrom): { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] },
        '#withEnvFromMixin':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFromMixin(envFrom): { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] },
        '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
        withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
        '#withImage':: d.fn(help='"Container image name.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='image', type=d.T.string)]),
        withImage(image): { image: image },
        '#withImagePullPolicy':: d.fn(help='"Image pull policy.\\nOne of Always, Never, IfNotPresent.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#updating-images"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
        withImagePullPolicy(imagePullPolicy): { imagePullPolicy: imagePullPolicy },
        '#withName':: d.fn(help='"Name of the container specified as a DNS_LABEL.\\nEach container in a pod must have a unique name (DNS_LABEL).\\nCannot be updated."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withPorts':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."', args=[d.arg(name='ports', type=d.T.array)]),
        withPorts(ports): { ports: if std.isArray(v=ports) then ports else [ports] },
        '#withPortsMixin':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
        withPortsMixin(ports): { ports+: if std.isArray(v=ports) then ports else [ports] },
        '#withResizePolicy':: d.fn(help='"Resources resize policy for the container."', args=[d.arg(name='resizePolicy', type=d.T.array)]),
        withResizePolicy(resizePolicy): { resizePolicy: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
        '#withResizePolicyMixin':: d.fn(help='"Resources resize policy for the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resizePolicy', type=d.T.array)]),
        withResizePolicyMixin(resizePolicy): { resizePolicy+: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
        '#withRestartPolicy':: d.fn(help="\"RestartPolicy defines the restart behavior of individual containers in a pod.\\nThis overrides the pod-level restart policy. When this field is not specified,\\nthe restart behavior is defined by the Pod's restart policy and the container type.\\nAdditionally, setting the RestartPolicy as \\\"Always\\\" for the init container will\\nhave the following effect:\\nthis init container will be continually restarted on\\nexit until all regular containers have terminated. Once all regular\\ncontainers have completed, all init containers with restartPolicy \\\"Always\\\"\\nwill be shut down. This lifecycle differs from normal init containers and\\nis often referred to as a \\\"sidecar\\\" container. Although this init\\ncontainer still starts in the init container sequence, it does not wait\\nfor the container to complete before proceeding to the next init\\ncontainer. Instead, the next init container starts immediately after this\\ninit container is started, or after any startupProbe has successfully\\ncompleted.\"", args=[d.arg(name='restartPolicy', type=d.T.string)]),
        withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
        '#withRestartPolicyRules':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
        withRestartPolicyRules(restartPolicyRules): { restartPolicyRules: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
        '#withRestartPolicyRulesMixin':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
        withRestartPolicyRulesMixin(restartPolicyRules): { restartPolicyRules+: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
        '#withStdin':: d.fn(help='"Whether this container should allocate a buffer for stdin in the container runtime. If this\\nis not set, reads from stdin in the container will always result in EOF.\\nDefault is false."', args=[d.arg(name='stdin', type=d.T.boolean)]),
        withStdin(stdin): { stdin: stdin },
        '#withStdinOnce':: d.fn(help='"Whether the container runtime should close the stdin channel after it has been opened by\\na single attach. When stdin is true the stdin stream will remain open across multiple attach\\nsessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the\\nfirst client attaches to stdin, and then remains open and accepts data until the client disconnects,\\nat which time stdin is closed and remains closed until the container is restarted. If this\\nflag is false, a container processes that reads from stdin will never receive an EOF.\\nDefault is false"', args=[d.arg(name='stdinOnce', type=d.T.boolean)]),
        withStdinOnce(stdinOnce): { stdinOnce: stdinOnce },
        '#withTerminationMessagePath':: d.fn(help="\"Optional: Path at which the file to which the container's termination message\\nwill be written is mounted into the container's filesystem.\\nMessage written is intended to be brief final status, such as an assertion failure message.\\nWill be truncated by the node if greater than 4096 bytes. The total message length across\\nall containers will be limited to 12kb.\\nDefaults to /dev/termination-log.\\nCannot be updated.\"", args=[d.arg(name='terminationMessagePath', type=d.T.string)]),
        withTerminationMessagePath(terminationMessagePath): { terminationMessagePath: terminationMessagePath },
        '#withTerminationMessagePolicy':: d.fn(help='"Indicate how the termination message should be populated. File will use the contents of\\nterminationMessagePath to populate the container status message on both success and failure.\\nFallbackToLogsOnError will use the last chunk of container log output if the termination\\nmessage file is empty and the container exited with an error.\\nThe log output is limited to 2048 bytes or 80 lines, whichever is smaller.\\nDefaults to File.\\nCannot be updated."', args=[d.arg(name='terminationMessagePolicy', type=d.T.string)]),
        withTerminationMessagePolicy(terminationMessagePolicy): { terminationMessagePolicy: terminationMessagePolicy },
        '#withTty':: d.fn(help="\"Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.\\nDefault is false.\"", args=[d.arg(name='tty', type=d.T.boolean)]),
        withTty(tty): { tty: tty },
        '#withVolumeDevices':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."', args=[d.arg(name='volumeDevices', type=d.T.array)]),
        withVolumeDevices(volumeDevices): { volumeDevices: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
        '#withVolumeDevicesMixin':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeDevices', type=d.T.array)]),
        withVolumeDevicesMixin(volumeDevices): { volumeDevices+: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
        '#withVolumeMounts':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
        withVolumeMounts(volumeMounts): { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
        '#withVolumeMountsMixin':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
        withVolumeMountsMixin(volumeMounts): { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
        '#withWorkingDir':: d.fn(help="\"Container's working directory.\\nIf not specified, the container runtime's default will be used, which\\nmight be configured in the container image.\\nCannot be updated.\"", args=[d.arg(name='workingDir', type=d.T.string)]),
        withWorkingDir(workingDir): { workingDir: workingDir },
      },
      '#metadata':: d.obj(help='"Metadata contains metadata for custom resources"'),
      metadata: {
        '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotations(annotations): { metadata+: { annotations: annotations } },
        '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
        withAnnotationsMixin(annotations): { metadata+: { annotations+: annotations } },
        '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
        withLabels(labels): { metadata+: { labels: labels } },
        '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
        withLabelsMixin(labels): { metadata+: { labels+: labels } },
      },
      '#resources':: d.obj(help='"Compute resources of a PostgreSQL container."'),
      resources: {
        '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
        claims: {
          '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
          withRequest(request): { request: request },
        },
        '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
        withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
        '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
        withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { resources+: { limits: limits } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { resources+: { limits+: limits } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { resources+: { requests: requests } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { resources+: { requests+: requests } },
      },
      '#securityContext':: d.obj(help='"SecurityContext defines the security settings for a PostgreSQL pod."'),
      securityContext: {
        '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
        appArmorProfile: {
          '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
          withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
          '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
        },
        '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
        seLinuxOptions: {
          '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
          withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
          '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
          withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
          '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
          '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
          withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
        },
        '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
        seccompProfile: {
          '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
          withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
          '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { securityContext+: { seccompProfile+: { type: type } } },
        },
        '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
        sysctls: {
          '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
        windowsOptions: {
          '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
          withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
          '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
          withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
          '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
          withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
          '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
          withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
        },
        '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
        withFsGroup(fsGroup): { securityContext+: { fsGroup: fsGroup } },
        '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
        withFsGroupChangePolicy(fsGroupChangePolicy): { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } },
        '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
        withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
        '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
        withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
        '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
        withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
        '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
        withSeLinuxChangePolicy(seLinuxChangePolicy): { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } },
        '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
        withSupplementalGroups(supplementalGroups): { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } },
        '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
        withSupplementalGroupsMixin(supplementalGroups): { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } },
        '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
        withSupplementalGroupsPolicy(supplementalGroupsPolicy): { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } },
        '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
        withSysctls(sysctls): { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } },
        '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
        withSysctlsMixin(sysctls): { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } },
      },
      '#sidecars':: d.obj(help='"Custom sidecars for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."'),
      sidecars: {
        '#env':: d.obj(help='"List of environment variables to set in the container.\\nCannot be updated."'),
        env: {
          '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
          valueFrom: {
            '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
            configMapKeyRef: {
              '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
            },
            '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
            fieldRef: {
              '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
              withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
              '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
              withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
            },
            '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
            fileKeyRef: {
              '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
              '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
              '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
              '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
            },
            '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
            resourceFieldRef: {
              '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
              withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
              '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
              withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
              '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
              withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
            },
            '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
            secretKeyRef: {
              '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
            },
          },
          '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#envFrom':: d.obj(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\""),
        envFrom: {
          '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
          configMapRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { configMapRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { configMapRef+: { optional: optional } },
          },
          '#secretRef':: d.obj(help='"The Secret to select from"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { secretRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { secretRef+: { optional: optional } },
          },
          '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
          withPrefix(prefix): { prefix: prefix },
        },
        '#lifecycle':: d.obj(help='"Actions that the management system should take in response to container lifecycle events.\\nCannot be updated."'),
        lifecycle: {
          '#postStart':: d.obj(help='"PostStart is called immediately after a container is created. If the handler fails,\\nthe container is terminated and restarted according to its restart policy.\\nOther management of the container blocks until the hook completes.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks"'),
          postStart: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { lifecycle+: { postStart+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { lifecycle+: { postStart+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { postStart+: { httpGet+: { host: host } } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { lifecycle+: { postStart+: { httpGet+: { path: path } } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { postStart+: { httpGet+: { port: port } } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { lifecycle+: { postStart+: { httpGet+: { scheme: scheme } } } },
            },
            '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
            sleep: {
              '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
              withSeconds(seconds): { lifecycle+: { postStart+: { sleep+: { seconds: seconds } } } },
            },
            '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { postStart+: { tcpSocket+: { host: host } } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { postStart+: { tcpSocket+: { port: port } } } },
            },
          },
          '#preStop':: d.obj(help="\"PreStop is called immediately before a container is terminated due to an\\nAPI request or management event such as liveness/startup probe failure,\\npreemption, resource contention, etc. The handler is not called if the\\ncontainer crashes or exits. The Pod's termination grace period countdown begins before the\\nPreStop hook is executed. Regardless of the outcome of the handler, the\\ncontainer will eventually terminate within the Pod's termination grace\\nperiod (unless delayed by finalizers). Other management of the container blocks until the hook completes\\nor until the termination grace period is reached.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks\""),
          preStop: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { lifecycle+: { preStop+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { lifecycle+: { preStop+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { preStop+: { httpGet+: { host: host } } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { lifecycle+: { preStop+: { httpGet+: { path: path } } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { preStop+: { httpGet+: { port: port } } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { lifecycle+: { preStop+: { httpGet+: { scheme: scheme } } } },
            },
            '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
            sleep: {
              '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
              withSeconds(seconds): { lifecycle+: { preStop+: { sleep+: { seconds: seconds } } } },
            },
            '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { lifecycle+: { preStop+: { tcpSocket+: { host: host } } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { lifecycle+: { preStop+: { tcpSocket+: { port: port } } } },
            },
          },
          '#withStopSignal':: d.fn(help='"StopSignal defines which signal will be sent to a container when it is being stopped.\\nIf not specified, the default is defined by the container runtime in use.\\nStopSignal can only be set for Pods with a non-empty .spec.os.name"', args=[d.arg(name='stopSignal', type=d.T.string)]),
          withStopSignal(stopSignal): { lifecycle+: { stopSignal: stopSignal } },
        },
        '#livenessProbe':: d.obj(help='"Periodic probe of container liveness.\\nContainer will be restarted if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
        livenessProbe: {
          '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
          exec: {
            '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { livenessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
            '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { livenessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
          },
          '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
          grpc: {
            '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { livenessProbe+: { grpc+: { port: port } } },
            '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
            withService(service): { livenessProbe+: { grpc+: { service: service } } },
          },
          '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
          httpGet: {
            '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
            httpHeaders: {
              '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { livenessProbe+: { httpGet+: { host: host } } },
            '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeaders(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeadersMixin(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { livenessProbe+: { httpGet+: { path: path } } },
            '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { livenessProbe+: { httpGet+: { port: port } } },
            '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
            withScheme(scheme): { livenessProbe+: { httpGet+: { scheme: scheme } } },
          },
          '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
          tcpSocket: {
            '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { livenessProbe+: { tcpSocket+: { host: host } } },
            '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { livenessProbe+: { tcpSocket+: { port: port } } },
          },
          '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
          withFailureThreshold(failureThreshold): { livenessProbe+: { failureThreshold: failureThreshold } },
          '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { livenessProbe+: { initialDelaySeconds: initialDelaySeconds } },
          '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
          withPeriodSeconds(periodSeconds): { livenessProbe+: { periodSeconds: periodSeconds } },
          '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
          withSuccessThreshold(successThreshold): { livenessProbe+: { successThreshold: successThreshold } },
          '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
          withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { livenessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
          '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
          withTimeoutSeconds(timeoutSeconds): { livenessProbe+: { timeoutSeconds: timeoutSeconds } },
        },
        '#ports':: d.obj(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."'),
        ports: {
          '#withContainerPort':: d.fn(help="\"Number of port to expose on the pod's IP address.\\nThis must be a valid port number, 0 \u003c x \u003c 65536.\"", args=[d.arg(name='containerPort', type=d.T.integer)]),
          withContainerPort(containerPort): { containerPort: containerPort },
          '#withHostIP':: d.fn(help='"What host IP to bind the external port to."', args=[d.arg(name='hostIP', type=d.T.string)]),
          withHostIP(hostIP): { hostIP: hostIP },
          '#withHostPort':: d.fn(help='"Number of port to expose on the host.\\nIf specified, this must be a valid port number, 0 < x < 65536.\\nIf HostNetwork is specified, this must match ContainerPort.\\nMost containers do not need this."', args=[d.arg(name='hostPort', type=d.T.integer)]),
          withHostPort(hostPort): { hostPort: hostPort },
          '#withName':: d.fn(help='"If specified, this must be an IANA_SVC_NAME and unique within the pod. Each\\nnamed port in a pod must have a unique name. Name for the port that can be\\nreferred to by services."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withProtocol':: d.fn(help='"Protocol for port. Must be UDP, TCP, or SCTP.\\nDefaults to \\"TCP\\"."', args=[d.arg(name='protocol', type=d.T.string)]),
          withProtocol(protocol): { protocol: protocol },
        },
        '#readinessProbe':: d.obj(help='"Periodic probe of container service readiness.\\nContainer will be removed from service endpoints if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
        readinessProbe: {
          '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
          exec: {
            '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { readinessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
            '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { readinessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
          },
          '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
          grpc: {
            '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { readinessProbe+: { grpc+: { port: port } } },
            '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
            withService(service): { readinessProbe+: { grpc+: { service: service } } },
          },
          '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
          httpGet: {
            '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
            httpHeaders: {
              '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { readinessProbe+: { httpGet+: { host: host } } },
            '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeaders(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeadersMixin(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { readinessProbe+: { httpGet+: { path: path } } },
            '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { readinessProbe+: { httpGet+: { port: port } } },
            '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
            withScheme(scheme): { readinessProbe+: { httpGet+: { scheme: scheme } } },
          },
          '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
          tcpSocket: {
            '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { readinessProbe+: { tcpSocket+: { host: host } } },
            '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { readinessProbe+: { tcpSocket+: { port: port } } },
          },
          '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
          withFailureThreshold(failureThreshold): { readinessProbe+: { failureThreshold: failureThreshold } },
          '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { readinessProbe+: { initialDelaySeconds: initialDelaySeconds } },
          '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
          withPeriodSeconds(periodSeconds): { readinessProbe+: { periodSeconds: periodSeconds } },
          '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
          withSuccessThreshold(successThreshold): { readinessProbe+: { successThreshold: successThreshold } },
          '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
          withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { readinessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
          '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
          withTimeoutSeconds(timeoutSeconds): { readinessProbe+: { timeoutSeconds: timeoutSeconds } },
        },
        '#resizePolicy':: d.obj(help='"Resources resize policy for the container."'),
        resizePolicy: {
          '#withResourceName':: d.fn(help='"Name of the resource to which this resource resize policy applies.\\nSupported values: cpu, memory."', args=[d.arg(name='resourceName', type=d.T.string)]),
          withResourceName(resourceName): { resourceName: resourceName },
          '#withRestartPolicy':: d.fn(help='"Restart policy to apply when specified resource is resized.\\nIf not specified, it defaults to NotRequired."', args=[d.arg(name='restartPolicy', type=d.T.string)]),
          withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
        },
        '#resources':: d.obj(help='"Compute Resources required by this container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { resources+: { limits: limits } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { resources+: { limits+: limits } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { resources+: { requests: requests } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { resources+: { requests+: requests } },
        },
        '#restartPolicyRules':: d.obj(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\""),
        restartPolicyRules: {
          '#exitCodes':: d.obj(help='"Represents the exit codes to check on container exits."'),
          exitCodes: {
            '#withOperator':: d.fn(help='"Represents the relationship between the container exit code(s) and the\\nspecified values. Possible values are:\\n- In: the requirement is satisfied if the container exit code is in the\\n  set of specified values.\\n- NotIn: the requirement is satisfied if the container exit code is\\n  not in the set of specified values."', args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { exitCodes+: { operator: operator } },
            '#withValues':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { exitCodes+: { values: if std.isArray(v=values) then values else [values] } },
            '#withValuesMixin':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { exitCodes+: { values+: if std.isArray(v=values) then values else [values] } },
          },
          '#withAction':: d.fn(help='"Specifies the action taken on a container exit if the requirements\\nare satisfied. The only possible value is \\"Restart\\" to restart the\\ncontainer."', args=[d.arg(name='action', type=d.T.string)]),
          withAction(action): { action: action },
        },
        '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
        securityContext: {
          '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
          appArmorProfile: {
            '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
            '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
          },
          '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
          capabilities: {
            '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
            withAdd(add): { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
            '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
            withAddMixin(add): { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
            '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
            withDrop(drop): { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
            '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
            withDropMixin(drop): { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
          },
          '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seLinuxOptions: {
            '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
            withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
            '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
            withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
            '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
            '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
            withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
          },
          '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seccompProfile: {
            '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
            '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { securityContext+: { seccompProfile+: { type: type } } },
          },
          '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
          windowsOptions: {
            '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
            withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
            '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
            withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
            '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
            withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
            '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
            withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
          },
          '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
          withAllowPrivilegeEscalation(allowPrivilegeEscalation): { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } },
          '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
          withPrivileged(privileged): { securityContext+: { privileged: privileged } },
          '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
          withProcMount(procMount): { securityContext+: { procMount: procMount } },
          '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
          withReadOnlyRootFilesystem(readOnlyRootFilesystem): { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } },
          '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
          withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
          '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
          withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
          '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
          withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
        },
        '#startupProbe':: d.obj(help="\"StartupProbe indicates that the Pod has successfully initialized.\\nIf specified, no other probes are executed until this completes successfully.\\nIf this probe fails, the Pod will be restarted, just as if the livenessProbe failed.\\nThis can be used to provide different probe parameters at the beginning of a Pod's lifecycle,\\nwhen it might take a long time to load data or warm a cache, than during steady-state operation.\\nThis cannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes\""),
        startupProbe: {
          '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
          exec: {
            '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
            withCommand(command): { startupProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
            '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
            withCommandMixin(command): { startupProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
          },
          '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
          grpc: {
            '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
            withPort(port): { startupProbe+: { grpc+: { port: port } } },
            '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
            withService(service): { startupProbe+: { grpc+: { service: service } } },
          },
          '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
          httpGet: {
            '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
            httpHeaders: {
              '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
              withValue(value): { value: value },
            },
            '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { startupProbe+: { httpGet+: { host: host } } },
            '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeaders(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
            withHttpHeadersMixin(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
            '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { startupProbe+: { httpGet+: { path: path } } },
            '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { startupProbe+: { httpGet+: { port: port } } },
            '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
            withScheme(scheme): { startupProbe+: { httpGet+: { scheme: scheme } } },
          },
          '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
          tcpSocket: {
            '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
            withHost(host): { startupProbe+: { tcpSocket+: { host: host } } },
            '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
            withPort(port): { startupProbe+: { tcpSocket+: { port: port } } },
          },
          '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
          withFailureThreshold(failureThreshold): { startupProbe+: { failureThreshold: failureThreshold } },
          '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
          withInitialDelaySeconds(initialDelaySeconds): { startupProbe+: { initialDelaySeconds: initialDelaySeconds } },
          '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
          withPeriodSeconds(periodSeconds): { startupProbe+: { periodSeconds: periodSeconds } },
          '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
          withSuccessThreshold(successThreshold): { startupProbe+: { successThreshold: successThreshold } },
          '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
          withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { startupProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
          '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
          withTimeoutSeconds(timeoutSeconds): { startupProbe+: { timeoutSeconds: timeoutSeconds } },
        },
        '#volumeDevices':: d.obj(help='"volumeDevices is the list of block devices to be used by the container."'),
        volumeDevices: {
          '#withDevicePath':: d.fn(help='"devicePath is the path inside of the container that the device will be mapped to."', args=[d.arg(name='devicePath', type=d.T.string)]),
          withDevicePath(devicePath): { devicePath: devicePath },
          '#withName':: d.fn(help='"name must match the name of a persistentVolumeClaim in the pod"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
        },
        '#volumeMounts':: d.obj(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\""),
        volumeMounts: {
          '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
          withMountPath(mountPath): { mountPath: mountPath },
          '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
          withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
          '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
          withReadOnly(readOnly): { readOnly: readOnly },
          '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
          withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
          '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
          withSubPath(subPath): { subPath: subPath },
          '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
          withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
        },
        '#withArgs':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='args', type=d.T.array)]),
        withArgs(args): { args: if std.isArray(v=args) then args else [args] },
        '#withArgsMixin':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
        withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
        '#withCommand':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='command', type=d.T.array)]),
        withCommand(command): { command: if std.isArray(v=command) then command else [command] },
        '#withCommandMixin':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
        withCommandMixin(command): { command+: if std.isArray(v=command) then command else [command] },
        '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."', args=[d.arg(name='env', type=d.T.array)]),
        withEnv(env): { env: if std.isArray(v=env) then env else [env] },
        '#withEnvFrom':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"", args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFrom(envFrom): { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] },
        '#withEnvFromMixin':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFromMixin(envFrom): { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] },
        '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
        withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
        '#withImage':: d.fn(help='"Container image name.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='image', type=d.T.string)]),
        withImage(image): { image: image },
        '#withImagePullPolicy':: d.fn(help='"Image pull policy.\\nOne of Always, Never, IfNotPresent.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#updating-images"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
        withImagePullPolicy(imagePullPolicy): { imagePullPolicy: imagePullPolicy },
        '#withName':: d.fn(help='"Name of the container specified as a DNS_LABEL.\\nEach container in a pod must have a unique name (DNS_LABEL).\\nCannot be updated."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withPorts':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."', args=[d.arg(name='ports', type=d.T.array)]),
        withPorts(ports): { ports: if std.isArray(v=ports) then ports else [ports] },
        '#withPortsMixin':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
        withPortsMixin(ports): { ports+: if std.isArray(v=ports) then ports else [ports] },
        '#withResizePolicy':: d.fn(help='"Resources resize policy for the container."', args=[d.arg(name='resizePolicy', type=d.T.array)]),
        withResizePolicy(resizePolicy): { resizePolicy: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
        '#withResizePolicyMixin':: d.fn(help='"Resources resize policy for the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resizePolicy', type=d.T.array)]),
        withResizePolicyMixin(resizePolicy): { resizePolicy+: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
        '#withRestartPolicy':: d.fn(help="\"RestartPolicy defines the restart behavior of individual containers in a pod.\\nThis overrides the pod-level restart policy. When this field is not specified,\\nthe restart behavior is defined by the Pod's restart policy and the container type.\\nAdditionally, setting the RestartPolicy as \\\"Always\\\" for the init container will\\nhave the following effect:\\nthis init container will be continually restarted on\\nexit until all regular containers have terminated. Once all regular\\ncontainers have completed, all init containers with restartPolicy \\\"Always\\\"\\nwill be shut down. This lifecycle differs from normal init containers and\\nis often referred to as a \\\"sidecar\\\" container. Although this init\\ncontainer still starts in the init container sequence, it does not wait\\nfor the container to complete before proceeding to the next init\\ncontainer. Instead, the next init container starts immediately after this\\ninit container is started, or after any startupProbe has successfully\\ncompleted.\"", args=[d.arg(name='restartPolicy', type=d.T.string)]),
        withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
        '#withRestartPolicyRules':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
        withRestartPolicyRules(restartPolicyRules): { restartPolicyRules: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
        '#withRestartPolicyRulesMixin':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
        withRestartPolicyRulesMixin(restartPolicyRules): { restartPolicyRules+: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
        '#withStdin':: d.fn(help='"Whether this container should allocate a buffer for stdin in the container runtime. If this\\nis not set, reads from stdin in the container will always result in EOF.\\nDefault is false."', args=[d.arg(name='stdin', type=d.T.boolean)]),
        withStdin(stdin): { stdin: stdin },
        '#withStdinOnce':: d.fn(help='"Whether the container runtime should close the stdin channel after it has been opened by\\na single attach. When stdin is true the stdin stream will remain open across multiple attach\\nsessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the\\nfirst client attaches to stdin, and then remains open and accepts data until the client disconnects,\\nat which time stdin is closed and remains closed until the container is restarted. If this\\nflag is false, a container processes that reads from stdin will never receive an EOF.\\nDefault is false"', args=[d.arg(name='stdinOnce', type=d.T.boolean)]),
        withStdinOnce(stdinOnce): { stdinOnce: stdinOnce },
        '#withTerminationMessagePath':: d.fn(help="\"Optional: Path at which the file to which the container's termination message\\nwill be written is mounted into the container's filesystem.\\nMessage written is intended to be brief final status, such as an assertion failure message.\\nWill be truncated by the node if greater than 4096 bytes. The total message length across\\nall containers will be limited to 12kb.\\nDefaults to /dev/termination-log.\\nCannot be updated.\"", args=[d.arg(name='terminationMessagePath', type=d.T.string)]),
        withTerminationMessagePath(terminationMessagePath): { terminationMessagePath: terminationMessagePath },
        '#withTerminationMessagePolicy':: d.fn(help='"Indicate how the termination message should be populated. File will use the contents of\\nterminationMessagePath to populate the container status message on both success and failure.\\nFallbackToLogsOnError will use the last chunk of container log output if the termination\\nmessage file is empty and the container exited with an error.\\nThe log output is limited to 2048 bytes or 80 lines, whichever is smaller.\\nDefaults to File.\\nCannot be updated."', args=[d.arg(name='terminationMessagePolicy', type=d.T.string)]),
        withTerminationMessagePolicy(terminationMessagePolicy): { terminationMessagePolicy: terminationMessagePolicy },
        '#withTty':: d.fn(help="\"Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.\\nDefault is false.\"", args=[d.arg(name='tty', type=d.T.boolean)]),
        withTty(tty): { tty: tty },
        '#withVolumeDevices':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."', args=[d.arg(name='volumeDevices', type=d.T.array)]),
        withVolumeDevices(volumeDevices): { volumeDevices: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
        '#withVolumeDevicesMixin':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeDevices', type=d.T.array)]),
        withVolumeDevicesMixin(volumeDevices): { volumeDevices+: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
        '#withVolumeMounts':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
        withVolumeMounts(volumeMounts): { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
        '#withVolumeMountsMixin':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
        withVolumeMountsMixin(volumeMounts): { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
        '#withWorkingDir':: d.fn(help="\"Container's working directory.\\nIf not specified, the container runtime's default will be used, which\\nmight be configured in the container image.\\nCannot be updated.\"", args=[d.arg(name='workingDir', type=d.T.string)]),
        withWorkingDir(workingDir): { workingDir: workingDir },
      },
      '#tablespaceVolumes':: d.obj(help='"The list of tablespaces volumes to mount for this postgrescluster\\nThis field requires enabling TablespaceVolumes feature gate"'),
      tablespaceVolumes: {
        '#dataVolumeClaimSpec':: d.obj(help='"Defines a PersistentVolumeClaim for a tablespace.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes"'),
        dataVolumeClaimSpec: {
          '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
          dataSource: {
            '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
            withApiGroup(apiGroup): { dataVolumeClaimSpec+: { dataSource+: { apiGroup: apiGroup } } },
            '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { dataVolumeClaimSpec+: { dataSource+: { kind: kind } } },
            '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { dataVolumeClaimSpec+: { dataSource+: { name: name } } },
          },
          '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
          dataSourceRef: {
            '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
            withApiGroup(apiGroup): { dataVolumeClaimSpec+: { dataSourceRef+: { apiGroup: apiGroup } } },
            '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
            withKind(kind): { dataVolumeClaimSpec+: { dataSourceRef+: { kind: kind } } },
            '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { dataVolumeClaimSpec+: { dataSourceRef+: { name: name } } },
            '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
            withNamespace(namespace): { dataVolumeClaimSpec+: { dataSourceRef+: { namespace: namespace } } },
          },
          '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
          resources: {
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { dataVolumeClaimSpec+: { resources+: { limits: limits } } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { dataVolumeClaimSpec+: { resources+: { limits+: limits } } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { dataVolumeClaimSpec+: { resources+: { requests: requests } } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { dataVolumeClaimSpec+: { resources+: { requests+: requests } } },
          },
          '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
          selector: {
            '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
            matchExpressions: {
              '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { operator: operator },
              '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
              withValues(values): { values: if std.isArray(v=values) then values else [values] },
              '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
              withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
            },
            '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressions(matchExpressions): { dataVolumeClaimSpec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
            '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressionsMixin(matchExpressions): { dataVolumeClaimSpec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
            '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { dataVolumeClaimSpec+: { selector+: { matchLabels: matchLabels } } },
            '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { dataVolumeClaimSpec+: { selector+: { matchLabels+: matchLabels } } },
          },
          '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
          withAccessModes(accessModes): { dataVolumeClaimSpec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
          '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
          withAccessModesMixin(accessModes): { dataVolumeClaimSpec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
          '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
          withStorageClassName(storageClassName): { dataVolumeClaimSpec+: { storageClassName: storageClassName } },
          '#withVolumeAttributesClassName':: d.fn(help='"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string or nil value indicates that no\\nVolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,\\nthis field can be reset to its previous value (including nil) to cancel the modification.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/"', args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
          withVolumeAttributesClassName(volumeAttributesClassName): { dataVolumeClaimSpec+: { volumeAttributesClassName: volumeAttributesClassName } },
          '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
          withVolumeMode(volumeMode): { dataVolumeClaimSpec+: { volumeMode: volumeMode } },
          '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
          withVolumeName(volumeName): { dataVolumeClaimSpec+: { volumeName: volumeName } },
        },
        '#withName':: d.fn(help='"The name for the tablespace, used as the path name for the volume.\\nMust be unique in the instance set since they become the directory names."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
      },
      '#tolerations':: d.obj(help='"Tolerations of a PostgreSQL pod. Changing this value causes PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
      tolerations: {
        '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
        withEffect(effect): { effect: effect },
        '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
        withKey(key): { key: key },
        '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
        withOperator(operator): { operator: operator },
        '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
        withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
        '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
        withValue(value): { value: value },
      },
      '#topologySpreadConstraints':: d.obj(help='"Topology spread constraints of a PostgreSQL pod. Changing this value causes\\nPostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"'),
      topologySpreadConstraints: {
        '#labelSelector':: d.obj(help='"LabelSelector is used to find matching pods.\\nPods that match this label selector are counted to determine the number of pods\\nin their corresponding topology domain."'),
        labelSelector: {
          '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
          matchExpressions: {
            '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { values: if std.isArray(v=values) then values else [values] },
            '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
          },
          '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
          '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
          '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
          '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
        },
        '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
        withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
        '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
        withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
        '#withMaxSkew':: d.fn(help="\"MaxSkew describes the degree to which pods may be unevenly distributed.\\nWhen `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference\\nbetween the number of matching pods in the target topology and the global minimum.\\nThe global minimum is the minimum number of matching pods in an eligible domain\\nor zero if the number of eligible domains is less than MinDomains.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 2/2/1:\\nIn this case, the global minimum is 1.\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |   P   |\\n- if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;\\nscheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)\\nviolate MaxSkew(1).\\n- if MaxSkew is 2, incoming pod can be scheduled onto any zone.\\nWhen `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence\\nto topologies that satisfy it.\\nIt's a required field. Default value is 1 and 0 is not allowed.\"", args=[d.arg(name='maxSkew', type=d.T.integer)]),
        withMaxSkew(maxSkew): { maxSkew: maxSkew },
        '#withMinDomains':: d.fn(help="\"MinDomains indicates a minimum number of eligible domains.\\nWhen the number of eligible domains with matching topology keys is less than minDomains,\\nPod Topology Spread treats \\\"global minimum\\\" as 0, and then the calculation of Skew is performed.\\nAnd when the number of eligible domains with matching topology keys equals or greater than minDomains,\\nthis value has no effect on scheduling.\\nAs a result, when the number of eligible domains is less than minDomains,\\nscheduler won't schedule more than maxSkew Pods to those domains.\\nIf value is nil, the constraint behaves as if MinDomains is equal to 1.\\nValid values are integers greater than 0.\\nWhen value is not nil, WhenUnsatisfiable must be DoNotSchedule.\\n\\nFor example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same\\nlabelSelector spread as 2/2/2:\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |  P P  |\\nThe number of domains is less than 5(MinDomains), so \\\"global minimum\\\" is treated as 0.\\nIn this situation, new pod with the same labelSelector cannot be scheduled,\\nbecause computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,\\nit will violate MaxSkew.\"", args=[d.arg(name='minDomains', type=d.T.integer)]),
        withMinDomains(minDomains): { minDomains: minDomains },
        '#withNodeAffinityPolicy':: d.fn(help="\"NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector\\nwhen calculating pod topology spread skew. Options are:\\n- Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.\\n- Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.\\n\\nIf this value is nil, the behavior is equivalent to the Honor policy.\"", args=[d.arg(name='nodeAffinityPolicy', type=d.T.string)]),
        withNodeAffinityPolicy(nodeAffinityPolicy): { nodeAffinityPolicy: nodeAffinityPolicy },
        '#withNodeTaintsPolicy':: d.fn(help='"NodeTaintsPolicy indicates how we will treat node taints when calculating\\npod topology spread skew. Options are:\\n- Honor: nodes without taints, along with tainted nodes for which the incoming pod\\nhas a toleration, are included.\\n- Ignore: node taints are ignored. All nodes are included.\\n\\nIf this value is nil, the behavior is equivalent to the Ignore policy."', args=[d.arg(name='nodeTaintsPolicy', type=d.T.string)]),
        withNodeTaintsPolicy(nodeTaintsPolicy): { nodeTaintsPolicy: nodeTaintsPolicy },
        '#withTopologyKey':: d.fn(help="\"TopologyKey is the key of node labels. Nodes that have a label with this key\\nand identical values are considered to be in the same topology.\\nWe consider each \u003ckey, value\u003e as a \\\"bucket\\\", and try to put balanced number\\nof pods into each bucket.\\nWe define a domain as a particular instance of a topology.\\nAlso, we define an eligible domain as a domain whose nodes meet the requirements of\\nnodeAffinityPolicy and nodeTaintsPolicy.\\ne.g. If TopologyKey is \\\"kubernetes.io/hostname\\\", each Node is a domain of that topology.\\nAnd, if TopologyKey is \\\"topology.kubernetes.io/zone\\\", each zone is a domain of that topology.\\nIt's a required field.\"", args=[d.arg(name='topologyKey', type=d.T.string)]),
        withTopologyKey(topologyKey): { topologyKey: topologyKey },
        '#withWhenUnsatisfiable':: d.fn(help="\"WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy\\nthe spread constraint.\\n- DoNotSchedule (default) tells the scheduler not to schedule it.\\n- ScheduleAnyway tells the scheduler to schedule the pod in any location,\\n  but giving higher precedence to topologies that would help reduce the\\n  skew.\\nA constraint is considered \\\"Unsatisfiable\\\" for an incoming pod\\nif and only if every possible node assignment for that pod would violate\\n\\\"MaxSkew\\\" on some topology.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 3/1/1:\\n| zone1 | zone2 | zone3 |\\n| P P P |   P   |   P   |\\nIf WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled\\nto zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies\\nMaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler\\nwon't make it *more* imbalanced.\\nIt's a required field.\"", args=[d.arg(name='whenUnsatisfiable', type=d.T.string)]),
        withWhenUnsatisfiable(whenUnsatisfiable): { whenUnsatisfiable: whenUnsatisfiable },
      },
      '#volumeMounts':: d.obj(help='"The list of volume mounts to mount to PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."'),
      volumeMounts: {
        '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
        withMountPath(mountPath): { mountPath: mountPath },
        '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
        withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
        '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { name: name },
        '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
        withReadOnly(readOnly): { readOnly: readOnly },
        '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
        withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
        '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
        withSubPath(subPath): { subPath: subPath },
        '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
        withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
      },
      '#walVolumeClaimSpec':: d.obj(help="\"Defines a separate PersistentVolumeClaim for PostgreSQL's write-ahead log.\\nMore info: https://www.postgresql.org/docs/current/wal.html\""),
      walVolumeClaimSpec: {
        '#dataSource':: d.obj(help='"dataSource field can be used to specify either:\\n* An existing VolumeSnapshot object (snapshot.storage.k8s.io/VolumeSnapshot)\\n* An existing PVC (PersistentVolumeClaim)\\nIf the provisioner or an external controller can support the specified data source,\\nit will create a new volume based on the contents of the specified data source.\\nWhen the AnyVolumeDataSource feature gate is enabled, dataSource contents will be copied to dataSourceRef,\\nand dataSourceRef contents will be copied to dataSource when dataSourceRef.namespace is not specified.\\nIf the namespace is specified, then dataSourceRef will not be copied to dataSource."'),
        dataSource: {
          '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
          withApiGroup(apiGroup): { walVolumeClaimSpec+: { dataSource+: { apiGroup: apiGroup } } },
          '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
          withKind(kind): { walVolumeClaimSpec+: { dataSource+: { kind: kind } } },
          '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { walVolumeClaimSpec+: { dataSource+: { name: name } } },
        },
        '#dataSourceRef':: d.obj(help="\"dataSourceRef specifies the object from which to populate the volume with data, if a non-empty\\nvolume is desired. This may be any object from a non-empty API group (non\\ncore object) or a PersistentVolumeClaim object.\\nWhen this field is specified, volume binding will only succeed if the type of\\nthe specified object matches some installed volume populator or dynamic\\nprovisioner.\\nThis field will replace the functionality of the dataSource field and as such\\nif both fields are non-empty, they must have the same value. For backwards\\ncompatibility, when namespace isn't specified in dataSourceRef,\\nboth fields (dataSource and dataSourceRef) will be set to the same\\nvalue automatically if one of them is empty and the other is non-empty.\\nWhen namespace is specified in dataSourceRef,\\ndataSource isn't set to the same value and must be empty.\\nThere are three important differences between dataSource and dataSourceRef:\\n* While dataSource only allows two specific types of objects, dataSourceRef\\n  allows any non-core object, as well as PersistentVolumeClaim objects.\\n* While dataSource ignores disallowed values (dropping them), dataSourceRef\\n  preserves all values, and generates an error if a disallowed value is\\n  specified.\\n* While dataSource only allows local objects, dataSourceRef allows objects\\n  in any namespaces.\\n(Beta) Using this field requires the AnyVolumeDataSource feature gate to be enabled.\\n(Alpha) Using the namespace field of dataSourceRef requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\""),
        dataSourceRef: {
          '#withApiGroup':: d.fn(help='"APIGroup is the group for the resource being referenced.\\nIf APIGroup is not specified, the specified Kind must be in the core API group.\\nFor any other third-party types, APIGroup is required."', args=[d.arg(name='apiGroup', type=d.T.string)]),
          withApiGroup(apiGroup): { walVolumeClaimSpec+: { dataSourceRef+: { apiGroup: apiGroup } } },
          '#withKind':: d.fn(help='"Kind is the type of resource being referenced"', args=[d.arg(name='kind', type=d.T.string)]),
          withKind(kind): { walVolumeClaimSpec+: { dataSourceRef+: { kind: kind } } },
          '#withName':: d.fn(help='"Name is the name of resource being referenced"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { walVolumeClaimSpec+: { dataSourceRef+: { name: name } } },
          '#withNamespace':: d.fn(help="\"Namespace is the namespace of resource being referenced\\nNote that when a namespace is specified, a gateway.networking.k8s.io/ReferenceGrant object is required in the referent namespace to allow that namespace's owner to accept the reference. See the ReferenceGrant documentation for details.\\n(Alpha) This field requires the CrossNamespaceVolumeDataSource feature gate to be enabled.\"", args=[d.arg(name='namespace', type=d.T.string)]),
          withNamespace(namespace): { walVolumeClaimSpec+: { dataSourceRef+: { namespace: namespace } } },
        },
        '#resources':: d.obj(help='"resources represents the minimum resources the volume should have.\\nIf RecoverVolumeExpansionFailure feature is enabled users are allowed to specify resource requirements\\nthat are lower than previous value but must still be higher than capacity recorded in the\\nstatus field of the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#resources"'),
        resources: {
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { walVolumeClaimSpec+: { resources+: { limits: limits } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { walVolumeClaimSpec+: { resources+: { limits+: limits } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { walVolumeClaimSpec+: { resources+: { requests: requests } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { walVolumeClaimSpec+: { resources+: { requests+: requests } } },
        },
        '#selector':: d.obj(help='"selector is a label query over volumes to consider for binding."'),
        selector: {
          '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
          matchExpressions: {
            '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
            withOperator(operator): { operator: operator },
            '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
            withValues(values): { values: if std.isArray(v=values) then values else [values] },
            '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
            withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
          },
          '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressions(matchExpressions): { walVolumeClaimSpec+: { selector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
          '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
          withMatchExpressionsMixin(matchExpressions): { walVolumeClaimSpec+: { selector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
          '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabels(matchLabels): { walVolumeClaimSpec+: { selector+: { matchLabels: matchLabels } } },
          '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
          withMatchLabelsMixin(matchLabels): { walVolumeClaimSpec+: { selector+: { matchLabels+: matchLabels } } },
        },
        '#withAccessModes':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"', args=[d.arg(name='accessModes', type=d.T.array)]),
        withAccessModes(accessModes): { walVolumeClaimSpec+: { accessModes: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
        '#withAccessModesMixin':: d.fn(help='"accessModes contains the desired access modes the volume should have.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#access-modes-1"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='accessModes', type=d.T.array)]),
        withAccessModesMixin(accessModes): { walVolumeClaimSpec+: { accessModes+: if std.isArray(v=accessModes) then accessModes else [accessModes] } },
        '#withStorageClassName':: d.fn(help='"storageClassName is the name of the StorageClass required by the claim.\\nMore info: https://kubernetes.io/docs/concepts/storage/persistent-volumes#class-1"', args=[d.arg(name='storageClassName', type=d.T.string)]),
        withStorageClassName(storageClassName): { walVolumeClaimSpec+: { storageClassName: storageClassName } },
        '#withVolumeAttributesClassName':: d.fn(help='"volumeAttributesClassName may be used to set the VolumeAttributesClass used by this claim.\\nIf specified, the CSI driver will create or update the volume with the attributes defined\\nin the corresponding VolumeAttributesClass. This has a different purpose than storageClassName,\\nit can be changed after the claim is created. An empty string or nil value indicates that no\\nVolumeAttributesClass will be applied to the claim. If the claim enters an Infeasible error state,\\nthis field can be reset to its previous value (including nil) to cancel the modification.\\nIf the resource referred to by volumeAttributesClass does not exist, this PersistentVolumeClaim will be\\nset to a Pending state, as reflected by the modifyVolumeStatus field, until such as a resource\\nexists.\\nMore info: https://kubernetes.io/docs/concepts/storage/volume-attributes-classes/"', args=[d.arg(name='volumeAttributesClassName', type=d.T.string)]),
        withVolumeAttributesClassName(volumeAttributesClassName): { walVolumeClaimSpec+: { volumeAttributesClassName: volumeAttributesClassName } },
        '#withVolumeMode':: d.fn(help='"volumeMode defines what type of volume is required by the claim.\\nValue of Filesystem is implied when not included in claim spec."', args=[d.arg(name='volumeMode', type=d.T.string)]),
        withVolumeMode(volumeMode): { walVolumeClaimSpec+: { volumeMode: volumeMode } },
        '#withVolumeName':: d.fn(help='"volumeName is the binding reference to the PersistentVolume backing this claim."', args=[d.arg(name='volumeName', type=d.T.string)]),
        withVolumeName(volumeName): { walVolumeClaimSpec+: { volumeName: volumeName } },
      },
      '#withEnv':: d.fn(help='', args=[d.arg(name='env', type=d.T.array)]),
      withEnv(env): { env: if std.isArray(v=env) then env else [env] },
      '#withEnvFrom':: d.fn(help='', args=[d.arg(name='envFrom', type=d.T.array)]),
      withEnvFrom(envFrom): { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] },
      '#withEnvFromMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='envFrom', type=d.T.array)]),
      withEnvFromMixin(envFrom): { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] },
      '#withEnvMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
      withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
      '#withInitContainers':: d.fn(help='"Additional init containers for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."', args=[d.arg(name='initContainers', type=d.T.array)]),
      withInitContainers(initContainers): { initContainers: if std.isArray(v=initContainers) then initContainers else [initContainers] },
      '#withInitContainersMixin':: d.fn(help='"Additional init containers for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='initContainers', type=d.T.array)]),
      withInitContainersMixin(initContainers): { initContainers+: if std.isArray(v=initContainers) then initContainers else [initContainers] },
      '#withMinAvailable':: d.fn(help='"Minimum number of pods that should be available at a time.\\nDefaults to one when the replicas field is greater than one."', args=[d.arg(name='minAvailable', type=d.T.any)]),
      withMinAvailable(minAvailable): { minAvailable: minAvailable },
      '#withName':: d.fn(help='"Name that associates this set of PostgreSQL pods. This field is optional\\nwhen only one instance set is defined. Each instance set in a cluster\\nmust have a unique name. The combined length of this and the cluster name\\nmust be 46 characters or less."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withPriorityClassName':: d.fn(help='"Priority class name for the PostgreSQL pod. Changing this value causes\\nPostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
      withPriorityClassName(priorityClassName): { priorityClassName: priorityClassName },
      '#withReplicas':: d.fn(help='"Number of desired PostgreSQL pods."', args=[d.arg(name='replicas', type=d.T.integer)]),
      withReplicas(replicas): { replicas: replicas },
      '#withSidecars':: d.fn(help='"Custom sidecars for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."', args=[d.arg(name='sidecars', type=d.T.array)]),
      withSidecars(sidecars): { sidecars: if std.isArray(v=sidecars) then sidecars else [sidecars] },
      '#withSidecarsMixin':: d.fn(help='"Custom sidecars for PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sidecars', type=d.T.array)]),
      withSidecarsMixin(sidecars): { sidecars+: if std.isArray(v=sidecars) then sidecars else [sidecars] },
      '#withTablespaceVolumes':: d.fn(help='"The list of tablespaces volumes to mount for this postgrescluster\\nThis field requires enabling TablespaceVolumes feature gate"', args=[d.arg(name='tablespaceVolumes', type=d.T.array)]),
      withTablespaceVolumes(tablespaceVolumes): { tablespaceVolumes: if std.isArray(v=tablespaceVolumes) then tablespaceVolumes else [tablespaceVolumes] },
      '#withTablespaceVolumesMixin':: d.fn(help='"The list of tablespaces volumes to mount for this postgrescluster\\nThis field requires enabling TablespaceVolumes feature gate"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tablespaceVolumes', type=d.T.array)]),
      withTablespaceVolumesMixin(tablespaceVolumes): { tablespaceVolumes+: if std.isArray(v=tablespaceVolumes) then tablespaceVolumes else [tablespaceVolumes] },
      '#withTolerations':: d.fn(help='"Tolerations of a PostgreSQL pod. Changing this value causes PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
      withTolerations(tolerations): { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] },
      '#withTolerationsMixin':: d.fn(help='"Tolerations of a PostgreSQL pod. Changing this value causes PostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
      withTolerationsMixin(tolerations): { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] },
      '#withTopologySpreadConstraints':: d.fn(help='"Topology spread constraints of a PostgreSQL pod. Changing this value causes\\nPostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
      withTopologySpreadConstraints(topologySpreadConstraints): { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] },
      '#withTopologySpreadConstraintsMixin':: d.fn(help='"Topology spread constraints of a PostgreSQL pod. Changing this value causes\\nPostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
      withTopologySpreadConstraintsMixin(topologySpreadConstraints): { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] },
      '#withVolumeMounts':: d.fn(help='"The list of volume mounts to mount to PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."', args=[d.arg(name='volumeMounts', type=d.T.array)]),
      withVolumeMounts(volumeMounts): { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
      '#withVolumeMountsMixin':: d.fn(help='"The list of volume mounts to mount to PostgreSQL instance pods. Changing this value causes\\nPostgreSQL to restart."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeMounts', type=d.T.array)]),
      withVolumeMountsMixin(volumeMounts): { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
    },
    '#metadata':: d.obj(help='"Metadata contains metadata for custom resources"'),
    metadata: {
      '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotations(annotations): { spec+: { metadata+: { annotations: annotations } } },
      '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
      withAnnotationsMixin(annotations): { spec+: { metadata+: { annotations+: annotations } } },
      '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
      withLabels(labels): { spec+: { metadata+: { labels: labels } } },
      '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
      withLabelsMixin(labels): { spec+: { metadata+: { labels+: labels } } },
    },
    '#patroni':: d.obj(help=''),
    patroni: {
      '#switchover':: d.obj(help='"Switchover gives options to perform ad hoc switchovers in a PostgresCluster."'),
      switchover: {
        '#withEnabled':: d.fn(help='"Whether or not the operator should allow switchovers in a PostgresCluster"', args=[d.arg(name='enabled', type=d.T.boolean)]),
        withEnabled(enabled): { spec+: { patroni+: { switchover+: { enabled: enabled } } } },
        '#withTargetInstance':: d.fn(help='"The instance that should become primary during a switchover. This field is\\noptional when Type is \\"Switchover\\" and required when Type is \\"Failover\\".\\nWhen it is not specified, a healthy replica is automatically selected."', args=[d.arg(name='targetInstance', type=d.T.string)]),
        withTargetInstance(targetInstance): { spec+: { patroni+: { switchover+: { targetInstance: targetInstance } } } },
        '#withType':: d.fn(help='"Type of switchover to perform. Valid options are Switchover and Failover.\\n\\"Switchover\\" changes the primary instance of a healthy PostgresCluster.\\n\\"Failover\\" forces a particular instance to be primary, regardless of other\\nfactors. A TargetInstance must be specified to failover.\\nNOTE: The Failover type is reserved as the \\"last resort\\" case."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { spec+: { patroni+: { switchover+: { type: type } } } },
      },
      '#withCreateReplicaMethods':: d.fn(help='"CreateReplicaMethods allows overriding create_replica_methods for all instances."', args=[d.arg(name='createReplicaMethods', type=d.T.array)]),
      withCreateReplicaMethods(createReplicaMethods): { spec+: { patroni+: { createReplicaMethods: if std.isArray(v=createReplicaMethods) then createReplicaMethods else [createReplicaMethods] } } },
      '#withCreateReplicaMethodsMixin':: d.fn(help='"CreateReplicaMethods allows overriding create_replica_methods for all instances."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='createReplicaMethods', type=d.T.array)]),
      withCreateReplicaMethodsMixin(createReplicaMethods): { spec+: { patroni+: { createReplicaMethods+: if std.isArray(v=createReplicaMethods) then createReplicaMethods else [createReplicaMethods] } } },
      '#withDynamicConfiguration':: d.fn(help='"Patroni dynamic configuration settings. Changes to this value will be\\nautomatically reloaded without validation. Changes to certain PostgreSQL\\nparameters cause PostgreSQL to restart.\\nMore info: https://patroni.readthedocs.io/en/latest/dynamic_configuration.html"', args=[d.arg(name='dynamicConfiguration', type=d.T.object)]),
      withDynamicConfiguration(dynamicConfiguration): { spec+: { patroni+: { dynamicConfiguration: dynamicConfiguration } } },
      '#withDynamicConfigurationMixin':: d.fn(help='"Patroni dynamic configuration settings. Changes to this value will be\\nautomatically reloaded without validation. Changes to certain PostgreSQL\\nparameters cause PostgreSQL to restart.\\nMore info: https://patroni.readthedocs.io/en/latest/dynamic_configuration.html"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='dynamicConfiguration', type=d.T.object)]),
      withDynamicConfigurationMixin(dynamicConfiguration): { spec+: { patroni+: { dynamicConfiguration+: dynamicConfiguration } } },
      '#withLeaderLeaseDurationSeconds':: d.fn(help='"TTL of the cluster leader lock. \\"Think of it as the\\nlength of time before initiation of the automatic failover process.\\"\\nChanging this value causes PostgreSQL to restart."', args=[d.arg(name='leaderLeaseDurationSeconds', type=d.T.integer)]),
      withLeaderLeaseDurationSeconds(leaderLeaseDurationSeconds): { spec+: { patroni+: { leaderLeaseDurationSeconds: leaderLeaseDurationSeconds } } },
      '#withPort':: d.fn(help='"The port on which Patroni should listen.\\nChanging this value causes PostgreSQL to restart."', args=[d.arg(name='port', type=d.T.integer)]),
      withPort(port): { spec+: { patroni+: { port: port } } },
      '#withSyncPeriodSeconds':: d.fn(help='"The interval for refreshing the leader lock and applying\\ndynamicConfiguration. Must be less than leaderLeaseDurationSeconds.\\nChanging this value causes PostgreSQL to restart."', args=[d.arg(name='syncPeriodSeconds', type=d.T.integer)]),
      withSyncPeriodSeconds(syncPeriodSeconds): { spec+: { patroni+: { syncPeriodSeconds: syncPeriodSeconds } } },
    },
    '#pmm':: d.obj(help='"The specification of PMM sidecars."'),
    pmm: {
      '#containerSecurityContext':: d.obj(help='"SecurityContext holds security configuration that will be applied to a container.\\nSome fields are present in both SecurityContext and PodSecurityContext.  When both\\nare set, the values in SecurityContext take precedence."'),
      containerSecurityContext: {
        '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
        appArmorProfile: {
          '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
          withLocalhostProfile(localhostProfile): { spec+: { pmm+: { containerSecurityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } },
          '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { pmm+: { containerSecurityContext+: { appArmorProfile+: { type: type } } } } },
        },
        '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
        capabilities: {
          '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
          withAdd(add): { spec+: { pmm+: { containerSecurityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } } } },
          '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
          withAddMixin(add): { spec+: { pmm+: { containerSecurityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } } } },
          '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
          withDrop(drop): { spec+: { pmm+: { containerSecurityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } } } },
          '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
          withDropMixin(drop): { spec+: { pmm+: { containerSecurityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } } } },
        },
        '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
        seLinuxOptions: {
          '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
          withLevel(level): { spec+: { pmm+: { containerSecurityContext+: { seLinuxOptions+: { level: level } } } } },
          '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
          withRole(role): { spec+: { pmm+: { containerSecurityContext+: { seLinuxOptions+: { role: role } } } } },
          '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { pmm+: { containerSecurityContext+: { seLinuxOptions+: { type: type } } } } },
          '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
          withUser(user): { spec+: { pmm+: { containerSecurityContext+: { seLinuxOptions+: { user: user } } } } },
        },
        '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
        seccompProfile: {
          '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
          withLocalhostProfile(localhostProfile): { spec+: { pmm+: { containerSecurityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } },
          '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { pmm+: { containerSecurityContext+: { seccompProfile+: { type: type } } } } },
        },
        '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
        windowsOptions: {
          '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
          withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { pmm+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } },
          '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
          withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { pmm+: { containerSecurityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } },
          '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
          withHostProcess(hostProcess): { spec+: { pmm+: { containerSecurityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } },
          '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
          withRunAsUserName(runAsUserName): { spec+: { pmm+: { containerSecurityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } },
        },
        '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
        withAllowPrivilegeEscalation(allowPrivilegeEscalation): { spec+: { pmm+: { containerSecurityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } } } },
        '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
        withPrivileged(privileged): { spec+: { pmm+: { containerSecurityContext+: { privileged: privileged } } } },
        '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
        withProcMount(procMount): { spec+: { pmm+: { containerSecurityContext+: { procMount: procMount } } } },
        '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
        withReadOnlyRootFilesystem(readOnlyRootFilesystem): { spec+: { pmm+: { containerSecurityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } } } },
        '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
        withRunAsGroup(runAsGroup): { spec+: { pmm+: { containerSecurityContext+: { runAsGroup: runAsGroup } } } },
        '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
        withRunAsNonRoot(runAsNonRoot): { spec+: { pmm+: { containerSecurityContext+: { runAsNonRoot: runAsNonRoot } } } },
        '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
        withRunAsUser(runAsUser): { spec+: { pmm+: { containerSecurityContext+: { runAsUser: runAsUser } } } },
      },
      '#resources':: d.obj(help='"Compute resources of a PMM container."'),
      resources: {
        '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
        claims: {
          '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
          withRequest(request): { request: request },
        },
        '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
        withClaims(claims): { spec+: { pmm+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
        withClaimsMixin(claims): { spec+: { pmm+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } },
        '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
        withLimits(limits): { spec+: { pmm+: { resources+: { limits: limits } } } },
        '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
        withLimitsMixin(limits): { spec+: { pmm+: { resources+: { limits+: limits } } } },
        '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
        withRequests(requests): { spec+: { pmm+: { resources+: { requests: requests } } } },
        '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
        withRequestsMixin(requests): { spec+: { pmm+: { resources+: { requests+: requests } } } },
      },
      '#withCustomClusterName':: d.fn(help='', args=[d.arg(name='customClusterName', type=d.T.string)]),
      withCustomClusterName(customClusterName): { spec+: { pmm+: { customClusterName: customClusterName } } },
      '#withEnabled':: d.fn(help='', args=[d.arg(name='enabled', type=d.T.boolean)]),
      withEnabled(enabled): { spec+: { pmm+: { enabled: enabled } } },
      '#withImage':: d.fn(help='', args=[d.arg(name='image', type=d.T.string)]),
      withImage(image): { spec+: { pmm+: { image: image } } },
      '#withImagePullPolicy':: d.fn(help='"ImagePullPolicy is used to determine when Kubernetes will attempt to\\npull (download) container images.\\nMore info: https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
      withImagePullPolicy(imagePullPolicy): { spec+: { pmm+: { imagePullPolicy: imagePullPolicy } } },
      '#withPostgresParams':: d.fn(help='', args=[d.arg(name='postgresParams', type=d.T.string)]),
      withPostgresParams(postgresParams): { spec+: { pmm+: { postgresParams: postgresParams } } },
      '#withQuerySource':: d.fn(help='', args=[d.arg(name='querySource', type=d.T.string)]),
      withQuerySource(querySource): { spec+: { pmm+: { querySource: querySource } } },
      '#withRuntimeClassName':: d.fn(help='', args=[d.arg(name='runtimeClassName', type=d.T.string)]),
      withRuntimeClassName(runtimeClassName): { spec+: { pmm+: { runtimeClassName: runtimeClassName } } },
      '#withSecret':: d.fn(help='', args=[d.arg(name='secret', type=d.T.string)]),
      withSecret(secret): { spec+: { pmm+: { secret: secret } } },
      '#withServerHost':: d.fn(help='', args=[d.arg(name='serverHost', type=d.T.string)]),
      withServerHost(serverHost): { spec+: { pmm+: { serverHost: serverHost } } },
    },
    '#proxy':: d.obj(help='"The specification of a proxy that connects to PostgreSQL."'),
    proxy: {
      '#pgBouncer':: d.obj(help='"Defines a PgBouncer proxy and connection pooler."'),
      pgBouncer: {
        '#affinity':: d.obj(help='"Scheduling constraints of a PgBouncer pod. Changing this value causes\\nPgBouncer to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node"'),
        affinity: {
          '#nodeAffinity':: d.obj(help='"Describes node affinity scheduling rules for the pod."'),
          nodeAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#preference':: d.obj(help='"A node selector term, associated with the corresponding weight."'),
              preference: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { preference+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { preference+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { preference+: { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { preference+: { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] } },
              },
              '#withWeight':: d.fn(help='"Weight associated with matching the corresponding nodeSelectorTerm, in the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to an update), the system\\nmay or may not try to eventually evict the pod from its node."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#nodeSelectorTerms':: d.obj(help='"Required. A list of node selector terms. The terms are ORed."'),
              nodeSelectorTerms: {
                '#matchExpressions':: d.obj(help="\"A list of node selector requirements by node's labels.\""),
                matchExpressions: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#matchFields':: d.obj(help="\"A list of node selector requirements by node's fields.\""),
                matchFields: {
                  '#withKey':: d.fn(help='"The label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"Represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists, DoesNotExist. Gt, and Lt.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"An array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. If the operator is Gt or Lt, the values\\narray must have a single element, which will be interpreted as an integer.\\nThis array is replaced during a strategic merge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help="\"A list of node selector requirements by node's labels.\"", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchExpressionsMixin':: d.fn(help="\"A list of node selector requirements by node's labels.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] },
                '#withMatchFields':: d.fn(help="\"A list of node selector requirements by node's fields.\"", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFields(matchFields): { matchFields: if std.isArray(v=matchFields) then matchFields else [matchFields] },
                '#withMatchFieldsMixin':: d.fn(help="\"A list of node selector requirements by node's fields.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchFields', type=d.T.array)]),
                withMatchFieldsMixin(matchFields): { matchFields+: if std.isArray(v=matchFields) then matchFields else [matchFields] },
              },
              '#withNodeSelectorTerms':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTerms(nodeSelectorTerms): { spec+: { proxy+: { pgBouncer+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
              '#withNodeSelectorTermsMixin':: d.fn(help='"Required. A list of node selector terms. The terms are ORed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='nodeSelectorTerms', type=d.T.array)]),
              withNodeSelectorTermsMixin(nodeSelectorTerms): { spec+: { proxy+: { pgBouncer+: { affinity+: { nodeAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: { nodeSelectorTerms+: if std.isArray(v=nodeSelectorTerms) then nodeSelectorTerms else [nodeSelectorTerms] } } } } } } },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node matches the corresponding matchExpressions; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { nodeAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAffinity':: d.obj(help='"Describes pod affinity scheduling rules (e.g. co-locate this pod in the same node, zone, etc. as some other pod(s))."'),
          podAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and adding\\n\\"weight\\" to the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
          '#podAntiAffinity':: d.obj(help='"Describes pod anti-affinity scheduling rules (e.g. avoid putting this pod in the same node, zone, etc. as some other pod(s))."'),
          podAntiAffinity: {
            '#preferredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."'),
            preferredDuringSchedulingIgnoredDuringExecution: {
              '#podAffinityTerm':: d.obj(help='"Required. A pod affinity term, associated with the corresponding weight."'),
              podAffinityTerm: {
                '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
                labelSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { labelSelector+: { matchLabels+: matchLabels } } },
                },
                '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
                namespaceSelector: {
                  '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                  matchExpressions: {
                    '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                    withKey(key): { key: key },
                    '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                    withOperator(operator): { operator: operator },
                    '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                    withValues(values): { values: if std.isArray(v=values) then values else [values] },
                    '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                    withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                  },
                  '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressions(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                  withMatchExpressionsMixin(matchExpressions): { podAffinityTerm+: { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                  '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabels(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels: matchLabels } } },
                  '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                  withMatchLabelsMixin(matchLabels): { podAffinityTerm+: { namespaceSelector+: { matchLabels+: matchLabels } } },
                },
                '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeys(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
                withMatchLabelKeysMixin(matchLabelKeys): { podAffinityTerm+: { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] } },
                '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeys(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
                withMismatchLabelKeysMixin(mismatchLabelKeys): { podAffinityTerm+: { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] } },
                '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespaces(namespaces): { podAffinityTerm+: { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
                withNamespacesMixin(namespaces): { podAffinityTerm+: { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] } },
                '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
                withTopologyKey(topologyKey): { podAffinityTerm+: { topologyKey: topologyKey } },
              },
              '#withWeight':: d.fn(help='"weight associated with matching the corresponding podAffinityTerm,\\nin the range 1-100."', args=[d.arg(name='weight', type=d.T.integer)]),
              withWeight(weight): { weight: weight },
            },
            '#requiredDuringSchedulingIgnoredDuringExecution':: d.obj(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."'),
            requiredDuringSchedulingIgnoredDuringExecution: {
              '#labelSelector':: d.obj(help="\"A label query over a set of resources, in this case pods.\\nIf it's null, this PodAffinityTerm matches with no Pods.\""),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
              },
              '#namespaceSelector':: d.obj(help="\"A label query over the set of namespaces that the term applies to.\\nThe term is applied to the union of the namespaces selected by this field\\nand the ones listed in the namespaces field.\\nnull selector and null or empty namespaces list means \\\"this pod's namespace\\\".\\nAn empty selector ({}) matches all namespaces.\""),
              namespaceSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { namespaceSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { namespaceSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { namespaceSelector+: { matchLabels: matchLabels } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { namespaceSelector+: { matchLabels+: matchLabels } },
              },
              '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key in (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both matchLabelKeys and labelSelector.\\nAlso, matchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
              withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
              '#withMismatchLabelKeys':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeys(mismatchLabelKeys): { mismatchLabelKeys: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withMismatchLabelKeysMixin':: d.fn(help="\"MismatchLabelKeys is a set of pod label keys to select which pods will\\nbe taken into consideration. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are merged with `labelSelector` as `key notin (value)`\\nto select the group of existing pods which pods will be taken into consideration\\nfor the incoming pod's pod (anti) affinity. Keys that don't exist in the incoming\\npod labels will be ignored. The default value is empty.\\nThe same key is forbidden to exist in both mismatchLabelKeys and labelSelector.\\nAlso, mismatchLabelKeys cannot be set when labelSelector isn't set.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='mismatchLabelKeys', type=d.T.array)]),
              withMismatchLabelKeysMixin(mismatchLabelKeys): { mismatchLabelKeys+: if std.isArray(v=mismatchLabelKeys) then mismatchLabelKeys else [mismatchLabelKeys] },
              '#withNamespaces':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespaces(namespaces): { namespaces: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withNamespacesMixin':: d.fn(help="\"namespaces specifies a static list of namespace names that the term applies to.\\nThe term is applied to the union of the namespaces listed in this field\\nand the ones selected by namespaceSelector.\\nnull or empty namespaces list and null namespaceSelector means \\\"this pod's namespace\\\".\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='namespaces', type=d.T.array)]),
              withNamespacesMixin(namespaces): { namespaces+: if std.isArray(v=namespaces) then namespaces else [namespaces] },
              '#withTopologyKey':: d.fn(help='"This pod should be co-located (affinity) or not co-located (anti-affinity) with the pods matching\\nthe labelSelector in the specified namespaces, where co-located is defined as running on a node\\nwhose value of the label with key topologyKey matches that of any node on which any of the\\nselected pods is running.\\nEmpty topologyKey is not allowed."', args=[d.arg(name='topologyKey', type=d.T.string)]),
              withTopologyKey(topologyKey): { topologyKey: topologyKey },
            },
            '#withPreferredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecution(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withPreferredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"The scheduler will prefer to schedule pods to nodes that satisfy\\nthe anti-affinity expressions specified by this field, but it may choose\\na node that violates one or more of the expressions. The node that is\\nmost preferred is the one with the greatest sum of weights, i.e.\\nfor each node that meets all of the scheduling requirements (resource\\nrequest, requiredDuringScheduling anti-affinity expressions, etc.),\\ncompute a sum by iterating through the elements of this field and subtracting\\n\\"weight\\" from the sum if the node has pods which matches the corresponding podAffinityTerm; the\\nnode(s) with the highest sum are the most preferred."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='preferredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withPreferredDuringSchedulingIgnoredDuringExecutionMixin(preferredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAntiAffinity+: { preferredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=preferredDuringSchedulingIgnoredDuringExecution) then preferredDuringSchedulingIgnoredDuringExecution else [preferredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecution':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecution(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
            '#withRequiredDuringSchedulingIgnoredDuringExecutionMixin':: d.fn(help='"If the anti-affinity requirements specified by this field are not met at\\nscheduling time, the pod will not be scheduled onto the node.\\nIf the anti-affinity requirements specified by this field cease to be met\\nat some point during pod execution (e.g. due to a pod label update), the\\nsystem may or may not try to eventually evict the pod from its node.\\nWhen there are multiple elements, the lists of nodes corresponding to each\\npodAffinityTerm are intersected, i.e. all terms must be satisfied."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requiredDuringSchedulingIgnoredDuringExecution', type=d.T.array)]),
            withRequiredDuringSchedulingIgnoredDuringExecutionMixin(requiredDuringSchedulingIgnoredDuringExecution): { spec+: { proxy+: { pgBouncer+: { affinity+: { podAntiAffinity+: { requiredDuringSchedulingIgnoredDuringExecution+: if std.isArray(v=requiredDuringSchedulingIgnoredDuringExecution) then requiredDuringSchedulingIgnoredDuringExecution else [requiredDuringSchedulingIgnoredDuringExecution] } } } } } },
          },
        },
        '#config':: d.obj(help='"Configuration settings for the PgBouncer process. Changes to any of these\\nvalues will be automatically reloaded without validation. Be careful, as\\nyou may put PgBouncer into an unusable state.\\nMore info: https://www.pgbouncer.org/usage.html#reload"'),
        config: {
          '#files':: d.obj(help='"Files to mount under \\"/etc/pgbouncer\\". When specified, settings in the\\n\\"pgbouncer.ini\\" file are loaded before all others. From there, other\\nfiles may be included by absolute path. Changing these references causes\\nPgBouncer to restart, but changes to the file contents are automatically\\nreloaded.\\nMore info: https://www.pgbouncer.org/config.html#include-directive"'),
          files: {
            '#clusterTrustBundle':: d.obj(help='"ClusterTrustBundle allows a pod to access the `.spec.trustBundle` field\\nof ClusterTrustBundle objects in an auto-updating file.\\n\\nAlpha, gated by the ClusterTrustBundleProjection feature gate.\\n\\nClusterTrustBundle objects can either be selected by name, or by the\\ncombination of signer name and a label selector.\\n\\nKubelet performs aggressive normalization of the PEM contents written\\ninto the pod filesystem.  Esoteric PEM features such as inter-block\\ncomments and block headers are stripped.  Certificates are deduplicated.\\nThe ordering of certificates within the file is arbitrary, and Kubelet\\nmay change the order over time."'),
            clusterTrustBundle: {
              '#labelSelector':: d.obj(help='"Select all ClusterTrustBundles that match this label selector.  Only has\\neffect if signerName is set.  Mutually-exclusive with name.  If unset,\\ninterpreted as \\"match nothing\\".  If set but empty, interpreted as \\"match\\neverything\\"."'),
              labelSelector: {
                '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
                matchExpressions: {
                  '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
                  withKey(key): { key: key },
                  '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
                  withOperator(operator): { operator: operator },
                  '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
                  withValues(values): { values: if std.isArray(v=values) then values else [values] },
                  '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
                  withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
                },
                '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressions(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
                withMatchExpressionsMixin(matchExpressions): { clusterTrustBundle+: { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } } },
                '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabels(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels: matchLabels } } },
                '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
                withMatchLabelsMixin(matchLabels): { clusterTrustBundle+: { labelSelector+: { matchLabels+: matchLabels } } },
              },
              '#withName':: d.fn(help='"Select a single ClusterTrustBundle by object name.  Mutually-exclusive\\nwith signerName and labelSelector."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { clusterTrustBundle+: { name: name } },
              '#withOptional':: d.fn(help="\"If true, don't block pod startup if the referenced ClusterTrustBundle(s)\\naren't available.  If using name, then the named ClusterTrustBundle is\\nallowed not to exist.  If using signerName, then the combination of\\nsignerName and labelSelector is allowed to match zero\\nClusterTrustBundles.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { clusterTrustBundle+: { optional: optional } },
              '#withPath':: d.fn(help='"Relative path from the volume root to write the bundle."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { clusterTrustBundle+: { path: path } },
              '#withSignerName':: d.fn(help='"Select all ClusterTrustBundles that match this signer name.\\nMutually-exclusive with name.  The contents of all selected\\nClusterTrustBundles will be unified and deduplicated."', args=[d.arg(name='signerName', type=d.T.string)]),
              withSignerName(signerName): { clusterTrustBundle+: { signerName: signerName } },
            },
            '#configMap':: d.obj(help='"configMap information about the configMap data to project"'),
            configMap: {
              '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
              items: {
                '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                withMode(mode): { mode: mode },
                '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { path: path },
              },
              '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
              withItems(items): { configMap+: { items: if std.isArray(v=items) then items else [items] } },
              '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nConfigMap will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the ConfigMap,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
              withItemsMixin(items): { configMap+: { items+: if std.isArray(v=items) then items else [items] } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { configMap+: { name: name } },
              '#withOptional':: d.fn(help='"optional specify whether the ConfigMap or its keys must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { configMap+: { optional: optional } },
            },
            '#downwardAPI':: d.obj(help='"downwardAPI information about the downwardAPI data to project"'),
            downwardAPI: {
              '#items':: d.obj(help='"Items is a list of DownwardAPIVolume file"'),
              items: {
                '#fieldRef':: d.obj(help='"Required: Selects a field of the pod: only annotations, labels, name, namespace and uid are supported."'),
                fieldRef: {
                  '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                  withApiVersion(apiVersion): { fieldRef+: { apiVersion: apiVersion } },
                  '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                  withFieldPath(fieldPath): { fieldRef+: { fieldPath: fieldPath } },
                },
                '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, requests.cpu and requests.memory) are currently supported."'),
                resourceFieldRef: {
                  '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                  withContainerName(containerName): { resourceFieldRef+: { containerName: containerName } },
                  '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                  withDivisor(divisor): { resourceFieldRef+: { divisor: divisor } },
                  '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                  withResource(resource): { resourceFieldRef+: { resource: resource } },
                },
                '#withMode':: d.fn(help='"Optional: mode bits used to set permissions on this file, must be an octal value\\nbetween 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                withMode(mode): { mode: mode },
                '#withPath':: d.fn(help="\"Required: Path is  the relative path name of the file to be created. Must not be absolute or contain the '..' path. Must be utf-8 encoded. The first item of the relative path must not start with '..'\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { path: path },
              },
              '#withItems':: d.fn(help='"Items is a list of DownwardAPIVolume file"', args=[d.arg(name='items', type=d.T.array)]),
              withItems(items): { downwardAPI+: { items: if std.isArray(v=items) then items else [items] } },
              '#withItemsMixin':: d.fn(help='"Items is a list of DownwardAPIVolume file"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='items', type=d.T.array)]),
              withItemsMixin(items): { downwardAPI+: { items+: if std.isArray(v=items) then items else [items] } },
            },
            '#podCertificate':: d.obj(help="\"Projects an auto-rotating credential bundle (private key and certificate\\nchain) that the pod can use either as a TLS client or server.\\n\\nKubelet generates a private key and uses it to send a\\nPodCertificateRequest to the named signer.  Once the signer approves the\\nrequest and issues a certificate chain, Kubelet writes the key and\\ncertificate chain to the pod filesystem.  The pod does not start until\\ncertificates have been issued for each podCertificate projected volume\\nsource in its spec.\\n\\nKubelet will begin trying to rotate the certificate at the time indicated\\nby the signer using the PodCertificateRequest.Status.BeginRefreshAt\\ntimestamp.\\n\\nKubelet can write a single file, indicated by the credentialBundlePath\\nfield, or separate files, indicated by the keyPath and\\ncertificateChainPath fields.\\n\\nThe credential bundle is a single file in PEM format.  The first PEM\\nentry is the private key (in PKCS#8 format), and the remaining PEM\\nentries are the certificate chain issued by the signer (typically,\\nsigners will return their certificate chain in leaf-to-root order).\\n\\nPrefer using the credential bundle format, since your application code\\ncan read it atomically.  If you use keyPath and certificateChainPath,\\nyour application must make two separate file reads. If these coincide\\nwith a certificate rotation, it is possible that the private key and leaf\\ncertificate you read may not correspond to each other.  Your application\\nwill need to check for this condition, and re-read until they are\\nconsistent.\\n\\nThe named signer controls chooses the format of the certificate it\\nissues; consult the signer implementation's documentation to learn how to\\nuse the certificates it issues.\""),
            podCertificate: {
              '#withCertificateChainPath':: d.fn(help='"Write the certificate chain at this path in the projected volume.\\n\\nMost applications should use credentialBundlePath.  When using keyPath\\nand certificateChainPath, your application needs to check that the key\\nand leaf certificate are consistent, because it is possible to read the\\nfiles mid-rotation."', args=[d.arg(name='certificateChainPath', type=d.T.string)]),
              withCertificateChainPath(certificateChainPath): { podCertificate+: { certificateChainPath: certificateChainPath } },
              '#withCredentialBundlePath':: d.fn(help="\"Write the credential bundle at this path in the projected volume.\\n\\nThe credential bundle is a single file that contains multiple PEM blocks.\\nThe first PEM block is a PRIVATE KEY block, containing a PKCS#8 private\\nkey.\\n\\nThe remaining blocks are CERTIFICATE blocks, containing the issued\\ncertificate chain from the signer (leaf and any intermediates).\\n\\nUsing credentialBundlePath lets your Pod's application code make a single\\natomic read that retrieves a consistent key and certificate chain.  If you\\nproject them to separate files, your application code will need to\\nadditionally check that the leaf certificate was issued to the key.\"", args=[d.arg(name='credentialBundlePath', type=d.T.string)]),
              withCredentialBundlePath(credentialBundlePath): { podCertificate+: { credentialBundlePath: credentialBundlePath } },
              '#withKeyPath':: d.fn(help='"Write the key at this path in the projected volume.\\n\\nMost applications should use credentialBundlePath.  When using keyPath\\nand certificateChainPath, your application needs to check that the key\\nand leaf certificate are consistent, because it is possible to read the\\nfiles mid-rotation."', args=[d.arg(name='keyPath', type=d.T.string)]),
              withKeyPath(keyPath): { podCertificate+: { keyPath: keyPath } },
              '#withKeyType':: d.fn(help='"The type of keypair Kubelet will generate for the pod.\\n\\nValid values are \\"RSA3072\\", \\"RSA4096\\", \\"ECDSAP256\\", \\"ECDSAP384\\",\\n\\"ECDSAP521\\", and \\"ED25519\\"."', args=[d.arg(name='keyType', type=d.T.string)]),
              withKeyType(keyType): { podCertificate+: { keyType: keyType } },
              '#withMaxExpirationSeconds':: d.fn(help='"maxExpirationSeconds is the maximum lifetime permitted for the\\ncertificate.\\n\\nKubelet copies this value verbatim into the PodCertificateRequests it\\ngenerates for this projection.\\n\\nIf omitted, kube-apiserver will set it to 86400(24 hours). kube-apiserver\\nwill reject values shorter than 3600 (1 hour).  The maximum allowable\\nvalue is 7862400 (91 days).\\n\\nThe signer implementation is then free to issue a certificate with any\\nlifetime *shorter* than MaxExpirationSeconds, but no shorter than 3600\\nseconds (1 hour).  This constraint is enforced by kube-apiserver.\\n`kubernetes.io` signers will never issue certificates with a lifetime\\nlonger than 24 hours."', args=[d.arg(name='maxExpirationSeconds', type=d.T.integer)]),
              withMaxExpirationSeconds(maxExpirationSeconds): { podCertificate+: { maxExpirationSeconds: maxExpirationSeconds } },
              '#withSignerName':: d.fn(help="\"Kubelet's generated CSRs will be addressed to this signer.\"", args=[d.arg(name='signerName', type=d.T.string)]),
              withSignerName(signerName): { podCertificate+: { signerName: signerName } },
            },
            '#secret':: d.obj(help='"secret information about the secret data to project"'),
            secret: {
              '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
              items: {
                '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { key: key },
                '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
                withMode(mode): { mode: mode },
                '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { path: path },
              },
              '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
              withItems(items): { secret+: { items: if std.isArray(v=items) then items else [items] } },
              '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
              withItemsMixin(items): { secret+: { items+: if std.isArray(v=items) then items else [items] } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { secret+: { name: name } },
              '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { secret+: { optional: optional } },
            },
            '#serviceAccountToken':: d.obj(help='"serviceAccountToken is information about the serviceAccountToken data to project"'),
            serviceAccountToken: {
              '#withAudience':: d.fn(help='"audience is the intended audience of the token. A recipient of a token\\nmust identify itself with an identifier specified in the audience of the\\ntoken, and otherwise should reject the token. The audience defaults to the\\nidentifier of the apiserver."', args=[d.arg(name='audience', type=d.T.string)]),
              withAudience(audience): { serviceAccountToken+: { audience: audience } },
              '#withExpirationSeconds':: d.fn(help='"expirationSeconds is the requested duration of validity of the service\\naccount token. As the token approaches expiration, the kubelet volume\\nplugin will proactively rotate the service account token. The kubelet will\\nstart trying to rotate the token if the token is older than 80 percent of\\nits time to live or if the token is older than 24 hours.Defaults to 1 hour\\nand must be at least 10 minutes."', args=[d.arg(name='expirationSeconds', type=d.T.integer)]),
              withExpirationSeconds(expirationSeconds): { serviceAccountToken+: { expirationSeconds: expirationSeconds } },
              '#withPath':: d.fn(help='"path is the path relative to the mount point of the file to project the\\ntoken into."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { serviceAccountToken+: { path: path } },
            },
          },
          '#withDatabases':: d.fn(help='"PgBouncer database definitions. The key is the database requested by a\\nclient while the value is a libpq-styled connection string. The special\\nkey \\"*\\" acts as a fallback. When this field is empty, PgBouncer is\\nconfigured with a single \\"*\\" entry that connects to the primary\\nPostgreSQL instance.\\nMore info: https://www.pgbouncer.org/config.html#section-databases"', args=[d.arg(name='databases', type=d.T.object)]),
          withDatabases(databases): { spec+: { proxy+: { pgBouncer+: { config+: { databases: databases } } } } },
          '#withDatabasesMixin':: d.fn(help='"PgBouncer database definitions. The key is the database requested by a\\nclient while the value is a libpq-styled connection string. The special\\nkey \\"*\\" acts as a fallback. When this field is empty, PgBouncer is\\nconfigured with a single \\"*\\" entry that connects to the primary\\nPostgreSQL instance.\\nMore info: https://www.pgbouncer.org/config.html#section-databases"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='databases', type=d.T.object)]),
          withDatabasesMixin(databases): { spec+: { proxy+: { pgBouncer+: { config+: { databases+: databases } } } } },
          '#withFiles':: d.fn(help='"Files to mount under \\"/etc/pgbouncer\\". When specified, settings in the\\n\\"pgbouncer.ini\\" file are loaded before all others. From there, other\\nfiles may be included by absolute path. Changing these references causes\\nPgBouncer to restart, but changes to the file contents are automatically\\nreloaded.\\nMore info: https://www.pgbouncer.org/config.html#include-directive"', args=[d.arg(name='files', type=d.T.array)]),
          withFiles(files): { spec+: { proxy+: { pgBouncer+: { config+: { files: if std.isArray(v=files) then files else [files] } } } } },
          '#withFilesMixin':: d.fn(help='"Files to mount under \\"/etc/pgbouncer\\". When specified, settings in the\\n\\"pgbouncer.ini\\" file are loaded before all others. From there, other\\nfiles may be included by absolute path. Changing these references causes\\nPgBouncer to restart, but changes to the file contents are automatically\\nreloaded.\\nMore info: https://www.pgbouncer.org/config.html#include-directive"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='files', type=d.T.array)]),
          withFilesMixin(files): { spec+: { proxy+: { pgBouncer+: { config+: { files+: if std.isArray(v=files) then files else [files] } } } } },
          '#withGlobal':: d.fn(help='"Settings that apply to the entire PgBouncer process.\\nMore info: https://www.pgbouncer.org/config.html"', args=[d.arg(name='global', type=d.T.object)]),
          withGlobal(global): { spec+: { proxy+: { pgBouncer+: { config+: { global: global } } } } },
          '#withGlobalMixin':: d.fn(help='"Settings that apply to the entire PgBouncer process.\\nMore info: https://www.pgbouncer.org/config.html"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='global', type=d.T.object)]),
          withGlobalMixin(global): { spec+: { proxy+: { pgBouncer+: { config+: { global+: global } } } } },
          '#withUsers':: d.fn(help='"Connection settings specific to particular users.\\nMore info: https://www.pgbouncer.org/config.html#section-users"', args=[d.arg(name='users', type=d.T.object)]),
          withUsers(users): { spec+: { proxy+: { pgBouncer+: { config+: { users: users } } } } },
          '#withUsersMixin':: d.fn(help='"Connection settings specific to particular users.\\nMore info: https://www.pgbouncer.org/config.html#section-users"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='users', type=d.T.object)]),
          withUsersMixin(users): { spec+: { proxy+: { pgBouncer+: { config+: { users+: users } } } } },
        },
        '#containers':: d.obj(help='"Configuration for pgBouncer default sidecar containers."'),
        containers: {
          '#pgbouncerConfig':: d.obj(help='"Defines the configuration for the pgBouncer config sidecar container"'),
          pgbouncerConfig: {
            '#resources':: d.obj(help='"Resource requirements for a sidecar container"'),
            resources: {
              '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
              claims: {
                '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
                withRequest(request): { request: request },
              },
              '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
              withClaims(claims): { spec+: { proxy+: { pgBouncer+: { containers+: { pgbouncerConfig+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
              withClaimsMixin(claims): { spec+: { proxy+: { pgBouncer+: { containers+: { pgbouncerConfig+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } } } },
              '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
              withLimits(limits): { spec+: { proxy+: { pgBouncer+: { containers+: { pgbouncerConfig+: { resources+: { limits: limits } } } } } } },
              '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
              withLimitsMixin(limits): { spec+: { proxy+: { pgBouncer+: { containers+: { pgbouncerConfig+: { resources+: { limits+: limits } } } } } } },
              '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
              withRequests(requests): { spec+: { proxy+: { pgBouncer+: { containers+: { pgbouncerConfig+: { resources+: { requests: requests } } } } } } },
              '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
              withRequestsMixin(requests): { spec+: { proxy+: { pgBouncer+: { containers+: { pgbouncerConfig+: { resources+: { requests+: requests } } } } } } },
            },
          },
        },
        '#customTLSSecret':: d.obj(help='"A secret projection containing a certificate and key with which to encrypt\\nconnections to PgBouncer. The \\"tls.crt\\", \\"tls.key\\", and \\"ca.crt\\" paths must\\nbe PEM-encoded certificates and keys. Changing this value causes PgBouncer\\nto restart.\\nMore info: https://kubernetes.io/docs/concepts/configuration/secret/#projection-of-secret-keys-to-specific-paths"'),
        customTLSSecret: {
          '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
          items: {
            '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
            withKey(key): { key: key },
            '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
            withMode(mode): { mode: mode },
            '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
            withPath(path): { path: path },
          },
          '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
          withItems(items): { spec+: { proxy+: { pgBouncer+: { customTLSSecret+: { items: if std.isArray(v=items) then items else [items] } } } } },
          '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
          withItemsMixin(items): { spec+: { proxy+: { pgBouncer+: { customTLSSecret+: { items+: if std.isArray(v=items) then items else [items] } } } } },
          '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { spec+: { proxy+: { pgBouncer+: { customTLSSecret+: { name: name } } } } },
          '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
          withOptional(optional): { spec+: { proxy+: { pgBouncer+: { customTLSSecret+: { optional: optional } } } } },
        },
        '#env':: d.obj(help=''),
        env: {
          '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
          valueFrom: {
            '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
            configMapKeyRef: {
              '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
            },
            '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
            fieldRef: {
              '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
              withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
              '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
              withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
            },
            '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
            fileKeyRef: {
              '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
              '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
              '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
              '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
              withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
            },
            '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
            resourceFieldRef: {
              '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
              withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
              '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
              withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
              '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
              withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
            },
            '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
            secretKeyRef: {
              '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
              '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
            },
          },
          '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#envFrom':: d.obj(help=''),
        envFrom: {
          '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
          configMapRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { configMapRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { configMapRef+: { optional: optional } },
          },
          '#secretRef':: d.obj(help='"The Secret to select from"'),
          secretRef: {
            '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { secretRef+: { name: name } },
            '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
            withOptional(optional): { secretRef+: { optional: optional } },
          },
          '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
          withPrefix(prefix): { prefix: prefix },
        },
        '#expose':: d.obj(help='"Specification of the service that exposes PgBouncer."'),
        expose: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { proxy+: { pgBouncer+: { expose+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { proxy+: { pgBouncer+: { expose+: { annotations+: annotations } } } } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { proxy+: { pgBouncer+: { expose+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { proxy+: { pgBouncer+: { expose+: { labels+: labels } } } } },
          '#withLoadBalancerClass':: d.fn(help='"LoadBalancerClass specifies the class of the load balancer implementation\\nto be used. This field is supported for Service Type LoadBalancer only.\\n\\nMore info:\\nhttps://kubernetes.io/docs/concepts/services-networking/service/#load-balancer-class"', args=[d.arg(name='loadBalancerClass', type=d.T.string)]),
          withLoadBalancerClass(loadBalancerClass): { spec+: { proxy+: { pgBouncer+: { expose+: { loadBalancerClass: loadBalancerClass } } } } },
          '#withLoadBalancerSourceRanges':: d.fn(help='"LoadBalancerSourceRanges is a list of IP CIDRs allowed access to load.\\nThis field will be ignored if the cloud-provider does not support the feature."', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRanges(loadBalancerSourceRanges): { spec+: { proxy+: { pgBouncer+: { expose+: { loadBalancerSourceRanges: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withLoadBalancerSourceRangesMixin':: d.fn(help='"LoadBalancerSourceRanges is a list of IP CIDRs allowed access to load.\\nThis field will be ignored if the cloud-provider does not support the feature."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='loadBalancerSourceRanges', type=d.T.array)]),
          withLoadBalancerSourceRangesMixin(loadBalancerSourceRanges): { spec+: { proxy+: { pgBouncer+: { expose+: { loadBalancerSourceRanges+: if std.isArray(v=loadBalancerSourceRanges) then loadBalancerSourceRanges else [loadBalancerSourceRanges] } } } } },
          '#withNodePort':: d.fn(help='"The port on which this service is exposed when type is NodePort or\\nLoadBalancer. Value must be in-range and not in use or the operation will\\nfail. If unspecified, a port will be allocated if this Service requires one.\\n- https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport"', args=[d.arg(name='nodePort', type=d.T.integer)]),
          withNodePort(nodePort): { spec+: { proxy+: { pgBouncer+: { expose+: { nodePort: nodePort } } } } },
          '#withType':: d.fn(help='"More info: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types"', args=[d.arg(name='type', type=d.T.string)]),
          withType(type): { spec+: { proxy+: { pgBouncer+: { expose+: { type: type } } } } },
        },
        '#metadata':: d.obj(help='"Metadata contains metadata for custom resources"'),
        metadata: {
          '#withAnnotations':: d.fn(help='', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotations(annotations): { spec+: { proxy+: { pgBouncer+: { metadata+: { annotations: annotations } } } } },
          '#withAnnotationsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='annotations', type=d.T.object)]),
          withAnnotationsMixin(annotations): { spec+: { proxy+: { pgBouncer+: { metadata+: { annotations+: annotations } } } } },
          '#withLabels':: d.fn(help='', args=[d.arg(name='labels', type=d.T.object)]),
          withLabels(labels): { spec+: { proxy+: { pgBouncer+: { metadata+: { labels: labels } } } } },
          '#withLabelsMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='labels', type=d.T.object)]),
          withLabelsMixin(labels): { spec+: { proxy+: { pgBouncer+: { metadata+: { labels+: labels } } } } },
        },
        '#resources':: d.obj(help='"Compute resources of a PgBouncer container. Changing this value causes\\nPgBouncer to restart.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers"'),
        resources: {
          '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
          claims: {
            '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
            withRequest(request): { request: request },
          },
          '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
          withClaims(claims): { spec+: { proxy+: { pgBouncer+: { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
          withClaimsMixin(claims): { spec+: { proxy+: { pgBouncer+: { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } } } } },
          '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
          withLimits(limits): { spec+: { proxy+: { pgBouncer+: { resources+: { limits: limits } } } } },
          '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
          withLimitsMixin(limits): { spec+: { proxy+: { pgBouncer+: { resources+: { limits+: limits } } } } },
          '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
          withRequests(requests): { spec+: { proxy+: { pgBouncer+: { resources+: { requests: requests } } } } },
          '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
          withRequestsMixin(requests): { spec+: { proxy+: { pgBouncer+: { resources+: { requests+: requests } } } } },
        },
        '#securityContext':: d.obj(help='"SecurityContext defines the security settings for PGBouncer pods."'),
        securityContext: {
          '#appArmorProfile':: d.obj(help='"appArmorProfile is the AppArmor options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
          appArmorProfile: {
            '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { spec+: { proxy+: { pgBouncer+: { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } } } } },
            '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { proxy+: { pgBouncer+: { securityContext+: { appArmorProfile+: { type: type } } } } } },
          },
          '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to all containers.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in SecurityContext.  If set in\\nboth SecurityContext and PodSecurityContext, the value specified in SecurityContext\\ntakes precedence for that container.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seLinuxOptions: {
            '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
            withLevel(level): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seLinuxOptions+: { level: level } } } } } },
            '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
            withRole(role): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seLinuxOptions+: { role: role } } } } } },
            '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seLinuxOptions+: { type: type } } } } } },
            '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
            withUser(user): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seLinuxOptions+: { user: user } } } } } },
          },
          '#seccompProfile':: d.obj(help='"The seccomp options to use by the containers in this pod.\\nNote that this field cannot be set when spec.os.name is windows."'),
          seccompProfile: {
            '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
            withLocalhostProfile(localhostProfile): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } } } } },
            '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
            withType(type): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seccompProfile+: { type: type } } } } } },
          },
          '#sysctls':: d.obj(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."'),
          sysctls: {
            '#withName':: d.fn(help='"Name of a property to set"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValue':: d.fn(help='"Value of a property to set"', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#windowsOptions':: d.obj(help="\"The Windows specific settings applied to all containers.\\nIf unspecified, the options within a container's SecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux.\""),
          windowsOptions: {
            '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
            withGmsaCredentialSpec(gmsaCredentialSpec): { spec+: { proxy+: { pgBouncer+: { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } } } } },
            '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
            withGmsaCredentialSpecName(gmsaCredentialSpecName): { spec+: { proxy+: { pgBouncer+: { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } } } } },
            '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
            withHostProcess(hostProcess): { spec+: { proxy+: { pgBouncer+: { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } } } } },
            '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
            withRunAsUserName(runAsUserName): { spec+: { proxy+: { pgBouncer+: { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } } } } },
          },
          '#withFsGroup':: d.fn(help="\"A special supplemental group that applies to all containers in a pod.\\nSome volume types allow the Kubelet to change the ownership of that volume\\nto be owned by the pod:\\n\\n1. The owning GID will be the FSGroup\\n2. The setgid bit is set (new files created in the volume will be owned by FSGroup)\\n3. The permission bits are OR'd with rw-rw----\\n\\nIf unset, the Kubelet will not modify the ownership and permissions of any volume.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='fsGroup', type=d.T.integer)]),
          withFsGroup(fsGroup): { spec+: { proxy+: { pgBouncer+: { securityContext+: { fsGroup: fsGroup } } } } },
          '#withFsGroupChangePolicy':: d.fn(help='"fsGroupChangePolicy defines behavior of changing ownership and permission of the volume\\nbefore being exposed inside Pod. This field will only apply to\\nvolume types which support fsGroup based ownership(and permissions).\\nIt will have no effect on ephemeral volume types such as: secret, configmaps\\nand emptydir.\\nValid values are \\"OnRootMismatch\\" and \\"Always\\". If not specified, \\"Always\\" is used.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='fsGroupChangePolicy', type=d.T.string)]),
          withFsGroupChangePolicy(fsGroupChangePolicy): { spec+: { proxy+: { pgBouncer+: { securityContext+: { fsGroupChangePolicy: fsGroupChangePolicy } } } } },
          '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
          withRunAsGroup(runAsGroup): { spec+: { proxy+: { pgBouncer+: { securityContext+: { runAsGroup: runAsGroup } } } } },
          '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
          withRunAsNonRoot(runAsNonRoot): { spec+: { proxy+: { pgBouncer+: { securityContext+: { runAsNonRoot: runAsNonRoot } } } } },
          '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in SecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence\\nfor that container.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
          withRunAsUser(runAsUser): { spec+: { proxy+: { pgBouncer+: { securityContext+: { runAsUser: runAsUser } } } } },
          '#withSeLinuxChangePolicy':: d.fn(help="\"seLinuxChangePolicy defines how the container's SELinux label is applied to all volumes used by the Pod.\\nIt has no effect on nodes that do not support SELinux or to volumes does not support SELinux.\\nValid values are \\\"MountOption\\\" and \\\"Recursive\\\".\\n\\n\\\"Recursive\\\" means relabeling of all files on all Pod volumes by the container runtime.\\nThis may be slow for large volumes, but allows mixing privileged and unprivileged Pods sharing the same volume on the same node.\\n\\n\\\"MountOption\\\" mounts all eligible Pod volumes with `-o context` mount option.\\nThis requires all Pods that share the same volume to use the same SELinux label.\\nIt is not possible to share the same volume among privileged and unprivileged Pods.\\nEligible volumes are in-tree FibreChannel and iSCSI volumes, and all CSI volumes\\nwhose CSI driver announces SELinux support by setting spec.seLinuxMount: true in their\\nCSIDriver instance. Other volumes are always re-labelled recursively.\\n\\\"MountOption\\\" value is allowed only when SELinuxMount feature gate is enabled.\\n\\nIf not specified and SELinuxMount feature gate is enabled, \\\"MountOption\\\" is used.\\nIf not specified and SELinuxMount feature gate is disabled, \\\"MountOption\\\" is used for ReadWriteOncePod volumes\\nand \\\"Recursive\\\" for all other volumes.\\n\\nThis field affects only Pods that have SELinux label set, either in PodSecurityContext or in SecurityContext of all containers.\\n\\nAll Pods that use the same volume should use the same seLinuxChangePolicy, otherwise some pods can get stuck in ContainerCreating state.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='seLinuxChangePolicy', type=d.T.string)]),
          withSeLinuxChangePolicy(seLinuxChangePolicy): { spec+: { proxy+: { pgBouncer+: { securityContext+: { seLinuxChangePolicy: seLinuxChangePolicy } } } } },
          '#withSupplementalGroups':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
          withSupplementalGroups(supplementalGroups): { spec+: { proxy+: { pgBouncer+: { securityContext+: { supplementalGroups: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } },
          '#withSupplementalGroupsMixin':: d.fn(help="\"A list of groups applied to the first process run in each container, in\\naddition to the container's primary GID and fsGroup (if specified).  If\\nthe SupplementalGroupsPolicy feature is enabled, the\\nsupplementalGroupsPolicy field determines whether these are in addition\\nto or instead of any group memberships defined in the container image.\\nIf unspecified, no additional groups are added, though group memberships\\ndefined in the container image may still be used, depending on the\\nsupplementalGroupsPolicy field.\\nNote that this field cannot be set when spec.os.name is windows.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='supplementalGroups', type=d.T.array)]),
          withSupplementalGroupsMixin(supplementalGroups): { spec+: { proxy+: { pgBouncer+: { securityContext+: { supplementalGroups+: if std.isArray(v=supplementalGroups) then supplementalGroups else [supplementalGroups] } } } } },
          '#withSupplementalGroupsPolicy':: d.fn(help='"Defines how supplemental groups of the first container processes are calculated.\\nValid values are \\"Merge\\" and \\"Strict\\". If not specified, \\"Merge\\" is used.\\n(Alpha) Using the field requires the SupplementalGroupsPolicy feature gate to be enabled\\nand the container runtime must implement support for this feature.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='supplementalGroupsPolicy', type=d.T.string)]),
          withSupplementalGroupsPolicy(supplementalGroupsPolicy): { spec+: { proxy+: { pgBouncer+: { securityContext+: { supplementalGroupsPolicy: supplementalGroupsPolicy } } } } },
          '#withSysctls':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='sysctls', type=d.T.array)]),
          withSysctls(sysctls): { spec+: { proxy+: { pgBouncer+: { securityContext+: { sysctls: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } },
          '#withSysctlsMixin':: d.fn(help='"Sysctls hold a list of namespaced sysctls used for the pod. Pods with unsupported\\nsysctls (by the container runtime) might fail to launch.\\nNote that this field cannot be set when spec.os.name is windows."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sysctls', type=d.T.array)]),
          withSysctlsMixin(sysctls): { spec+: { proxy+: { pgBouncer+: { securityContext+: { sysctls+: if std.isArray(v=sysctls) then sysctls else [sysctls] } } } } },
        },
        '#sidecars':: d.obj(help='"Custom sidecars for a PgBouncer pod. Changing this value causes\\nPgBouncer to restart."'),
        sidecars: {
          '#env':: d.obj(help='"List of environment variables to set in the container.\\nCannot be updated."'),
          env: {
            '#valueFrom':: d.obj(help="\"Source for the environment variable's value. Cannot be used if value is not empty.\""),
            valueFrom: {
              '#configMapKeyRef':: d.obj(help='"Selects a key of a ConfigMap."'),
              configMapKeyRef: {
                '#withKey':: d.fn(help='"The key to select."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { valueFrom+: { configMapKeyRef+: { key: key } } },
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { valueFrom+: { configMapKeyRef+: { name: name } } },
                '#withOptional':: d.fn(help='"Specify whether the ConfigMap or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { valueFrom+: { configMapKeyRef+: { optional: optional } } },
              },
              '#fieldRef':: d.obj(help="\"Selects a field of the pod: supports metadata.name, metadata.namespace, `metadata.labels['\u003cKEY\u003e']`, `metadata.annotations['\u003cKEY\u003e']`,\\nspec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.\""),
              fieldRef: {
                '#withApiVersion':: d.fn(help='"Version of the schema the FieldPath is written in terms of, defaults to \\"v1\\"."', args=[d.arg(name='apiVersion', type=d.T.string)]),
                withApiVersion(apiVersion): { valueFrom+: { fieldRef+: { apiVersion: apiVersion } } },
                '#withFieldPath':: d.fn(help='"Path of the field to select in the specified API version."', args=[d.arg(name='fieldPath', type=d.T.string)]),
                withFieldPath(fieldPath): { valueFrom+: { fieldRef+: { fieldPath: fieldPath } } },
              },
              '#fileKeyRef':: d.obj(help='"FileKeyRef selects a key of the env file.\\nRequires the EnvFiles feature gate to be enabled."'),
              fileKeyRef: {
                '#withKey':: d.fn(help="\"The key within the env file. An invalid key will prevent the pod from starting.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nDuring Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters.\"", args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { valueFrom+: { fileKeyRef+: { key: key } } },
                '#withOptional':: d.fn(help="\"Specify whether the file or its key must be defined. If the file or key\\ndoes not exist, then the env var is not published.\\nIf optional is set to true and the specified key does not exist,\\nthe environment variable will not be set in the Pod's containers.\\n\\nIf optional is set to false and the specified key does not exist,\\nan error will be returned during Pod creation.\"", args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { valueFrom+: { fileKeyRef+: { optional: optional } } },
                '#withPath':: d.fn(help="\"The path within the volume from which to select the file.\\nMust be relative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { valueFrom+: { fileKeyRef+: { path: path } } },
                '#withVolumeName':: d.fn(help='"The name of the volume mount containing the env file."', args=[d.arg(name='volumeName', type=d.T.string)]),
                withVolumeName(volumeName): { valueFrom+: { fileKeyRef+: { volumeName: volumeName } } },
              },
              '#resourceFieldRef':: d.obj(help='"Selects a resource of the container: only resources limits and requests\\n(limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported."'),
              resourceFieldRef: {
                '#withContainerName':: d.fn(help='"Container name: required for volumes, optional for env vars"', args=[d.arg(name='containerName', type=d.T.string)]),
                withContainerName(containerName): { valueFrom+: { resourceFieldRef+: { containerName: containerName } } },
                '#withDivisor':: d.fn(help='"Specifies the output format of the exposed resources, defaults to \\"1\\', args=[d.arg(name='divisor', type=d.T.any)]),
                withDivisor(divisor): { valueFrom+: { resourceFieldRef+: { divisor: divisor } } },
                '#withResource':: d.fn(help='"Required: resource to select"', args=[d.arg(name='resource', type=d.T.string)]),
                withResource(resource): { valueFrom+: { resourceFieldRef+: { resource: resource } } },
              },
              '#secretKeyRef':: d.obj(help="\"Selects a key of a secret in the pod's namespace\""),
              secretKeyRef: {
                '#withKey':: d.fn(help='"The key of the secret to select from.  Must be a valid secret key."', args=[d.arg(name='key', type=d.T.string)]),
                withKey(key): { valueFrom+: { secretKeyRef+: { key: key } } },
                '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { valueFrom+: { secretKeyRef+: { name: name } } },
                '#withOptional':: d.fn(help='"Specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
                withOptional(optional): { valueFrom+: { secretKeyRef+: { optional: optional } } },
              },
            },
            '#withName':: d.fn(help="\"Name of the environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withValue':: d.fn(help='"Variable references $(VAR_NAME) are expanded\\nusing the previously defined environment variables in the container and\\nany service environment variables. If a variable cannot be resolved,\\nthe reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e.\\n\\"$$(VAR_NAME)\\" will produce the string literal \\"$(VAR_NAME)\\".\\nEscaped references will never be expanded, regardless of whether the variable\\nexists or not.\\nDefaults to \\"\\"."', args=[d.arg(name='value', type=d.T.string)]),
            withValue(value): { value: value },
          },
          '#envFrom':: d.obj(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\""),
          envFrom: {
            '#configMapRef':: d.obj(help='"The ConfigMap to select from"'),
            configMapRef: {
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { configMapRef+: { name: name } },
              '#withOptional':: d.fn(help='"Specify whether the ConfigMap must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { configMapRef+: { optional: optional } },
            },
            '#secretRef':: d.obj(help='"The Secret to select from"'),
            secretRef: {
              '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { secretRef+: { name: name } },
              '#withOptional':: d.fn(help='"Specify whether the Secret must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
              withOptional(optional): { secretRef+: { optional: optional } },
            },
            '#withPrefix':: d.fn(help="\"Optional text to prepend to the name of each environment variable.\\nMay consist of any printable ASCII characters except '='.\"", args=[d.arg(name='prefix', type=d.T.string)]),
            withPrefix(prefix): { prefix: prefix },
          },
          '#lifecycle':: d.obj(help='"Actions that the management system should take in response to container lifecycle events.\\nCannot be updated."'),
          lifecycle: {
            '#postStart':: d.obj(help='"PostStart is called immediately after a container is created. If the handler fails,\\nthe container is terminated and restarted according to its restart policy.\\nOther management of the container blocks until the hook completes.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks"'),
            postStart: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { lifecycle+: { postStart+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { lifecycle+: { postStart+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { lifecycle+: { postStart+: { httpGet+: { host: host } } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { lifecycle+: { postStart+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { lifecycle+: { postStart+: { httpGet+: { path: path } } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { lifecycle+: { postStart+: { httpGet+: { port: port } } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { lifecycle+: { postStart+: { httpGet+: { scheme: scheme } } } },
              },
              '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
              sleep: {
                '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
                withSeconds(seconds): { lifecycle+: { postStart+: { sleep+: { seconds: seconds } } } },
              },
              '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { lifecycle+: { postStart+: { tcpSocket+: { host: host } } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { lifecycle+: { postStart+: { tcpSocket+: { port: port } } } },
              },
            },
            '#preStop':: d.obj(help="\"PreStop is called immediately before a container is terminated due to an\\nAPI request or management event such as liveness/startup probe failure,\\npreemption, resource contention, etc. The handler is not called if the\\ncontainer crashes or exits. The Pod's termination grace period countdown begins before the\\nPreStop hook is executed. Regardless of the outcome of the handler, the\\ncontainer will eventually terminate within the Pod's termination grace\\nperiod (unless delayed by finalizers). Other management of the container blocks until the hook completes\\nor until the termination grace period is reached.\\nMore info: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks\""),
            preStop: {
              '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
              exec: {
                '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
                withCommand(command): { lifecycle+: { preStop+: { exec+: { command: if std.isArray(v=command) then command else [command] } } } },
                '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
                withCommandMixin(command): { lifecycle+: { preStop+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } } },
              },
              '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
              httpGet: {
                '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
                httpHeaders: {
                  '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                  withName(name): { name: name },
                  '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                  withValue(value): { value: value },
                },
                '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { lifecycle+: { preStop+: { httpGet+: { host: host } } } },
                '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeaders(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
                withHttpHeadersMixin(httpHeaders): { lifecycle+: { preStop+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } } },
                '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
                withPath(path): { lifecycle+: { preStop+: { httpGet+: { path: path } } } },
                '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { lifecycle+: { preStop+: { httpGet+: { port: port } } } },
                '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
                withScheme(scheme): { lifecycle+: { preStop+: { httpGet+: { scheme: scheme } } } },
              },
              '#sleep':: d.obj(help='"Sleep represents a duration that the container should sleep."'),
              sleep: {
                '#withSeconds':: d.fn(help='"Seconds is the number of seconds to sleep."', args=[d.arg(name='seconds', type=d.T.integer)]),
                withSeconds(seconds): { lifecycle+: { preStop+: { sleep+: { seconds: seconds } } } },
              },
              '#tcpSocket':: d.obj(help='"Deprecated. TCPSocket is NOT supported as a LifecycleHandler and kept\\nfor backward compatibility. There is no validation of this field and\\nlifecycle hooks will fail at runtime when it is specified."'),
              tcpSocket: {
                '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
                withHost(host): { lifecycle+: { preStop+: { tcpSocket+: { host: host } } } },
                '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
                withPort(port): { lifecycle+: { preStop+: { tcpSocket+: { port: port } } } },
              },
            },
            '#withStopSignal':: d.fn(help='"StopSignal defines which signal will be sent to a container when it is being stopped.\\nIf not specified, the default is defined by the container runtime in use.\\nStopSignal can only be set for Pods with a non-empty .spec.os.name"', args=[d.arg(name='stopSignal', type=d.T.string)]),
            withStopSignal(stopSignal): { lifecycle+: { stopSignal: stopSignal } },
          },
          '#livenessProbe':: d.obj(help='"Periodic probe of container liveness.\\nContainer will be restarted if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
          livenessProbe: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { livenessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { livenessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
            },
            '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
            grpc: {
              '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
              withPort(port): { livenessProbe+: { grpc+: { port: port } } },
              '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
              withService(service): { livenessProbe+: { grpc+: { service: service } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { livenessProbe+: { httpGet+: { host: host } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { livenessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { livenessProbe+: { httpGet+: { path: path } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { livenessProbe+: { httpGet+: { port: port } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { livenessProbe+: { httpGet+: { scheme: scheme } } },
            },
            '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { livenessProbe+: { tcpSocket+: { host: host } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { livenessProbe+: { tcpSocket+: { port: port } } },
            },
            '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
            withFailureThreshold(failureThreshold): { livenessProbe+: { failureThreshold: failureThreshold } },
            '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
            withInitialDelaySeconds(initialDelaySeconds): { livenessProbe+: { initialDelaySeconds: initialDelaySeconds } },
            '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
            withPeriodSeconds(periodSeconds): { livenessProbe+: { periodSeconds: periodSeconds } },
            '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
            withSuccessThreshold(successThreshold): { livenessProbe+: { successThreshold: successThreshold } },
            '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
            withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { livenessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
            '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
            withTimeoutSeconds(timeoutSeconds): { livenessProbe+: { timeoutSeconds: timeoutSeconds } },
          },
          '#ports':: d.obj(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."'),
          ports: {
            '#withContainerPort':: d.fn(help="\"Number of port to expose on the pod's IP address.\\nThis must be a valid port number, 0 \u003c x \u003c 65536.\"", args=[d.arg(name='containerPort', type=d.T.integer)]),
            withContainerPort(containerPort): { containerPort: containerPort },
            '#withHostIP':: d.fn(help='"What host IP to bind the external port to."', args=[d.arg(name='hostIP', type=d.T.string)]),
            withHostIP(hostIP): { hostIP: hostIP },
            '#withHostPort':: d.fn(help='"Number of port to expose on the host.\\nIf specified, this must be a valid port number, 0 < x < 65536.\\nIf HostNetwork is specified, this must match ContainerPort.\\nMost containers do not need this."', args=[d.arg(name='hostPort', type=d.T.integer)]),
            withHostPort(hostPort): { hostPort: hostPort },
            '#withName':: d.fn(help='"If specified, this must be an IANA_SVC_NAME and unique within the pod. Each\\nnamed port in a pod must have a unique name. Name for the port that can be\\nreferred to by services."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withProtocol':: d.fn(help='"Protocol for port. Must be UDP, TCP, or SCTP.\\nDefaults to \\"TCP\\"."', args=[d.arg(name='protocol', type=d.T.string)]),
            withProtocol(protocol): { protocol: protocol },
          },
          '#readinessProbe':: d.obj(help='"Periodic probe of container service readiness.\\nContainer will be removed from service endpoints if the probe fails.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"'),
          readinessProbe: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { readinessProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { readinessProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
            },
            '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
            grpc: {
              '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
              withPort(port): { readinessProbe+: { grpc+: { port: port } } },
              '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
              withService(service): { readinessProbe+: { grpc+: { service: service } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { readinessProbe+: { httpGet+: { host: host } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { readinessProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { readinessProbe+: { httpGet+: { path: path } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { readinessProbe+: { httpGet+: { port: port } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { readinessProbe+: { httpGet+: { scheme: scheme } } },
            },
            '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { readinessProbe+: { tcpSocket+: { host: host } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { readinessProbe+: { tcpSocket+: { port: port } } },
            },
            '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
            withFailureThreshold(failureThreshold): { readinessProbe+: { failureThreshold: failureThreshold } },
            '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
            withInitialDelaySeconds(initialDelaySeconds): { readinessProbe+: { initialDelaySeconds: initialDelaySeconds } },
            '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
            withPeriodSeconds(periodSeconds): { readinessProbe+: { periodSeconds: periodSeconds } },
            '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
            withSuccessThreshold(successThreshold): { readinessProbe+: { successThreshold: successThreshold } },
            '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
            withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { readinessProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
            '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
            withTimeoutSeconds(timeoutSeconds): { readinessProbe+: { timeoutSeconds: timeoutSeconds } },
          },
          '#resizePolicy':: d.obj(help='"Resources resize policy for the container."'),
          resizePolicy: {
            '#withResourceName':: d.fn(help='"Name of the resource to which this resource resize policy applies.\\nSupported values: cpu, memory."', args=[d.arg(name='resourceName', type=d.T.string)]),
            withResourceName(resourceName): { resourceName: resourceName },
            '#withRestartPolicy':: d.fn(help='"Restart policy to apply when specified resource is resized.\\nIf not specified, it defaults to NotRequired."', args=[d.arg(name='restartPolicy', type=d.T.string)]),
            withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
          },
          '#resources':: d.obj(help='"Compute Resources required by this container.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"'),
          resources: {
            '#claims':: d.obj(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."'),
            claims: {
              '#withName':: d.fn(help='"Name must match the name of one entry in pod.spec.resourceClaims of\\nthe Pod where this field is used. It makes that resource available\\ninside a container."', args=[d.arg(name='name', type=d.T.string)]),
              withName(name): { name: name },
              '#withRequest':: d.fn(help='"Request is the name chosen for a request in the referenced claim.\\nIf empty, everything from the claim is made available, otherwise\\nonly the result of this request."', args=[d.arg(name='request', type=d.T.string)]),
              withRequest(request): { request: request },
            },
            '#withClaims':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."', args=[d.arg(name='claims', type=d.T.array)]),
            withClaims(claims): { resources+: { claims: if std.isArray(v=claims) then claims else [claims] } },
            '#withClaimsMixin':: d.fn(help='"Claims lists the names of resources, defined in spec.resourceClaims,\\nthat are used by this container.\\n\\nThis field depends on the\\nDynamicResourceAllocation feature gate.\\n\\nThis field is immutable. It can only be set for containers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='claims', type=d.T.array)]),
            withClaimsMixin(claims): { resources+: { claims+: if std.isArray(v=claims) then claims else [claims] } },
            '#withLimits':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='limits', type=d.T.object)]),
            withLimits(limits): { resources+: { limits: limits } },
            '#withLimitsMixin':: d.fn(help='"Limits describes the maximum amount of compute resources allowed.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='limits', type=d.T.object)]),
            withLimitsMixin(limits): { resources+: { limits+: limits } },
            '#withRequests':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"', args=[d.arg(name='requests', type=d.T.object)]),
            withRequests(requests): { resources+: { requests: requests } },
            '#withRequestsMixin':: d.fn(help='"Requests describes the minimum amount of compute resources required.\\nIf Requests is omitted for a container, it defaults to Limits if that is explicitly specified,\\notherwise to an implementation-defined value. Requests cannot exceed Limits.\\nMore info: https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='requests', type=d.T.object)]),
            withRequestsMixin(requests): { resources+: { requests+: requests } },
          },
          '#restartPolicyRules':: d.obj(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\""),
          restartPolicyRules: {
            '#exitCodes':: d.obj(help='"Represents the exit codes to check on container exits."'),
            exitCodes: {
              '#withOperator':: d.fn(help='"Represents the relationship between the container exit code(s) and the\\nspecified values. Possible values are:\\n- In: the requirement is satisfied if the container exit code is in the\\n  set of specified values.\\n- NotIn: the requirement is satisfied if the container exit code is\\n  not in the set of specified values."', args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { exitCodes+: { operator: operator } },
              '#withValues':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."', args=[d.arg(name='values', type=d.T.array)]),
              withValues(values): { exitCodes+: { values: if std.isArray(v=values) then values else [values] } },
              '#withValuesMixin':: d.fn(help='"Specifies the set of values to check for container exit codes.\\nAt most 255 elements are allowed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
              withValuesMixin(values): { exitCodes+: { values+: if std.isArray(v=values) then values else [values] } },
            },
            '#withAction':: d.fn(help='"Specifies the action taken on a container exit if the requirements\\nare satisfied. The only possible value is \\"Restart\\" to restart the\\ncontainer."', args=[d.arg(name='action', type=d.T.string)]),
            withAction(action): { action: action },
          },
          '#securityContext':: d.obj(help='"SecurityContext defines the security options the container should be run with.\\nIf set, the fields of SecurityContext override the equivalent fields of PodSecurityContext.\\nMore info: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/"'),
          securityContext: {
            '#appArmorProfile':: d.obj(help="\"appArmorProfile is the AppArmor options to use by this container. If set, this profile\\noverrides the pod's appArmorProfile.\\nNote that this field cannot be set when spec.os.name is windows.\""),
            appArmorProfile: {
              '#withLocalhostProfile':: d.fn(help='"localhostProfile indicates a profile loaded on the node that should be used.\\nThe profile must be preconfigured on the node to work.\\nMust match the loaded name of the profile.\\nMust be set if and only if type is \\"Localhost\\"."', args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { securityContext+: { appArmorProfile+: { localhostProfile: localhostProfile } } },
              '#withType':: d.fn(help="\"type indicates which kind of AppArmor profile will be applied.\\nValid options are:\\n  Localhost - a profile pre-loaded on the node.\\n  RuntimeDefault - the container runtime's default profile.\\n  Unconfined - no AppArmor enforcement.\"", args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { securityContext+: { appArmorProfile+: { type: type } } },
            },
            '#capabilities':: d.obj(help='"The capabilities to add/drop when running containers.\\nDefaults to the default set of capabilities granted by the container runtime.\\nNote that this field cannot be set when spec.os.name is windows."'),
            capabilities: {
              '#withAdd':: d.fn(help='"Added capabilities"', args=[d.arg(name='add', type=d.T.array)]),
              withAdd(add): { securityContext+: { capabilities+: { add: if std.isArray(v=add) then add else [add] } } },
              '#withAddMixin':: d.fn(help='"Added capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='add', type=d.T.array)]),
              withAddMixin(add): { securityContext+: { capabilities+: { add+: if std.isArray(v=add) then add else [add] } } },
              '#withDrop':: d.fn(help='"Removed capabilities"', args=[d.arg(name='drop', type=d.T.array)]),
              withDrop(drop): { securityContext+: { capabilities+: { drop: if std.isArray(v=drop) then drop else [drop] } } },
              '#withDropMixin':: d.fn(help='"Removed capabilities"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='drop', type=d.T.array)]),
              withDropMixin(drop): { securityContext+: { capabilities+: { drop+: if std.isArray(v=drop) then drop else [drop] } } },
            },
            '#seLinuxOptions':: d.obj(help='"The SELinux context to be applied to the container.\\nIf unspecified, the container runtime will allocate a random SELinux context for each\\ncontainer.  May also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seLinuxOptions: {
              '#withLevel':: d.fn(help='"Level is SELinux level label that applies to the container."', args=[d.arg(name='level', type=d.T.string)]),
              withLevel(level): { securityContext+: { seLinuxOptions+: { level: level } } },
              '#withRole':: d.fn(help='"Role is a SELinux role label that applies to the container."', args=[d.arg(name='role', type=d.T.string)]),
              withRole(role): { securityContext+: { seLinuxOptions+: { role: role } } },
              '#withType':: d.fn(help='"Type is a SELinux type label that applies to the container."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { securityContext+: { seLinuxOptions+: { type: type } } },
              '#withUser':: d.fn(help='"User is a SELinux user label that applies to the container."', args=[d.arg(name='user', type=d.T.string)]),
              withUser(user): { securityContext+: { seLinuxOptions+: { user: user } } },
            },
            '#seccompProfile':: d.obj(help='"The seccomp options to use by this container. If seccomp options are\\nprovided at both the pod & container level, the container options\\noverride the pod options.\\nNote that this field cannot be set when spec.os.name is windows."'),
            seccompProfile: {
              '#withLocalhostProfile':: d.fn(help="\"localhostProfile indicates a profile defined in a file on the node should be used.\\nThe profile must be preconfigured on the node to work.\\nMust be a descending path, relative to the kubelet's configured seccomp profile location.\\nMust be set if type is \\\"Localhost\\\". Must NOT be set for any other type.\"", args=[d.arg(name='localhostProfile', type=d.T.string)]),
              withLocalhostProfile(localhostProfile): { securityContext+: { seccompProfile+: { localhostProfile: localhostProfile } } },
              '#withType':: d.fn(help='"type indicates which kind of seccomp profile will be applied.\\nValid options are:\\n\\nLocalhost - a profile defined in a file on the node should be used.\\nRuntimeDefault - the container runtime default profile should be used.\\nUnconfined - no profile should be applied."', args=[d.arg(name='type', type=d.T.string)]),
              withType(type): { securityContext+: { seccompProfile+: { type: type } } },
            },
            '#windowsOptions':: d.obj(help='"The Windows specific settings applied to all containers.\\nIf unspecified, the options from the PodSecurityContext will be used.\\nIf set in both SecurityContext and PodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is linux."'),
            windowsOptions: {
              '#withGmsaCredentialSpec':: d.fn(help='"GMSACredentialSpec is where the GMSA admission webhook\\n(https://github.com/kubernetes-sigs/windows-gmsa) inlines the contents of the\\nGMSA credential spec named by the GMSACredentialSpecName field."', args=[d.arg(name='gmsaCredentialSpec', type=d.T.string)]),
              withGmsaCredentialSpec(gmsaCredentialSpec): { securityContext+: { windowsOptions+: { gmsaCredentialSpec: gmsaCredentialSpec } } },
              '#withGmsaCredentialSpecName':: d.fn(help='"GMSACredentialSpecName is the name of the GMSA credential spec to use."', args=[d.arg(name='gmsaCredentialSpecName', type=d.T.string)]),
              withGmsaCredentialSpecName(gmsaCredentialSpecName): { securityContext+: { windowsOptions+: { gmsaCredentialSpecName: gmsaCredentialSpecName } } },
              '#withHostProcess':: d.fn(help="\"HostProcess determines if a container should be run as a 'Host Process' container.\\nAll of a Pod's containers must have the same effective HostProcess value\\n(it is not allowed to have a mix of HostProcess containers and non-HostProcess containers).\\nIn addition, if HostProcess is true then HostNetwork must also be set to true.\"", args=[d.arg(name='hostProcess', type=d.T.boolean)]),
              withHostProcess(hostProcess): { securityContext+: { windowsOptions+: { hostProcess: hostProcess } } },
              '#withRunAsUserName':: d.fn(help='"The UserName in Windows to run the entrypoint of the container process.\\nDefaults to the user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext. If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsUserName', type=d.T.string)]),
              withRunAsUserName(runAsUserName): { securityContext+: { windowsOptions+: { runAsUserName: runAsUserName } } },
            },
            '#withAllowPrivilegeEscalation':: d.fn(help='"AllowPrivilegeEscalation controls whether a process can gain more\\nprivileges than its parent process. This bool directly controls if\\nthe no_new_privs flag will be set on the container process.\\nAllowPrivilegeEscalation is true always when the container is:\\n1) run as Privileged\\n2) has CAP_SYS_ADMIN\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='allowPrivilegeEscalation', type=d.T.boolean)]),
            withAllowPrivilegeEscalation(allowPrivilegeEscalation): { securityContext+: { allowPrivilegeEscalation: allowPrivilegeEscalation } },
            '#withPrivileged':: d.fn(help='"Run container in privileged mode.\\nProcesses in privileged containers are essentially equivalent to root on the host.\\nDefaults to false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='privileged', type=d.T.boolean)]),
            withPrivileged(privileged): { securityContext+: { privileged: privileged } },
            '#withProcMount':: d.fn(help='"procMount denotes the type of proc mount to use for the containers.\\nThe default value is Default which uses the container runtime defaults for\\nreadonly paths and masked paths.\\nThis requires the ProcMountType feature flag to be enabled.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='procMount', type=d.T.string)]),
            withProcMount(procMount): { securityContext+: { procMount: procMount } },
            '#withReadOnlyRootFilesystem':: d.fn(help='"Whether this container has a read-only root filesystem.\\nDefault is false.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='readOnlyRootFilesystem', type=d.T.boolean)]),
            withReadOnlyRootFilesystem(readOnlyRootFilesystem): { securityContext+: { readOnlyRootFilesystem: readOnlyRootFilesystem } },
            '#withRunAsGroup':: d.fn(help='"The GID to run the entrypoint of the container process.\\nUses runtime default if unset.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsGroup', type=d.T.integer)]),
            withRunAsGroup(runAsGroup): { securityContext+: { runAsGroup: runAsGroup } },
            '#withRunAsNonRoot':: d.fn(help='"Indicates that the container must run as a non-root user.\\nIf true, the Kubelet will validate the image at runtime to ensure that it\\ndoes not run as UID 0 (root) and fail to start the container if it does.\\nIf unset or false, no such validation will be performed.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence."', args=[d.arg(name='runAsNonRoot', type=d.T.boolean)]),
            withRunAsNonRoot(runAsNonRoot): { securityContext+: { runAsNonRoot: runAsNonRoot } },
            '#withRunAsUser':: d.fn(help='"The UID to run the entrypoint of the container process.\\nDefaults to user specified in image metadata if unspecified.\\nMay also be set in PodSecurityContext.  If set in both SecurityContext and\\nPodSecurityContext, the value specified in SecurityContext takes precedence.\\nNote that this field cannot be set when spec.os.name is windows."', args=[d.arg(name='runAsUser', type=d.T.integer)]),
            withRunAsUser(runAsUser): { securityContext+: { runAsUser: runAsUser } },
          },
          '#startupProbe':: d.obj(help="\"StartupProbe indicates that the Pod has successfully initialized.\\nIf specified, no other probes are executed until this completes successfully.\\nIf this probe fails, the Pod will be restarted, just as if the livenessProbe failed.\\nThis can be used to provide different probe parameters at the beginning of a Pod's lifecycle,\\nwhen it might take a long time to load data or warm a cache, than during steady-state operation.\\nThis cannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes\""),
          startupProbe: {
            '#exec':: d.obj(help='"Exec specifies a command to execute in the container."'),
            exec: {
              '#withCommand':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"", args=[d.arg(name='command', type=d.T.array)]),
              withCommand(command): { startupProbe+: { exec+: { command: if std.isArray(v=command) then command else [command] } } },
              '#withCommandMixin':: d.fn(help="\"Command is the command line to execute inside the container, the working directory for the\\ncommand  is root ('/') in the container's filesystem. The command is simply exec'd, it is\\nnot run inside a shell, so traditional shell instructions ('|', etc) won't work. To use\\na shell, you need to explicitly call out to that shell.\\nExit status of 0 is treated as live/healthy and non-zero is unhealthy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
              withCommandMixin(command): { startupProbe+: { exec+: { command+: if std.isArray(v=command) then command else [command] } } },
            },
            '#grpc':: d.obj(help='"GRPC specifies a GRPC HealthCheckRequest."'),
            grpc: {
              '#withPort':: d.fn(help='"Port number of the gRPC service. Number must be in the range 1 to 65535."', args=[d.arg(name='port', type=d.T.integer)]),
              withPort(port): { startupProbe+: { grpc+: { port: port } } },
              '#withService':: d.fn(help='"Service is the name of the service to place in the gRPC HealthCheckRequest\\n(see https://github.com/grpc/grpc/blob/master/doc/health-checking.md).\\n\\nIf this is not specified, the default behavior is defined by gRPC."', args=[d.arg(name='service', type=d.T.string)]),
              withService(service): { startupProbe+: { grpc+: { service: service } } },
            },
            '#httpGet':: d.obj(help='"HTTPGet specifies an HTTP GET request to perform."'),
            httpGet: {
              '#httpHeaders':: d.obj(help='"Custom headers to set in the request. HTTP allows repeated headers."'),
              httpHeaders: {
                '#withName':: d.fn(help='"The header field name.\\nThis will be canonicalized upon output, so case-variant names will be understood as the same header."', args=[d.arg(name='name', type=d.T.string)]),
                withName(name): { name: name },
                '#withValue':: d.fn(help='"The header field value"', args=[d.arg(name='value', type=d.T.string)]),
                withValue(value): { value: value },
              },
              '#withHost':: d.fn(help='"Host name to connect to, defaults to the pod IP. You probably want to set\\n\\"Host\\" in httpHeaders instead."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { startupProbe+: { httpGet+: { host: host } } },
              '#withHttpHeaders':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeaders(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
              '#withHttpHeadersMixin':: d.fn(help='"Custom headers to set in the request. HTTP allows repeated headers."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='httpHeaders', type=d.T.array)]),
              withHttpHeadersMixin(httpHeaders): { startupProbe+: { httpGet+: { httpHeaders+: if std.isArray(v=httpHeaders) then httpHeaders else [httpHeaders] } } },
              '#withPath':: d.fn(help='"Path to access on the HTTP server."', args=[d.arg(name='path', type=d.T.string)]),
              withPath(path): { startupProbe+: { httpGet+: { path: path } } },
              '#withPort':: d.fn(help='"Name or number of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { startupProbe+: { httpGet+: { port: port } } },
              '#withScheme':: d.fn(help='"Scheme to use for connecting to the host.\\nDefaults to HTTP."', args=[d.arg(name='scheme', type=d.T.string)]),
              withScheme(scheme): { startupProbe+: { httpGet+: { scheme: scheme } } },
            },
            '#tcpSocket':: d.obj(help='"TCPSocket specifies a connection to a TCP port."'),
            tcpSocket: {
              '#withHost':: d.fn(help='"Optional: Host name to connect to, defaults to the pod IP."', args=[d.arg(name='host', type=d.T.string)]),
              withHost(host): { startupProbe+: { tcpSocket+: { host: host } } },
              '#withPort':: d.fn(help='"Number or name of the port to access on the container.\\nNumber must be in the range 1 to 65535.\\nName must be an IANA_SVC_NAME."', args=[d.arg(name='port', type=d.T.any)]),
              withPort(port): { startupProbe+: { tcpSocket+: { port: port } } },
            },
            '#withFailureThreshold':: d.fn(help='"Minimum consecutive failures for the probe to be considered failed after having succeeded.\\nDefaults to 3. Minimum value is 1."', args=[d.arg(name='failureThreshold', type=d.T.integer)]),
            withFailureThreshold(failureThreshold): { startupProbe+: { failureThreshold: failureThreshold } },
            '#withInitialDelaySeconds':: d.fn(help='"Number of seconds after the container has started before liveness probes are initiated.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='initialDelaySeconds', type=d.T.integer)]),
            withInitialDelaySeconds(initialDelaySeconds): { startupProbe+: { initialDelaySeconds: initialDelaySeconds } },
            '#withPeriodSeconds':: d.fn(help='"How often (in seconds) to perform the probe.\\nDefault to 10 seconds. Minimum value is 1."', args=[d.arg(name='periodSeconds', type=d.T.integer)]),
            withPeriodSeconds(periodSeconds): { startupProbe+: { periodSeconds: periodSeconds } },
            '#withSuccessThreshold':: d.fn(help='"Minimum consecutive successes for the probe to be considered successful after having failed.\\nDefaults to 1. Must be 1 for liveness and startup. Minimum value is 1."', args=[d.arg(name='successThreshold', type=d.T.integer)]),
            withSuccessThreshold(successThreshold): { startupProbe+: { successThreshold: successThreshold } },
            '#withTerminationGracePeriodSeconds':: d.fn(help="\"Optional duration in seconds the pod needs to terminate gracefully upon probe failure.\\nThe grace period is the duration in seconds after the processes running in the pod are sent\\na termination signal and the time when the processes are forcibly halted with a kill signal.\\nSet this value longer than the expected cleanup time for your process.\\nIf this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this\\nvalue overrides the value provided by the pod spec.\\nValue must be non-negative integer. The value zero indicates stop immediately via\\nthe kill signal (no opportunity to shut down).\\nThis is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.\\nMinimum value is 1. spec.terminationGracePeriodSeconds is used if unset.\"", args=[d.arg(name='terminationGracePeriodSeconds', type=d.T.integer)]),
            withTerminationGracePeriodSeconds(terminationGracePeriodSeconds): { startupProbe+: { terminationGracePeriodSeconds: terminationGracePeriodSeconds } },
            '#withTimeoutSeconds':: d.fn(help='"Number of seconds after which the probe times out.\\nDefaults to 1 second. Minimum value is 1.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes"', args=[d.arg(name='timeoutSeconds', type=d.T.integer)]),
            withTimeoutSeconds(timeoutSeconds): { startupProbe+: { timeoutSeconds: timeoutSeconds } },
          },
          '#volumeDevices':: d.obj(help='"volumeDevices is the list of block devices to be used by the container."'),
          volumeDevices: {
            '#withDevicePath':: d.fn(help='"devicePath is the path inside of the container that the device will be mapped to."', args=[d.arg(name='devicePath', type=d.T.string)]),
            withDevicePath(devicePath): { devicePath: devicePath },
            '#withName':: d.fn(help='"name must match the name of a persistentVolumeClaim in the pod"', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
          },
          '#volumeMounts':: d.obj(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\""),
          volumeMounts: {
            '#withMountPath':: d.fn(help="\"Path within the container at which the volume should be mounted.  Must\\nnot contain ':'.\"", args=[d.arg(name='mountPath', type=d.T.string)]),
            withMountPath(mountPath): { mountPath: mountPath },
            '#withMountPropagation':: d.fn(help='"mountPropagation determines how mounts are propagated from the host\\nto container and the other way around.\\nWhen not set, MountPropagationNone is used.\\nThis field is beta in 1.10.\\nWhen RecursiveReadOnly is set to IfPossible or to Enabled, MountPropagation must be None or unspecified\\n(which defaults to None)."', args=[d.arg(name='mountPropagation', type=d.T.string)]),
            withMountPropagation(mountPropagation): { mountPropagation: mountPropagation },
            '#withName':: d.fn(help='"This must match the Name of a Volume."', args=[d.arg(name='name', type=d.T.string)]),
            withName(name): { name: name },
            '#withReadOnly':: d.fn(help='"Mounted read-only if true, read-write otherwise (false or unspecified).\\nDefaults to false."', args=[d.arg(name='readOnly', type=d.T.boolean)]),
            withReadOnly(readOnly): { readOnly: readOnly },
            '#withRecursiveReadOnly':: d.fn(help='"RecursiveReadOnly specifies whether read-only mounts should be handled\\nrecursively.\\n\\nIf ReadOnly is false, this field has no meaning and must be unspecified.\\n\\nIf ReadOnly is true, and this field is set to Disabled, the mount is not made\\nrecursively read-only.  If this field is set to IfPossible, the mount is made\\nrecursively read-only, if it is supported by the container runtime.  If this\\nfield is set to Enabled, the mount is made recursively read-only if it is\\nsupported by the container runtime, otherwise the pod will not be started and\\nan error will be generated to indicate the reason.\\n\\nIf this field is set to IfPossible or Enabled, MountPropagation must be set to\\nNone (or be unspecified, which defaults to None).\\n\\nIf this field is not specified, it is treated as an equivalent of Disabled."', args=[d.arg(name='recursiveReadOnly', type=d.T.string)]),
            withRecursiveReadOnly(recursiveReadOnly): { recursiveReadOnly: recursiveReadOnly },
            '#withSubPath':: d.fn(help="\"Path within the volume from which the container's volume should be mounted.\\nDefaults to \\\"\\\" (volume's root).\"", args=[d.arg(name='subPath', type=d.T.string)]),
            withSubPath(subPath): { subPath: subPath },
            '#withSubPathExpr':: d.fn(help="\"Expanded path within the volume from which the container's volume should be mounted.\\nBehaves similarly to SubPath but environment variable references $(VAR_NAME) are expanded using the container's environment.\\nDefaults to \\\"\\\" (volume's root).\\nSubPathExpr and SubPath are mutually exclusive.\"", args=[d.arg(name='subPathExpr', type=d.T.string)]),
            withSubPathExpr(subPathExpr): { subPathExpr: subPathExpr },
          },
          '#withArgs':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='args', type=d.T.array)]),
          withArgs(args): { args: if std.isArray(v=args) then args else [args] },
          '#withArgsMixin':: d.fn(help="\"Arguments to the entrypoint.\\nThe container image's CMD is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='args', type=d.T.array)]),
          withArgsMixin(args): { args+: if std.isArray(v=args) then args else [args] },
          '#withCommand':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"", args=[d.arg(name='command', type=d.T.array)]),
          withCommand(command): { command: if std.isArray(v=command) then command else [command] },
          '#withCommandMixin':: d.fn(help="\"Entrypoint array. Not executed within a shell.\\nThe container image's ENTRYPOINT is used if this is not provided.\\nVariable references $(VAR_NAME) are expanded using the container's environment. If a variable\\ncannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced\\nto a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. \\\"$$(VAR_NAME)\\\" will\\nproduce the string literal \\\"$(VAR_NAME)\\\". Escaped references will never be expanded, regardless\\nof whether the variable exists or not. Cannot be updated.\\nMore info: https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#running-a-command-in-a-shell\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='command', type=d.T.array)]),
          withCommandMixin(command): { command+: if std.isArray(v=command) then command else [command] },
          '#withEnv':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."', args=[d.arg(name='env', type=d.T.array)]),
          withEnv(env): { env: if std.isArray(v=env) then env else [env] },
          '#withEnvFrom':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"", args=[d.arg(name='envFrom', type=d.T.array)]),
          withEnvFrom(envFrom): { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] },
          '#withEnvFromMixin':: d.fn(help="\"List of sources to populate environment variables in the container.\\nThe keys defined within a source may consist of any printable ASCII characters except '='.\\nWhen a key exists in multiple\\nsources, the value associated with the last source will take precedence.\\nValues defined by an Env with a duplicate key will take precedence.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='envFrom', type=d.T.array)]),
          withEnvFromMixin(envFrom): { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] },
          '#withEnvMixin':: d.fn(help='"List of environment variables to set in the container.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
          withEnvMixin(env): { env+: if std.isArray(v=env) then env else [env] },
          '#withImage':: d.fn(help='"Container image name.\\nMore info: https://kubernetes.io/docs/concepts/containers/images\\nThis field is optional to allow higher level config management to default or override\\ncontainer images in workload controllers like Deployments and StatefulSets."', args=[d.arg(name='image', type=d.T.string)]),
          withImage(image): { image: image },
          '#withImagePullPolicy':: d.fn(help='"Image pull policy.\\nOne of Always, Never, IfNotPresent.\\nDefaults to Always if :latest tag is specified, or IfNotPresent otherwise.\\nCannot be updated.\\nMore info: https://kubernetes.io/docs/concepts/containers/images#updating-images"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
          withImagePullPolicy(imagePullPolicy): { imagePullPolicy: imagePullPolicy },
          '#withName':: d.fn(help='"Name of the container specified as a DNS_LABEL.\\nEach container in a pod must have a unique name (DNS_LABEL).\\nCannot be updated."', args=[d.arg(name='name', type=d.T.string)]),
          withName(name): { name: name },
          '#withPorts':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."', args=[d.arg(name='ports', type=d.T.array)]),
          withPorts(ports): { ports: if std.isArray(v=ports) then ports else [ports] },
          '#withPortsMixin':: d.fn(help='"List of ports to expose from the container. Not specifying a port here\\nDOES NOT prevent that port from being exposed. Any port which is\\nlistening on the default \\"0.0.0.0\\" address inside a container will be\\naccessible from the network.\\nModifying this array with strategic merge patch may corrupt the data.\\nFor more information See https://github.com/kubernetes/kubernetes/issues/108255.\\nCannot be updated."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='ports', type=d.T.array)]),
          withPortsMixin(ports): { ports+: if std.isArray(v=ports) then ports else [ports] },
          '#withResizePolicy':: d.fn(help='"Resources resize policy for the container."', args=[d.arg(name='resizePolicy', type=d.T.array)]),
          withResizePolicy(resizePolicy): { resizePolicy: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
          '#withResizePolicyMixin':: d.fn(help='"Resources resize policy for the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='resizePolicy', type=d.T.array)]),
          withResizePolicyMixin(resizePolicy): { resizePolicy+: if std.isArray(v=resizePolicy) then resizePolicy else [resizePolicy] },
          '#withRestartPolicy':: d.fn(help="\"RestartPolicy defines the restart behavior of individual containers in a pod.\\nThis overrides the pod-level restart policy. When this field is not specified,\\nthe restart behavior is defined by the Pod's restart policy and the container type.\\nAdditionally, setting the RestartPolicy as \\\"Always\\\" for the init container will\\nhave the following effect:\\nthis init container will be continually restarted on\\nexit until all regular containers have terminated. Once all regular\\ncontainers have completed, all init containers with restartPolicy \\\"Always\\\"\\nwill be shut down. This lifecycle differs from normal init containers and\\nis often referred to as a \\\"sidecar\\\" container. Although this init\\ncontainer still starts in the init container sequence, it does not wait\\nfor the container to complete before proceeding to the next init\\ncontainer. Instead, the next init container starts immediately after this\\ninit container is started, or after any startupProbe has successfully\\ncompleted.\"", args=[d.arg(name='restartPolicy', type=d.T.string)]),
          withRestartPolicy(restartPolicy): { restartPolicy: restartPolicy },
          '#withRestartPolicyRules':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
          withRestartPolicyRules(restartPolicyRules): { restartPolicyRules: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
          '#withRestartPolicyRulesMixin':: d.fn(help="\"Represents a list of rules to be checked to determine if the\\ncontainer should be restarted on exit. The rules are evaluated in\\norder. Once a rule matches a container exit condition, the remaining\\nrules are ignored. If no rule matches the container exit condition,\\nthe Container-level restart policy determines the whether the container\\nis restarted or not. Constraints on the rules:\\n- At most 20 rules are allowed.\\n- Rules can have the same action.\\n- Identical rules are not forbidden in validations.\\nWhen rules are specified, container MUST set RestartPolicy explicitly\\neven it if matches the Pod's RestartPolicy.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='restartPolicyRules', type=d.T.array)]),
          withRestartPolicyRulesMixin(restartPolicyRules): { restartPolicyRules+: if std.isArray(v=restartPolicyRules) then restartPolicyRules else [restartPolicyRules] },
          '#withStdin':: d.fn(help='"Whether this container should allocate a buffer for stdin in the container runtime. If this\\nis not set, reads from stdin in the container will always result in EOF.\\nDefault is false."', args=[d.arg(name='stdin', type=d.T.boolean)]),
          withStdin(stdin): { stdin: stdin },
          '#withStdinOnce':: d.fn(help='"Whether the container runtime should close the stdin channel after it has been opened by\\na single attach. When stdin is true the stdin stream will remain open across multiple attach\\nsessions. If stdinOnce is set to true, stdin is opened on container start, is empty until the\\nfirst client attaches to stdin, and then remains open and accepts data until the client disconnects,\\nat which time stdin is closed and remains closed until the container is restarted. If this\\nflag is false, a container processes that reads from stdin will never receive an EOF.\\nDefault is false"', args=[d.arg(name='stdinOnce', type=d.T.boolean)]),
          withStdinOnce(stdinOnce): { stdinOnce: stdinOnce },
          '#withTerminationMessagePath':: d.fn(help="\"Optional: Path at which the file to which the container's termination message\\nwill be written is mounted into the container's filesystem.\\nMessage written is intended to be brief final status, such as an assertion failure message.\\nWill be truncated by the node if greater than 4096 bytes. The total message length across\\nall containers will be limited to 12kb.\\nDefaults to /dev/termination-log.\\nCannot be updated.\"", args=[d.arg(name='terminationMessagePath', type=d.T.string)]),
          withTerminationMessagePath(terminationMessagePath): { terminationMessagePath: terminationMessagePath },
          '#withTerminationMessagePolicy':: d.fn(help='"Indicate how the termination message should be populated. File will use the contents of\\nterminationMessagePath to populate the container status message on both success and failure.\\nFallbackToLogsOnError will use the last chunk of container log output if the termination\\nmessage file is empty and the container exited with an error.\\nThe log output is limited to 2048 bytes or 80 lines, whichever is smaller.\\nDefaults to File.\\nCannot be updated."', args=[d.arg(name='terminationMessagePolicy', type=d.T.string)]),
          withTerminationMessagePolicy(terminationMessagePolicy): { terminationMessagePolicy: terminationMessagePolicy },
          '#withTty':: d.fn(help="\"Whether this container should allocate a TTY for itself, also requires 'stdin' to be true.\\nDefault is false.\"", args=[d.arg(name='tty', type=d.T.boolean)]),
          withTty(tty): { tty: tty },
          '#withVolumeDevices':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."', args=[d.arg(name='volumeDevices', type=d.T.array)]),
          withVolumeDevices(volumeDevices): { volumeDevices: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
          '#withVolumeDevicesMixin':: d.fn(help='"volumeDevices is the list of block devices to be used by the container."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='volumeDevices', type=d.T.array)]),
          withVolumeDevicesMixin(volumeDevices): { volumeDevices+: if std.isArray(v=volumeDevices) then volumeDevices else [volumeDevices] },
          '#withVolumeMounts':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"", args=[d.arg(name='volumeMounts', type=d.T.array)]),
          withVolumeMounts(volumeMounts): { volumeMounts: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
          '#withVolumeMountsMixin':: d.fn(help="\"Pod volumes to mount into the container's filesystem.\\nCannot be updated.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='volumeMounts', type=d.T.array)]),
          withVolumeMountsMixin(volumeMounts): { volumeMounts+: if std.isArray(v=volumeMounts) then volumeMounts else [volumeMounts] },
          '#withWorkingDir':: d.fn(help="\"Container's working directory.\\nIf not specified, the container runtime's default will be used, which\\nmight be configured in the container image.\\nCannot be updated.\"", args=[d.arg(name='workingDir', type=d.T.string)]),
          withWorkingDir(workingDir): { workingDir: workingDir },
        },
        '#tolerations':: d.obj(help='"Tolerations of a PgBouncer pod. Changing this value causes PgBouncer to\\nrestart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"'),
        tolerations: {
          '#withEffect':: d.fn(help='"Effect indicates the taint effect to match. Empty means match all taint effects.\\nWhen specified, allowed values are NoSchedule, PreferNoSchedule and NoExecute."', args=[d.arg(name='effect', type=d.T.string)]),
          withEffect(effect): { effect: effect },
          '#withKey':: d.fn(help='"Key is the taint key that the toleration applies to. Empty means match all taint keys.\\nIf the key is empty, operator must be Exists; this combination means to match all values and all keys."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withOperator':: d.fn(help="\"Operator represents a key's relationship to the value.\\nValid operators are Exists and Equal. Defaults to Equal.\\nExists is equivalent to wildcard for value, so that a pod can\\ntolerate all taints of a particular category.\"", args=[d.arg(name='operator', type=d.T.string)]),
          withOperator(operator): { operator: operator },
          '#withTolerationSeconds':: d.fn(help='"TolerationSeconds represents the period of time the toleration (which must be\\nof effect NoExecute, otherwise this field is ignored) tolerates the taint. By default,\\nit is not set, which means tolerate the taint forever (do not evict). Zero and\\nnegative values will be treated as 0 (evict immediately) by the system."', args=[d.arg(name='tolerationSeconds', type=d.T.integer)]),
          withTolerationSeconds(tolerationSeconds): { tolerationSeconds: tolerationSeconds },
          '#withValue':: d.fn(help='"Value is the taint value the toleration matches to.\\nIf the operator is Exists, the value should be empty, otherwise just a regular string."', args=[d.arg(name='value', type=d.T.string)]),
          withValue(value): { value: value },
        },
        '#topologySpreadConstraints':: d.obj(help='"Topology spread constraints of a PgBouncer pod. Changing this value causes\\nPgBouncer to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"'),
        topologySpreadConstraints: {
          '#labelSelector':: d.obj(help='"LabelSelector is used to find matching pods.\\nPods that match this label selector are counted to determine the number of pods\\nin their corresponding topology domain."'),
          labelSelector: {
            '#matchExpressions':: d.obj(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."'),
            matchExpressions: {
              '#withKey':: d.fn(help='"key is the label key that the selector applies to."', args=[d.arg(name='key', type=d.T.string)]),
              withKey(key): { key: key },
              '#withOperator':: d.fn(help="\"operator represents a key's relationship to a set of values.\\nValid operators are In, NotIn, Exists and DoesNotExist.\"", args=[d.arg(name='operator', type=d.T.string)]),
              withOperator(operator): { operator: operator },
              '#withValues':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."', args=[d.arg(name='values', type=d.T.array)]),
              withValues(values): { values: if std.isArray(v=values) then values else [values] },
              '#withValuesMixin':: d.fn(help='"values is an array of string values. If the operator is In or NotIn,\\nthe values array must be non-empty. If the operator is Exists or DoesNotExist,\\nthe values array must be empty. This array is replaced during a strategic\\nmerge patch."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='values', type=d.T.array)]),
              withValuesMixin(values): { values+: if std.isArray(v=values) then values else [values] },
            },
            '#withMatchExpressions':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressions(matchExpressions): { labelSelector+: { matchExpressions: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
            '#withMatchExpressionsMixin':: d.fn(help='"matchExpressions is a list of label selector requirements. The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchExpressions', type=d.T.array)]),
            withMatchExpressionsMixin(matchExpressions): { labelSelector+: { matchExpressions+: if std.isArray(v=matchExpressions) then matchExpressions else [matchExpressions] } },
            '#withMatchLabels':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabels(matchLabels): { labelSelector+: { matchLabels: matchLabels } },
            '#withMatchLabelsMixin':: d.fn(help='"matchLabels is a map of {key,value} pairs. A single {key,value} in the matchLabels\\nmap is equivalent to an element of matchExpressions, whose key field is \\"key\\", the\\noperator is \\"In\\", and the values array contains only \\"value\\". The requirements are ANDed."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='matchLabels', type=d.T.object)]),
            withMatchLabelsMixin(matchLabels): { labelSelector+: { matchLabels+: matchLabels } },
          },
          '#withMatchLabelKeys':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
          withMatchLabelKeys(matchLabelKeys): { matchLabelKeys: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
          '#withMatchLabelKeysMixin':: d.fn(help="\"MatchLabelKeys is a set of pod label keys to select the pods over which\\nspreading will be calculated. The keys are used to lookup values from the\\nincoming pod labels, those key-value labels are ANDed with labelSelector\\nto select the group of existing pods over which spreading will be calculated\\nfor the incoming pod. The same key is forbidden to exist in both MatchLabelKeys and LabelSelector.\\nMatchLabelKeys cannot be set when LabelSelector isn't set.\\nKeys that don't exist in the incoming pod labels will\\nbe ignored. A null or empty list means only match against labelSelector.\\n\\nThis is a beta field and requires the MatchLabelKeysInPodTopologySpread feature gate to be enabled (enabled by default).\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='matchLabelKeys', type=d.T.array)]),
          withMatchLabelKeysMixin(matchLabelKeys): { matchLabelKeys+: if std.isArray(v=matchLabelKeys) then matchLabelKeys else [matchLabelKeys] },
          '#withMaxSkew':: d.fn(help="\"MaxSkew describes the degree to which pods may be unevenly distributed.\\nWhen `whenUnsatisfiable=DoNotSchedule`, it is the maximum permitted difference\\nbetween the number of matching pods in the target topology and the global minimum.\\nThe global minimum is the minimum number of matching pods in an eligible domain\\nor zero if the number of eligible domains is less than MinDomains.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 2/2/1:\\nIn this case, the global minimum is 1.\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |   P   |\\n- if MaxSkew is 1, incoming pod can only be scheduled to zone3 to become 2/2/2;\\nscheduling it onto zone1(zone2) would make the ActualSkew(3-1) on zone1(zone2)\\nviolate MaxSkew(1).\\n- if MaxSkew is 2, incoming pod can be scheduled onto any zone.\\nWhen `whenUnsatisfiable=ScheduleAnyway`, it is used to give higher precedence\\nto topologies that satisfy it.\\nIt's a required field. Default value is 1 and 0 is not allowed.\"", args=[d.arg(name='maxSkew', type=d.T.integer)]),
          withMaxSkew(maxSkew): { maxSkew: maxSkew },
          '#withMinDomains':: d.fn(help="\"MinDomains indicates a minimum number of eligible domains.\\nWhen the number of eligible domains with matching topology keys is less than minDomains,\\nPod Topology Spread treats \\\"global minimum\\\" as 0, and then the calculation of Skew is performed.\\nAnd when the number of eligible domains with matching topology keys equals or greater than minDomains,\\nthis value has no effect on scheduling.\\nAs a result, when the number of eligible domains is less than minDomains,\\nscheduler won't schedule more than maxSkew Pods to those domains.\\nIf value is nil, the constraint behaves as if MinDomains is equal to 1.\\nValid values are integers greater than 0.\\nWhen value is not nil, WhenUnsatisfiable must be DoNotSchedule.\\n\\nFor example, in a 3-zone cluster, MaxSkew is set to 2, MinDomains is set to 5 and pods with the same\\nlabelSelector spread as 2/2/2:\\n| zone1 | zone2 | zone3 |\\n|  P P  |  P P  |  P P  |\\nThe number of domains is less than 5(MinDomains), so \\\"global minimum\\\" is treated as 0.\\nIn this situation, new pod with the same labelSelector cannot be scheduled,\\nbecause computed skew will be 3(3 - 0) if new Pod is scheduled to any of the three zones,\\nit will violate MaxSkew.\"", args=[d.arg(name='minDomains', type=d.T.integer)]),
          withMinDomains(minDomains): { minDomains: minDomains },
          '#withNodeAffinityPolicy':: d.fn(help="\"NodeAffinityPolicy indicates how we will treat Pod's nodeAffinity/nodeSelector\\nwhen calculating pod topology spread skew. Options are:\\n- Honor: only nodes matching nodeAffinity/nodeSelector are included in the calculations.\\n- Ignore: nodeAffinity/nodeSelector are ignored. All nodes are included in the calculations.\\n\\nIf this value is nil, the behavior is equivalent to the Honor policy.\"", args=[d.arg(name='nodeAffinityPolicy', type=d.T.string)]),
          withNodeAffinityPolicy(nodeAffinityPolicy): { nodeAffinityPolicy: nodeAffinityPolicy },
          '#withNodeTaintsPolicy':: d.fn(help='"NodeTaintsPolicy indicates how we will treat node taints when calculating\\npod topology spread skew. Options are:\\n- Honor: nodes without taints, along with tainted nodes for which the incoming pod\\nhas a toleration, are included.\\n- Ignore: node taints are ignored. All nodes are included.\\n\\nIf this value is nil, the behavior is equivalent to the Ignore policy."', args=[d.arg(name='nodeTaintsPolicy', type=d.T.string)]),
          withNodeTaintsPolicy(nodeTaintsPolicy): { nodeTaintsPolicy: nodeTaintsPolicy },
          '#withTopologyKey':: d.fn(help="\"TopologyKey is the key of node labels. Nodes that have a label with this key\\nand identical values are considered to be in the same topology.\\nWe consider each \u003ckey, value\u003e as a \\\"bucket\\\", and try to put balanced number\\nof pods into each bucket.\\nWe define a domain as a particular instance of a topology.\\nAlso, we define an eligible domain as a domain whose nodes meet the requirements of\\nnodeAffinityPolicy and nodeTaintsPolicy.\\ne.g. If TopologyKey is \\\"kubernetes.io/hostname\\\", each Node is a domain of that topology.\\nAnd, if TopologyKey is \\\"topology.kubernetes.io/zone\\\", each zone is a domain of that topology.\\nIt's a required field.\"", args=[d.arg(name='topologyKey', type=d.T.string)]),
          withTopologyKey(topologyKey): { topologyKey: topologyKey },
          '#withWhenUnsatisfiable':: d.fn(help="\"WhenUnsatisfiable indicates how to deal with a pod if it doesn't satisfy\\nthe spread constraint.\\n- DoNotSchedule (default) tells the scheduler not to schedule it.\\n- ScheduleAnyway tells the scheduler to schedule the pod in any location,\\n  but giving higher precedence to topologies that would help reduce the\\n  skew.\\nA constraint is considered \\\"Unsatisfiable\\\" for an incoming pod\\nif and only if every possible node assignment for that pod would violate\\n\\\"MaxSkew\\\" on some topology.\\nFor example, in a 3-zone cluster, MaxSkew is set to 1, and pods with the same\\nlabelSelector spread as 3/1/1:\\n| zone1 | zone2 | zone3 |\\n| P P P |   P   |   P   |\\nIf WhenUnsatisfiable is set to DoNotSchedule, incoming pod can only be scheduled\\nto zone2(zone3) to become 3/2/1(3/1/2) as ActualSkew(2-1) on zone2(zone3) satisfies\\nMaxSkew(1). In other words, the cluster can still be imbalanced, but scheduler\\nwon't make it *more* imbalanced.\\nIt's a required field.\"", args=[d.arg(name='whenUnsatisfiable', type=d.T.string)]),
          withWhenUnsatisfiable(whenUnsatisfiable): { whenUnsatisfiable: whenUnsatisfiable },
        },
        '#withEnv':: d.fn(help='', args=[d.arg(name='env', type=d.T.array)]),
        withEnv(env): { spec+: { proxy+: { pgBouncer+: { env: if std.isArray(v=env) then env else [env] } } } },
        '#withEnvFrom':: d.fn(help='', args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFrom(envFrom): { spec+: { proxy+: { pgBouncer+: { envFrom: if std.isArray(v=envFrom) then envFrom else [envFrom] } } } },
        '#withEnvFromMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='envFrom', type=d.T.array)]),
        withEnvFromMixin(envFrom): { spec+: { proxy+: { pgBouncer+: { envFrom+: if std.isArray(v=envFrom) then envFrom else [envFrom] } } } },
        '#withEnvMixin':: d.fn(help='\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='env', type=d.T.array)]),
        withEnvMixin(env): { spec+: { proxy+: { pgBouncer+: { env+: if std.isArray(v=env) then env else [env] } } } },
        '#withExposeSuperusers':: d.fn(help='"Allow SUPERUSERs to connect through PGBouncer."', args=[d.arg(name='exposeSuperusers', type=d.T.boolean)]),
        withExposeSuperusers(exposeSuperusers): { spec+: { proxy+: { pgBouncer+: { exposeSuperusers: exposeSuperusers } } } },
        '#withImage':: d.fn(help='"Name of a container image that can run PgBouncer 1.15 or newer. Changing\\nthis value causes PgBouncer to restart. The image may also be set using\\nthe RELATED_IMAGE_PGBOUNCER environment variable.\\nMore info: https://kubernetes.io/docs/concepts/containers/images"', args=[d.arg(name='image', type=d.T.string)]),
        withImage(image): { spec+: { proxy+: { pgBouncer+: { image: image } } } },
        '#withMinAvailable':: d.fn(help='"Minimum number of pods that should be available at a time.\\nDefaults to one when the replicas field is greater than one."', args=[d.arg(name='minAvailable', type=d.T.any)]),
        withMinAvailable(minAvailable): { spec+: { proxy+: { pgBouncer+: { minAvailable: minAvailable } } } },
        '#withPort':: d.fn(help='"Port on which PgBouncer should listen for client connections. Changing\\nthis value causes PgBouncer to restart."', args=[d.arg(name='port', type=d.T.integer)]),
        withPort(port): { spec+: { proxy+: { pgBouncer+: { port: port } } } },
        '#withPriorityClassName':: d.fn(help='"Priority class name for the pgBouncer pod. Changing this value causes\\nPostgreSQL to restart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/"', args=[d.arg(name='priorityClassName', type=d.T.string)]),
        withPriorityClassName(priorityClassName): { spec+: { proxy+: { pgBouncer+: { priorityClassName: priorityClassName } } } },
        '#withReplicas':: d.fn(help='"Number of desired PgBouncer pods."', args=[d.arg(name='replicas', type=d.T.integer)]),
        withReplicas(replicas): { spec+: { proxy+: { pgBouncer+: { replicas: replicas } } } },
        '#withSidecars':: d.fn(help='"Custom sidecars for a PgBouncer pod. Changing this value causes\\nPgBouncer to restart."', args=[d.arg(name='sidecars', type=d.T.array)]),
        withSidecars(sidecars): { spec+: { proxy+: { pgBouncer+: { sidecars: if std.isArray(v=sidecars) then sidecars else [sidecars] } } } },
        '#withSidecarsMixin':: d.fn(help='"Custom sidecars for a PgBouncer pod. Changing this value causes\\nPgBouncer to restart."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='sidecars', type=d.T.array)]),
        withSidecarsMixin(sidecars): { spec+: { proxy+: { pgBouncer+: { sidecars+: if std.isArray(v=sidecars) then sidecars else [sidecars] } } } },
        '#withTolerations':: d.fn(help='"Tolerations of a PgBouncer pod. Changing this value causes PgBouncer to\\nrestart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerations(tolerations): { spec+: { proxy+: { pgBouncer+: { tolerations: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTolerationsMixin':: d.fn(help='"Tolerations of a PgBouncer pod. Changing this value causes PgBouncer to\\nrestart.\\nMore info: https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='tolerations', type=d.T.array)]),
        withTolerationsMixin(tolerations): { spec+: { proxy+: { pgBouncer+: { tolerations+: if std.isArray(v=tolerations) then tolerations else [tolerations] } } } },
        '#withTopologySpreadConstraints':: d.fn(help='"Topology spread constraints of a PgBouncer pod. Changing this value causes\\nPgBouncer to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
        withTopologySpreadConstraints(topologySpreadConstraints): { spec+: { proxy+: { pgBouncer+: { topologySpreadConstraints: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } },
        '#withTopologySpreadConstraintsMixin':: d.fn(help='"Topology spread constraints of a PgBouncer pod. Changing this value causes\\nPgBouncer to restart.\\nMore info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='topologySpreadConstraints', type=d.T.array)]),
        withTopologySpreadConstraintsMixin(topologySpreadConstraints): { spec+: { proxy+: { pgBouncer+: { topologySpreadConstraints+: if std.isArray(v=topologySpreadConstraints) then topologySpreadConstraints else [topologySpreadConstraints] } } } },
      },
    },
    '#secrets':: d.obj(help=''),
    secrets: {
      '#customReplicationTLSSecret':: d.obj(help='"The secret containing the replication client certificates and keys for\\nsecure connections to the PostgreSQL server. It will need to contain the\\nclient TLS certificate, TLS key and the Certificate Authority certificate\\nwith the data keys set to tls.crt, tls.key and ca.crt, respectively.\\nNOTE: If CustomReplicationClientTLSSecret is provided, CustomTLSSecret\\nMUST be provided and the ca.crt provided must be the same."'),
      customReplicationTLSSecret: {
        '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
        items: {
          '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
          withMode(mode): { mode: mode },
          '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { path: path },
        },
        '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
        withItems(items): { spec+: { secrets+: { customReplicationTLSSecret+: { items: if std.isArray(v=items) then items else [items] } } } },
        '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
        withItemsMixin(items): { spec+: { secrets+: { customReplicationTLSSecret+: { items+: if std.isArray(v=items) then items else [items] } } } },
        '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { secrets+: { customReplicationTLSSecret+: { name: name } } } },
        '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { secrets+: { customReplicationTLSSecret+: { optional: optional } } } },
      },
      '#customRootCATLSSecret':: d.obj(help='"The secret containing the root CA certificate and key for\\nsecure connections to the PostgreSQL server. It will need to contain the\\nCA TLS certificate and CA TLS key with the data keys set to\\nroot.crt and root.key, respectively."'),
      customRootCATLSSecret: {
        '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
        items: {
          '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
          withMode(mode): { mode: mode },
          '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { path: path },
        },
        '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
        withItems(items): { spec+: { secrets+: { customRootCATLSSecret+: { items: if std.isArray(v=items) then items else [items] } } } },
        '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
        withItemsMixin(items): { spec+: { secrets+: { customRootCATLSSecret+: { items+: if std.isArray(v=items) then items else [items] } } } },
        '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { secrets+: { customRootCATLSSecret+: { name: name } } } },
        '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { secrets+: { customRootCATLSSecret+: { optional: optional } } } },
      },
      '#customTLSSecret':: d.obj(help="\"The secret containing the Certificates and Keys to encrypt PostgreSQL\\ntraffic will need to contain the server TLS certificate, TLS key and the\\nCertificate Authority certificate with the data keys set to tls.crt,\\ntls.key and ca.crt, respectively. It will then be mounted as a volume\\nprojection to the '/pgconf/tls' directory. For more information on\\nKubernetes secret projections, please see\\nhttps://k8s.io/docs/concepts/configuration/secret/#projection-of-secret-keys-to-specific-paths\\nNOTE: If CustomTLSSecret is provided, CustomReplicationClientTLSSecret\\nMUST be provided and the ca.crt provided must be the same.\""),
      customTLSSecret: {
        '#items':: d.obj(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\""),
        items: {
          '#withKey':: d.fn(help='"key is the key to project."', args=[d.arg(name='key', type=d.T.string)]),
          withKey(key): { key: key },
          '#withMode':: d.fn(help='"mode is Optional: mode bits used to set permissions on this file.\\nMust be an octal value between 0000 and 0777 or a decimal value between 0 and 511.\\nYAML accepts both octal and decimal values, JSON requires decimal values for mode bits.\\nIf not specified, the volume defaultMode will be used.\\nThis might be in conflict with other options that affect the file\\nmode, like fsGroup, and the result can be other mode bits set."', args=[d.arg(name='mode', type=d.T.integer)]),
          withMode(mode): { mode: mode },
          '#withPath':: d.fn(help="\"path is the relative path of the file to map the key to.\\nMay not be an absolute path.\\nMay not contain the path element '..'.\\nMay not start with the string '..'.\"", args=[d.arg(name='path', type=d.T.string)]),
          withPath(path): { path: path },
        },
        '#withItems':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"", args=[d.arg(name='items', type=d.T.array)]),
        withItems(items): { spec+: { secrets+: { customTLSSecret+: { items: if std.isArray(v=items) then items else [items] } } } },
        '#withItemsMixin':: d.fn(help="\"items if unspecified, each key-value pair in the Data field of the referenced\\nSecret will be projected into the volume as a file whose name is the\\nkey and content is the value. If specified, the listed keys will be\\nprojected into the specified paths, and unlisted keys will not be\\npresent. If a key is specified which is not present in the Secret,\\nthe volume setup will error unless it is marked optional. Paths must be\\nrelative and may not contain the '..' path or start with '..'.\"\n\n**Note:** This function appends passed data to existing values", args=[d.arg(name='items', type=d.T.array)]),
        withItemsMixin(items): { spec+: { secrets+: { customTLSSecret+: { items+: if std.isArray(v=items) then items else [items] } } } },
        '#withName':: d.fn(help='"Name of the referent.\\nThis field is effectively required, but due to backwards compatibility is\\nallowed to be empty. Instances of this type with an empty value here are\\nalmost certainly wrong.\\nMore info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names"', args=[d.arg(name='name', type=d.T.string)]),
        withName(name): { spec+: { secrets+: { customTLSSecret+: { name: name } } } },
        '#withOptional':: d.fn(help='"optional field specify whether the Secret or its key must be defined"', args=[d.arg(name='optional', type=d.T.boolean)]),
        withOptional(optional): { spec+: { secrets+: { customTLSSecret+: { optional: optional } } } },
      },
    },
    '#standby':: d.obj(help='"Run this cluster as a read-only copy of an existing cluster or archive."'),
    standby: {
      '#withEnabled':: d.fn(help='"Whether or not the PostgreSQL cluster should be read-only. When this is\\ntrue, WAL files are applied from a pgBackRest repository or another\\nPostgreSQL server."', args=[d.arg(name='enabled', type=d.T.boolean)]),
      withEnabled(enabled): { spec+: { standby+: { enabled: enabled } } },
      '#withHost':: d.fn(help='"Network address of the PostgreSQL server to follow via streaming replication."', args=[d.arg(name='host', type=d.T.string)]),
      withHost(host): { spec+: { standby+: { host: host } } },
      '#withPort':: d.fn(help='"Network port of the PostgreSQL server to follow via streaming replication."', args=[d.arg(name='port', type=d.T.integer)]),
      withPort(port): { spec+: { standby+: { port: port } } },
      '#withRepoName':: d.fn(help='"The name of the pgBackRest repository to follow for WAL files."', args=[d.arg(name='repoName', type=d.T.string)]),
      withRepoName(repoName): { spec+: { standby+: { repoName: repoName } } },
    },
    '#users':: d.obj(help='"Users to create inside PostgreSQL and the databases they should access.\\nThe default creates one user that can access one database matching the\\nPostgresCluster name. An empty list creates no users. Removing a user\\nfrom this list does NOT drop the user nor revoke their access."'),
    users: {
      '#password':: d.obj(help='"Properties of the password generated for this user."'),
      password: {
        '#withType':: d.fn(help='"Type of password to generate. Defaults to ASCII. Valid options are ASCII\\nand AlphaNumeric.\\n\\"ASCII\\" passwords contain letters, numbers, and symbols from the US-ASCII character set.\\n\\"AlphaNumeric\\" passwords contain letters and numbers from the US-ASCII character set."', args=[d.arg(name='type', type=d.T.string)]),
        withType(type): { password+: { type: type } },
      },
      '#withDatabases':: d.fn(help='"Databases to which this user can connect and create objects. Removing a\\ndatabase from this list does NOT revoke access. This field is ignored for\\nthe \\"postgres\\" user."', args=[d.arg(name='databases', type=d.T.array)]),
      withDatabases(databases): { databases: if std.isArray(v=databases) then databases else [databases] },
      '#withDatabasesMixin':: d.fn(help='"Databases to which this user can connect and create objects. Removing a\\ndatabase from this list does NOT revoke access. This field is ignored for\\nthe \\"postgres\\" user."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='databases', type=d.T.array)]),
      withDatabasesMixin(databases): { databases+: if std.isArray(v=databases) then databases else [databases] },
      '#withGrantPublicSchemaAccess':: d.fn(help='"Grant the user access to the public schema in each database listed under `databases`."', args=[d.arg(name='grantPublicSchemaAccess', type=d.T.boolean)]),
      withGrantPublicSchemaAccess(grantPublicSchemaAccess): { grantPublicSchemaAccess: grantPublicSchemaAccess },
      '#withName':: d.fn(help='"The name of this PostgreSQL user. The value may contain only lowercase\\nletters, numbers, and hyphen so that it fits into Kubernetes metadata."', args=[d.arg(name='name', type=d.T.string)]),
      withName(name): { name: name },
      '#withOptions':: d.fn(help='"ALTER ROLE options except for PASSWORD. This field is ignored for the\\n\\"postgres\\" user.\\nMore info: https://www.postgresql.org/docs/current/role-attributes.html"', args=[d.arg(name='options', type=d.T.string)]),
      withOptions(options): { options: options },
      '#withSecretName':: d.fn(help='"The secret name to generate user, password, connection info this PostgreSQL user."', args=[d.arg(name='secretName', type=d.T.string)]),
      withSecretName(secretName): { secretName: secretName },
    },
    '#withAutoCreateUserSchema':: d.fn(help='"Indicates whether schemas are automatically created for the user\\nspecified in `spec.users` across all databases associated with that user."', args=[d.arg(name='autoCreateUserSchema', type=d.T.boolean)]),
    withAutoCreateUserSchema(autoCreateUserSchema): { spec+: { autoCreateUserSchema: autoCreateUserSchema } },
    '#withCrVersion':: d.fn(help='"Version of the operator. Update this to new version after operator\\nupgrade to apply changes to Kubernetes objects. Default is the latest\\nversion."', args=[d.arg(name='crVersion', type=d.T.string)]),
    withCrVersion(crVersion): { spec+: { crVersion: crVersion } },
    '#withImage':: d.fn(help='"The image name to use for PostgreSQL containers."', args=[d.arg(name='image', type=d.T.string)]),
    withImage(image): { spec+: { image: image } },
    '#withImagePullPolicy':: d.fn(help='"ImagePullPolicy is used to determine when Kubernetes will attempt to\\npull (download) container images.\\nMore info: https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy"', args=[d.arg(name='imagePullPolicy', type=d.T.string)]),
    withImagePullPolicy(imagePullPolicy): { spec+: { imagePullPolicy: imagePullPolicy } },
    '#withImagePullSecrets':: d.fn(help='"The image pull secrets used to pull from a private registry\\nChanging this value causes all running pods to restart.\\nhttps://k8s.io/docs/tasks/configure-pod-container/pull-image-private-registry/"', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
    withImagePullSecrets(imagePullSecrets): { spec+: { imagePullSecrets: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } },
    '#withImagePullSecretsMixin':: d.fn(help='"The image pull secrets used to pull from a private registry\\nChanging this value causes all running pods to restart.\\nhttps://k8s.io/docs/tasks/configure-pod-container/pull-image-private-registry/"\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='imagePullSecrets', type=d.T.array)]),
    withImagePullSecretsMixin(imagePullSecrets): { spec+: { imagePullSecrets+: if std.isArray(v=imagePullSecrets) then imagePullSecrets else [imagePullSecrets] } },
    '#withInstances':: d.fn(help='"Specifies one or more sets of PostgreSQL pods that replicate data for\\nthis cluster."', args=[d.arg(name='instances', type=d.T.array)]),
    withInstances(instances): { spec+: { instances: if std.isArray(v=instances) then instances else [instances] } },
    '#withInstancesMixin':: d.fn(help='"Specifies one or more sets of PostgreSQL pods that replicate data for\\nthis cluster."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='instances', type=d.T.array)]),
    withInstancesMixin(instances): { spec+: { instances+: if std.isArray(v=instances) then instances else [instances] } },
    '#withOpenshift':: d.fn(help='"Whether or not the PostgreSQL cluster is being deployed to an OpenShift\\nenvironment. If the field is unset, the operator will automatically\\ndetect the environment."', args=[d.arg(name='openshift', type=d.T.boolean)]),
    withOpenshift(openshift): { spec+: { openshift: openshift } },
    '#withPause':: d.fn(help='"Whether or not the PostgreSQL cluster should be stopped.\\nWhen this is true, workloads are scaled to zero and CronJobs\\nare suspended.\\nOther resources, such as Services and Volumes, remain in place."', args=[d.arg(name='pause', type=d.T.boolean)]),
    withPause(pause): { spec+: { pause: pause } },
    '#withPort':: d.fn(help='"The port on which PostgreSQL should listen."', args=[d.arg(name='port', type=d.T.integer)]),
    withPort(port): { spec+: { port: port } },
    '#withPostgresVersion':: d.fn(help='"The major version of PostgreSQL installed in the PostgreSQL image"', args=[d.arg(name='postgresVersion', type=d.T.integer)]),
    withPostgresVersion(postgresVersion): { spec+: { postgresVersion: postgresVersion } },
    '#withTlsOnly':: d.fn(help='', args=[d.arg(name='tlsOnly', type=d.T.boolean)]),
    withTlsOnly(tlsOnly): { spec+: { tlsOnly: tlsOnly } },
    '#withUnmanaged':: d.fn(help='"Suspends the rollout and reconciliation of changes made to the\\nPostgresCluster spec."', args=[d.arg(name='unmanaged', type=d.T.boolean)]),
    withUnmanaged(unmanaged): { spec+: { unmanaged: unmanaged } },
    '#withUsers':: d.fn(help='"Users to create inside PostgreSQL and the databases they should access.\\nThe default creates one user that can access one database matching the\\nPostgresCluster name. An empty list creates no users. Removing a user\\nfrom this list does NOT drop the user nor revoke their access."', args=[d.arg(name='users', type=d.T.array)]),
    withUsers(users): { spec+: { users: if std.isArray(v=users) then users else [users] } },
    '#withUsersMixin':: d.fn(help='"Users to create inside PostgreSQL and the databases they should access.\\nThe default creates one user that can access one database matching the\\nPostgresCluster name. An empty list creates no users. Removing a user\\nfrom this list does NOT drop the user nor revoke their access."\n\n**Note:** This function appends passed data to existing values', args=[d.arg(name='users', type=d.T.array)]),
    withUsersMixin(users): { spec+: { users+: if std.isArray(v=users) then users else [users] } },
  },
  '#mixin': 'ignore',
  mixin: self,
}
